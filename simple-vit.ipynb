{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10214857,"sourceType":"datasetVersion","datasetId":6313708},{"sourceId":14557955,"sourceType":"datasetVersion","datasetId":9298487},{"sourceId":14558261,"sourceType":"datasetVersion","datasetId":9298694},{"sourceId":14558305,"sourceType":"datasetVersion","datasetId":9298725}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"yakhyokhuja/webface-112x112\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-23T04:22:23.402982Z","iopub.execute_input":"2026-01-23T04:22:23.403278Z","iopub.status.idle":"2026-01-23T04:22:24.410159Z","shell.execute_reply.started":"2026-01-23T04:22:23.403248Z","shell.execute_reply":"2026-01-23T04:22:24.409284Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/webface-112x112\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\n\nBASE_DIR = \"/kaggle/working/FaceDetectionViT\"\n\nfolders = [\n    \"data/raw\",\n    \"data/processed\",\n    \"data/annotations\",\n    \"models/checkpoints\",\n    \"models/exported\",\n    \"src\",\n    \"notebooks\",\n    \"outputs/logs\",\n    \"outputs/plots\",\n    \"outputs/predictions\",\n]\n\nfor f in folders:\n    os.makedirs(os.path.join(BASE_DIR, f), exist_ok=True)\n\nprint(\" Folder structure created at:\", BASE_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T04:24:15.828373Z","iopub.execute_input":"2026-01-23T04:24:15.828650Z","iopub.status.idle":"2026-01-23T04:24:15.833927Z","shell.execute_reply.started":"2026-01-23T04:24:15.828624Z","shell.execute_reply":"2026-01-23T04:24:15.833375Z"}},"outputs":[{"name":"stdout","text":" Folder structure created at: /kaggle/working/FaceDetectionViT\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"#DATA LOADING AND HANDLING","metadata":{}},{"cell_type":"code","source":"DATASET_INPUT = \"/kaggle/input/webface-112x112/webface_112x112\"\n\nPROJECT_DIR   = \"/kaggle/working/FaceDetectionViT\"\nRAW_DIR       = f\"{PROJECT_DIR}/data/raw\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T04:24:18.613567Z","iopub.execute_input":"2026-01-23T04:24:18.613845Z","iopub.status.idle":"2026-01-23T04:24:18.617364Z","shell.execute_reply.started":"2026-01-23T04:24:18.613822Z","shell.execute_reply":"2026-01-23T04:24:18.616704Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import os\n\ndef show_samples(path, limit=5):\n    items = sorted(os.listdir(path))[:limit]\n    for i in items:\n        print(i)\n\nprint(\"ðŸ“Œ Top folders/files inside dataset:\")\nshow_samples(DATASET_INPUT, limit=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T04:24:20.278928Z","iopub.execute_input":"2026-01-23T04:24:20.279231Z","iopub.status.idle":"2026-01-23T04:24:20.444508Z","shell.execute_reply.started":"2026-01-23T04:24:20.279206Z","shell.execute_reply":"2026-01-23T04:24:20.443849Z"}},"outputs":[{"name":"stdout","text":"ðŸ“Œ Top folders/files inside dataset:\nid_0\nid_1\nid_10\nid_100\nid_1000\nid_10000\nid_10001\nid_10002\nid_10003\nid_10004\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import os\n\nroot = DATASET_INPUT\nidentities = []\ntotal_imgs = 0\n\nfor name in os.listdir(root):\n    person_dir = os.path.join(root, name)\n    if os.path.isdir(person_dir):\n        identities.append(name)\n        imgs = [x for x in os.listdir(person_dir) if x.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n        total_imgs += len(imgs)\n\nprint(\" Total Identities:\", len(identities))\nprint(\" Total Images:\", total_imgs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T04:24:21.903552Z","iopub.execute_input":"2026-01-23T04:24:21.903838Z","iopub.status.idle":"2026-01-23T04:27:38.259888Z","shell.execute_reply.started":"2026-01-23T04:24:21.903814Z","shell.execute_reply":"2026-01-23T04:27:38.259247Z"}},"outputs":[{"name":"stdout","text":" Total Identities: 10572\n Total Images: 490623\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os, random\n\nall_ids = [d for d in os.listdir(DATASET_INPUT) if os.path.isdir(os.path.join(DATASET_INPUT, d))]\nprint(\" Total IDs:\", len(all_ids))\n\nsample_ids = random.sample(all_ids, min(10, len(all_ids)))\n\nfor pid in sample_ids:\n    pdir = os.path.join(DATASET_INPUT, pid)\n    imgs = [x for x in os.listdir(pdir) if x.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n    print(pid, \"->\", len(imgs), \"images\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T04:27:38.261168Z","iopub.execute_input":"2026-01-23T04:27:38.261411Z","iopub.status.idle":"2026-01-23T04:27:50.410276Z","shell.execute_reply.started":"2026-01-23T04:27:38.261391Z","shell.execute_reply":"2026-01-23T04:27:50.409622Z"}},"outputs":[{"name":"stdout","text":" Total IDs: 10572\nid_2006 -> 49 images\nid_2541 -> 33 images\nid_4239 -> 33 images\nid_7671 -> 16 images\nid_10211 -> 34 images\nid_1432 -> 17 images\nid_8911 -> 17 images\nid_8779 -> 31 images\nid_2483 -> 22 images\nid_8077 -> 21 images\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import os, random\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\npid = random.choice(all_ids)\npdir = os.path.join(DATASET_INPUT, pid)\nimgs = [x for x in os.listdir(pdir) if x.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n\nimg_path = os.path.join(pdir, random.choice(imgs))\nimg = Image.open(img_path).convert(\"RGB\")\n\nprint(\" ID:\", pid)\nprint(\" Image:\", img_path)\n\nplt.imshow(img)\nplt.axis(\"off\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T04:27:50.411124Z","iopub.execute_input":"2026-01-23T04:27:50.411709Z","iopub.status.idle":"2026-01-23T04:27:50.507811Z","shell.execute_reply.started":"2026-01-23T04:27:50.411687Z","shell.execute_reply":"2026-01-23T04:27:50.507237Z"}},"outputs":[{"name":"stdout","text":" ID: id_9641\n Image: /kaggle/input/webface-112x112/webface_112x112/id_9641/9641_463166.jpg\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAj65JREFUeJztvVmzLEl2necxZ+bJM9yxxp7QANhoEQRMgpGSiTDTo6QXPchMD/qbNMlMNFEyUSBIgkaiwQbQU1V3dXfNdeveM+UUox5uV/i3V2Zk560qiDJoryc/mRGRHh4eEWcvX3uvZBiGITgcDofDEUJI/1N3wOFwOBz/34G/FBwOh8Mxwl8KDofD4RjhLwWHw+FwjPCXgsPhcDhG+EvB4XA4HCP8peBwOByOEf5ScDgcDseI/NQN/8kfxPdHkiTmuyzLxnbf92O77ex2eR5/bkhie7vdxs+HzOwzm83G9mZdj+35fG62G9r4W/f392O7Ku12FxcX2G4ztj/99DPsMzP7pGk89yI/3O8Q7LiUZRk/H3qzXVHGc+SYrFax37NZafcpinjsaroPi2qBY8TzGIbObMdrlufx/HiuL3eM+93e3sb9kfPI/UMI4ayKv7tYxHaVTf8PUuY4v9Kee1nE810s4vnxZ+vtzu6D3zqbVWP7Yrk02/HazMrYh+fPn5vtujbOPY7Dd7/7XbPd06dPxzbn6G4X59rz6xdmn0ePHsXzwBwPgx2vO8zXv/3J34ztb3zrW2a7YhbnYZXFdpLEY2+u78w+ZY77Lo3jsDy/NNvtkOr6yYs4Dj/59Qdmu/c/+jj+1i7OIT4fqtmZ2acL8eCzKl6ncmHvx9ki7jfgOn/66TOzXd02Y/vufj221+u12S7PMd8wDG0f9+8Te/8MeLR1QxxXfTYO6YDtpu+ZFt8xnzgdpp+7oY/bcVx7+7gxePfd356r7JGCw+FwOEb4S8HhcDgcI5JTax/9ye8zDD2yIeiHNLHsFAOwHn8MjMX0PYXvGOatVhuzWb2JIdyDq0dhCvf3q7hP3eJnYtxYpJbCIqXC0LNtbEhZlvnBfczJhhCqWQzPz88RJmP/hw8fmn3mVdyHxyZVFkIIzS6OQ9vG82taS6+QtspAMXCfEEIoEJ7PQQuRduGxQghhARqmQwieD3biFDjfBLNQKawC/SMlk4Ju0Gt2dRlpD1IjZWr70INiIPXT1JaW423CMP7q6spsR+qLVGUIcbxub6/NPgvQKKQLdrvGbPfrX304tr/7vd8d23crOwfOzyPFdnsbKZU8i+eQ7V3neC0azOterlkKanWLaf3RzY3Z7pPrSC19/vx6bN/jvi2FAk7LSPNtce67xva1nMX9Pn0Wad9enh3s+hbPh7quzXZ8lpAyut1Eiq1PLCeTkJZLcS8U9l4gfdR09jlA9BPP1Cw4feRwOByO/4Twl4LD4XA4RvhLweFwOBwjTl5T+C9+b3pNocMRksA1AMuv1eDUQOWGHFxi39nukN/cbuJOQguGq4vIzafgl+/urPSO6xyLRdynAw/XyME79Jt8ZAUZ5cvjgXPH59v1ymyXF/FdXGGM+iFyp/N5ZfYpi3hOlJqSqw4hhDw5/J5/+ODK/M21g6I4LJENIYSPP4pSwwxn9fprT2IPhMRcGElp/K4U3t/IirHuopLUoYvXndLcFP3pO8u/d3X8m5LWxw/sWg2lpq+//jp+0/LYnAPsg103sPLSxTKuFXDezIV33oHvvr+BLBny4hBCyLI4LuS4CxmvLol9n5VxPgxNXFdqVnZODriGCbjquhUuHSr2uyb2e5jbvn56G++7d979xdh+9/33x/ZK1goCZck43sMnj21f8b/sw4dxvDdru25G6fDPf/7e2P7o00/MdkUe77VdE9eSmtAebIcQzL/TQ8Dc04cjpnyPNbBU1rbq7vBjmPecrrUNEzLWYeJYIYTwzju+puBwOByOV4C/FBwOh8Mx4uSMZmKQd0mCsMjKTq0EixRNAgkctWONhJSkjHaIDh8+tGF7AwnbzXUMwb/5zbfNdgzhPv7oUxw77q/UDekRUjfMCn7Zd4SRyAQW1iQkpFtAA5Q4nmb/Un45gIoYRO6aIhOatMvnn3xotrsE3VYUMVRP5Jp958034neggnjumqhMWq0DxdA1Nryv72P/mMG9KGwGawtKLBsOX4uzhc28HcBP1pg4VW7D9hbx/fVnUd6omeJLZELPHkUK6uzMZuU+ePBgbHPeJGAak2D7QAqqTJjZbcdhPovXaY7rdwOaJIQQMmTLzmagJ+s4DrvCykF7jBHp01xoE57TgL62wkp8m5ndWdxuh995/3ObgVyAzk2qeA9qdvmKmd1/HTO7B8kAZ/b71UWcH48fWzrqZz97d2zzuqdVnBv633OCOclxGES6OkBrnfGyC82UJMPBr5LhmP6f+1Mia797VcdljxQcDofDMcJfCg6Hw+EYcTp9xHBpLxyJoQtrvynNlIFWGPr43Qrqi5sbqyLhgvsMhc2ub6164sFFDNt/53ejioSZjCGEcAtVBItQlaCMFufnZh8qR3YbZD820le0z+ZxaHPhV/hnQRUJTjZP7BgXUCtUUAtlmb2EZziPWWUpNoJZvjy/TH730cOrsU1FzgqqroulpVAqZDTnUtiPIB1FZUW3tdnqZ3NkCS/jtemoOKptkbMFlE1zUEaFXIsZlCekG6zCy2aYd5jkhYz/0EKlRCUXmpp9XVWxr3kWf1eVYBUyyregYVJRM5XzuF2K6zzgd0uhJaplnCs1isdtMnuftZv4u/Nl/J1db+dNC1rz974BChcZvuu/+Auzz88//mhsP3w90pYPL+08fgvfsQjexx99Zra7eR4LD96nkVK+emQVaN/+5jfG9vltnF8fP4/08nprnyN9H++FFPMrEap4UiEU7HhpHcpxO9yPvRTWnPqPXgVQRytQHIBHCg6Hw+EY4S8Fh8PhcIzwl4LD4XA4Rpy8pkDJU6Nl+MBPHkmmCz1KAe7A0b14ATMLKSTIZM35LPJ9lP6FYJSd4TNIC1eSuckEzRk4ZPJ9KoEzWbQYh8tLu/aQo1oiExbL1A7KWRVP6gz8b4HtUhkIU5UUvGUhZh0LrDds7mLlyqUalcB86OoijsO5rKcUOdcvIv/+2lWUD2aigWtgKEPO3Ri5BLuOQA6/lwqeLeSlV4vY7yxfYBu7zxxZ8pTPziVLmNeWc7wT/pZZvg8x987FhIYELtcE0o5STrtLT65/EfudS8Z8R2k01lbKTA6IyWekwz1Mf3p7zXr2r4A8e2HXizbcDu1lZft6h7W3gIqz3337rbGdz/7U7DP/wV+O7U9v4prV6t5KbllS9BEy1J8+emo2+/zzuKawxlrIjVR0ZbY6KwJcYox7WQNokQnPYtB9kAcYLs2A65KKnL2WDPpxnyPPU373qusGx+CRgsPhcDhG+EvB4XA4HCNOpo/aI3FMB85ooHRVnCOYKblaxXCJ9rpzy3KE5fnV2Kan6/3KZpx+/lmUpt3dxdBVw6oCxeiYvUj6oqpsRjOlsLY4mw0BKSmtUIjsYmGPN8d+C1AMM9ArM5EjziHtLEHJpCIhJf+2fCMWrcvVOxbXkxTU2cxmup6BdqIMLwflkUtxr2QZKRpbwE6yPdEH0lYL6cOujtfz7iZSCRXorJlkFmu2+RdQb29mJLNYYlFZKS2LLHLENfM5R9G6ooj9q0BnDWrEQu9eQ1Xa7TLSW/h3juY0IYTQ4n5McR6zAuck1NQWlEqDDGS9tkWL8QNlN/SW/rjAvFnjnkmRQf7t118z+9z+bjQOqt6PGfirnT32PajnYYjnrt7Lq1WkoOjrfJVaiesWWfekf9pVnK+NyM95O5m5Js/JBufOYgGZPk8n6B9SmpoKYDKfPaPZ4XA4HH8X8JeCw+FwOEacTB91rGYn8glSRvxukPS+GiEY694xUl/Ml4FYnkV1x3odQ3VVCG3XLK4GxYsUFRtQqC4DlbTbxtBTqYcVVDwMpwspFpYV8btFuUTbDvM5PJrnoAuY3VwK1TKnT3GFzGfJjl2A6mKRrUEUYxSssNhboUoWKH8uzyJ1wHBVC+IVoFCYqaleD9YnGiqZxCo4Mm6H7Gn1XSCY/cvt9NrmE2E7lTUvjxGPx6+y3PZhfhZpMI5RDnqy0z6AZsowYI0UEExA67B0QJpZKmiGrHYqBRuqBFO7T48+zM4xv1pLm/S4p3uoijQLnZnLeQ3/YGR8l5Udh3/4e5E+4jX7qx+9Y7a7gAKtxsXYbix9dAmf7rtV/E6fHRky8EljdpivdWczmqk+IkXaifooaeI4MMt7j9dmtnOaHPp4z6PZONunX5/8yCMFh8PhcIzwl4LD4XA4RpxMHw0IVtq9DDXUjechhS4gBcVcjQskgZWlTS767Nn12Ka9Xi8FuIxCCPqQ9UbUIVD4GDUNLSkl2YwFy5YozkaFUQghLPD31TLucy5F4UrQRBWoEia1nUtBNipHqBbSgmxURNHXIJOKWxlootwU27PHY1B6BlUWw3tVnlCNltL/QBKcGHYTau+ZgrJYXl7q5gfB4osZ+K1SlDo5xrxrmVxkx4FdynMqjOx1okqJ9FiCWv/DILcdVHr0WsiEFuqHie8GS8O0oCxIOfU4diFzN8VtN4CGUX+TAuOXgIptanuf9aBK5lDfoWuhk30eoCjfNx/HRLT3zz4y2/0KRfASoYeJd9792diuoGjb1JbqatdRpfT+B9F+9vJR9F1QG9fbVXwWkVrKVVmWgErFmPSiGmzFx+QLdKouNAcfDjX3cewYB+CRgsPhcDhG+EvB4XA4HCP8peBwOByOESevKZDDVzUVvyNX1uyspG4AJzpbFAc/p/9qCCHc3UVzDPqiXlzYDNaAPjDLVLP5WPwqZQE7rEOkml7YR1ke66RVmeUzz5GOfQFZYCm+rZSoLsHRzsFHzoVvp7HOGeSW6idNkxdy86kUeMvAcee8tlKYqwRHDsVtqJhBKbLMAePK8S+Fp8/xNyWznRQf4zrQ3rUZt7HHnoFDZpZwIn1oGxjmYJ2kkzWrwPHC+eoaBQudMSM5SdFO7LVN8L8ZL9NeFxLOUfxOKrcxrlmKvrJoYCPVBjIcI8X86msrxUy4H9aS5ktbSHG3jfctFewsLJiI3DUgs/gRpKH/6Hu/bzZbQZp+hzWPb33jLbPdt3/nO2P702exSOYvf/2+2e76+npst1gfWN3Hc8hkftFrenER51o1t/fC/S6e7+6eBl/irT6RgX9MaDolQ01SXUN4NbmqRwoOh8PhGOEvBYfD4XCMOF2SekTVxPCXyqq6tiHS0IOKQKi+Qa3z7UZ8j5PDXby/s9mL/RDDSMoHNXCi/QASmkO1iP1ZiISUfsnLeQz9H4mfwiNQWhUkn4WEiqSWLiDzpJ+Cegnz78q0JewExUYardQsWso0IflMRL5WQdJo6B/QVKmmNJv+QOapk4hZuRNeti+/i+0MV5SUUS4F7Mx3zIgu7HYpqL0Mc7KVjOaO2cCY5FooLeP/WTnoHvxOnut4HfZxUNuSBONML4q9TFeMF/2gO8ifdYzpM8IxDkKbdA3Ovee1sPOLHhFMAed1blt7X3SQj5ezqJF964n1SfiHf/C9sX2NZ8eP3/ul2e6zF9dje4as/T/+4z8y2/3yl3G/EtL22/vYH5WMlub5FSnvQajiOTPZcYwbyGCPgXN/7xmM3zIF8b6iuYJHCg6Hw+EY4S8Fh8PhcIz4UvSRRidT4UomxdqokmgRr65XMQSUqD2kAVadUKVoJMW3G5N3Swl/z0ATXZwjC7qJoWIvCpyz8xjKPn4Qsy4fX0nxPmTs5uh3Odh3L1VGFSqy5eh4IdngHEnaVe4kY/vqIvav20GF1WnWMQql4TolUoivmsf+9Q0UOBMWpSFMUxu5KKq4HS+gFq0zngwpVUBQzMg+DNUHHHyv1jzO/R5F08q5zawvQfNRSaRFH2mFyfnaNCzEOM3FUtyjtp3mxkun/5+j6swo0LCPjnGH+ZFQcSYGJynmOKnGfmdtbwsomFhcsIfC6NjpseRBLmM8x58fQ9FzeWav2YNHMQv52XUsavnrX1qaifPo6iJmzDPD/V6K7a238XwH0HK1XBYq80g1JiotS6efbeM++w/e6e++AjxScDgcDscIfyk4HA6HY4S/FBwOh8Mx4uQ1BVKQe1K5CW6rEplgP0Q+8uY2yrh4vFK8Y3fIeswCK1BKBVZkHZMv1UxXyjTbXeQJmRj84MJKTc/hOfzo6mpsP76yWdXwvgndLmZDFsIflunUOgKqYAr5bbyYKUUTuet2HblO8uqVjCvXASrINEsZV3oaF5AdUraYaQYyzi/F+kmWH66KGoKVSCo/Sv9s8rI1eOcq1/UrymynuVeue1FmqAY+Zj0EHHenhlMT2m3y+b1UleW6BtcUOqGJec34K3trD0DP+weS1kSuczpwXYkpyNIHyoixPjCINDcFR971O3zOPkhFUfYb872QPjy+ejC2P3seq5WuNraCwgprRBtURpjLc2kNg6A17p/FIt73T8RP+qc//XHsty5UATWeN317uBJqCNb8y8zRI+Y5yeTvTnuhnwKPFBwOh8Mxwl8KDofD4RhxMn1EGoZy0hBsES9Ti0kKddU7SCl3ttDWuItI7Urj90ujEsmGpIU0vkslw5Da2svLyBldQXb64PLC7HK+iPQFPYyHXjK2cWzSK6X4HpNeyZjxy1hdzm8wdA2ypUXmyT6QMiqELjB0jQld7XYtKAIWj2N2s/aB4S/po73MW9IhR+gjMyeYPU3ZqdIcoBATtAcJx5klfAk5rxpJdcy4JtEhx2MxP35T0ZRoT4uJYoDDadRBi5tO6UlOtx5ewraon703U6T397i/a5Ey02fYshIyDhi/DscbzHZ2jhspLY27Cjsnz8D1PjiPsvDreyuL3aLvS/g6r2tLdd3fRlnrBf3K4bN+e28zkL/3ve/H/mWxr9e31v/5k+efju2+jzSVSoJpSjSYNObY/LKy01fdzyMFh8PhcIzwl4LD4XA4RpxMH5Ha0Jr2rQn943tmJ7XYV6u4Ek+xAo/Gmu8hWGUSa51rtrSlR6BcEGpjeQb/gupwITitR75ESHkF9VHW2/NrkfVYsbhdJT7KrLkfDmOQevfsUUNlhrBjhpoCNdLtZTQfLmhHr+sQLM1QYjteJx0vUjTGb1moPKPoUU8AwhQAjP3TuULwdxP+rhQ2SzFfa8xXpY/ow1AguznNRGGHy0aPAiblajYrM59NZvZe1I/96Pcr4hJSE8x+pwfDXnIsJmJyRAWXkMrLQQtl4ruQ4tpkzC5H4Uq5h8kmJaxeIF4gC2RZP34UlUi13jPPPh/bvJ6N3Avf+we/N7b/+kc/Hdt39/GcelHYPf/gemwXkB1+57vfMdudoerBFlUT3nnvXbPddksfFHMWY0uLVfIafo0JzR4pOBwOhyPCXwoOh8PhGOEvBYfD4XCMOHlNgfytZjQPzIaE/2wjawpbFBrk24i0pVbcJA/NKqsqSR3AGS7P4Zla2FO8v4G0DBVAz588GtuzQqW0kQtc3V+P7YvSrldwt5zVQZU7Zb+N1BFQjhDEMdcDahnjHfjSGbyghY60GdJGCms3rLFO0mN9YQYvWl23IU9Pbn+QErjZDBnSuLbq0cxzzDDIxpBGlheSkh7GyGhWQyBw5I2pFCqSTcqhKfmUdRLul+aHs6qHvS5gvQ6/o/cClzl6vQknYKrK8tgid+X9zTmpEvEMfWhwPXUOtLwgSWx3NGeSx0+Ga8YZUMuiCef/Q6zx1TKwW4xRi/l+8fCB2e7XH384tp8+js+BDz78ZGw3ko18BSnspo5S03fftWsFj15/HPuAMa636l+PPyZuR01Mniqa+1XXFzxScDgcDscIfyk4HA6HY8TpJjugBDQEzwKMJMBmbNY2pk+m2szaC8pNgSLomFFrNytA5aQI09rOZi+eg/ZYLBDq43crib+Ws3jsGaSvfWtDQL5i04yUgN2M49cb6SPCduGPpoq6KY3AvSx1oB7NoLfM+YpsFJRRQd9jHE9li6QSetJjrfgCw8M7w/XLdMBQsC/ndYZMtBZqKimibDEtooRUSZcSfSVtQlOdEEJIEmZF07TH9pUy25L+vLy2wuUxS9iUBwj2mmkWbNxHKVdSZ8zsZga5HIIfgK7RYnQ9qJsMx9vV0/Jgyo1TyFP7vfpwOAZl7rIVCzAWi3idLgdbyPJuF2mduzpSwHdra5jz/X8QPZ9//eEHY7trYn9++ev3zT4vnsfs6TNQSWlmabRPP44UVAUpbZ7b+UWzrArPpc2WlKbZJZRwGyKllsi4qn/2b4NHCg6Hw+EY4S8Fh8PhcIw4mT4yGaLyLqH/LIQ6pijWy/2YFX24xvcgAT4j5pI+CVJk7gyhOjOf29bSRxfnMcRcIBNxMc/RtlmqV8vom7BAPN3tJDsWiqgimx5aWy89NofDTFIIQbJeqegRKqKqDnsWtK1VKTFjmtSgFs7LUXuevgbMnD5WcMuqVyQ7lpmzuLaZqL82rNtvlDroWylFB8tY4JAUWJJNUzL0atgbL9AwVLSlQqX2Qwz3mwb0IrPLJUPX/kVqSr8hhYtzOjKuUzX1tLY/qRJKuRK5z5KJ2vyFZMJ3O/opsIje4SKIIVjaI4F3eSX30gYF9jpcs8XC+kkvUeRydhM9ml/c2Gv7zs9+En9rhsKYD6Nf866xXui/ej/STHd38djnDx6a7Xa72L/r27hdItQg73cWDs2PPKHb9nBxwvQYNXgCPFJwOBwOxwh/KTgcDodjxMn0kWEpJBxh2L3b9VObGUVOr1W8fgNdJ69QTI4qF6UsmOBUQJq0PLMh5Q6KBNJRl+evj+3HD6/MPly95/5GahVsobtjCUCESWpiPfkjXg3W/s9eQlIlDCP1eIZiONI/0iE9KpZ1SBSSPMKQQWGSoT+DXLPB+AjwIGIVmVNNc5iOytQfIDu8TyZKDI5rPqFECiGEHmNuqC75XRI+RvCFbjc7S2kGQ8VBLaQJeSgyZ9VoQkeZwnAT11nnQ3c4eU15TKrJOij7Ch0H0z/4jFC9l8g+8OvoB9LVFnyO1OhDKgl0tJnluavVaopz+uV7Px/b5xdXY/vx48fcJbz+5ltj+wd//cOxfQOaKgSbqNiATj8Xy98GlPca86PMp2napo5jZOoo6n3WT9O7h+CRgsPhcDhG+EvB4XA4HCP8peBwOByOEaevKSTT6wHMpqPSTd84/XC4iNdUYaeXx2ZhLZiHCCdKX+UZMpBrrgGEEC4vorz0m289GduPr7i/5Ryp0mwor5MsWvKoRTbHF3saMfxxmO9TTjudWAMoC5FY0suZRdxyOR6lnRN9CMFKkVnQK4X/sybU8m+zjnCi57B6X5dVXBdKsCbA4T+6LgJefCa8M9fDGsgy9Xj0ZV6v79Efm9WeI3s667DGRI5d+sclgQS6zEGy1XvIWjOsXvRyp1mDIazpmDUFWbCgDNX2zv7FTGPVPk4gNRngkJXLQLQwreIto+YyzTZuV0Eu3u7dZ3Esz8+i1PT59bXZ7AxSVkrb38P6wpM33rTHxnl8//vRr/lHP3vHbPbi/nZs39/HeZOW9tE7n8fz2LWxfy2qAGTZaeOtawqnFk8c+/ZKWzscDofj7zX8peBwOByOESfTR8ReETYT6sX2Xv2uvQJY+9vlklFrk3/jH6yjHkIIM5PJG/v3SOSli9nhzNRZxWxpkUSi4wmlkxKutrsY1m5Bc8wrS0fxpCidnMrwDcEWCjQSv6kiacGG7cJ02QJaGFd6Y2if7MEpubVfGZmtKQivslgU7MN1T+WcjJcBPp+itkIIoSPNkR2Wk4YQQo2Md46JyhZ5TszUT4SGyfJIPxSk9qBNVA8MFtWbdua23s6WidPMeqNFjkfDZp14VXe9yGTH/ojkGbRJOSF/DiGEAWPetOwD/BRkPnTGj3j6XlguIxV0s4qF6Yozu12F/lXoTyIezTsYvVw9iDTyh59+OrZ/8YtfmH3e+sY3x/Zf/vsfjO1v/u53zXYb0JOUi6t09fIySlQ537f1NPVj2EBDpX41QwWPFBwOh8Mxwl8KDofD4RjxpdRHyijkLF5VIEu1VyqIFEj8nOFS0wg1hfaThzHE0sJtJlMZYbuwCiGHKqjextCzTGPxqzOhe1IqjlicS1ihwOJ7pJaENutR6CwxHgVmI7MPlSgs+Nc0drt5HjtFmmkvy9HY/LGwlmSw4neNyoyiMDk2BT5GeSLbTRfSE08HXM8+cB6aNE57CBYIY/E42c7YX060QxCLUaQaD0If1ds4D9s6KpPY11yyfzOq8pgprqniAH93bxxxDSeFJ3KdJ0lILQwIvwDOr3bvd/qDbWPPOqFGfLkdLDw1IxdjuYBaqNEqADjGHIrCN157YrZ7fv352L69i8+ER4+iNafUvgyffBSppXMU2fz5z39utqP158OHsVje+/BZCCGE+3UsuDeonO8E8Drv0fuv6M/pkYLD4XA4RvhLweFwOBwj/KXgcDgcjhEnrymYSpNCQLKS6TDAqKSb5pB5PFbiVJreSq34m5KZWkdZWQIO8sGlrUbI3R6iUiETDHvxdS7R7xwn3zZ2O/rXpil8gZXYZfbuRHbzHg9ISeSRaqp2HWFaisnKr+S0lUvnOoLhuHtwy5poWcbt8pTXSTItkf7ehcipdp29tmkKvtVUP8VF0/UKekhn05wqzZB2u7gGoNnqWUbeH+Ml41qY36LPMNoiiTSVVVlWU9YUOFc6QyIPk9sR5v6TarGcH5SG9pq1j2vGKrBNbfuaF4fXZ2xm9xEfcpyTMQAKITRY50ixpjArrdHPZXaGfeJ5XCALOoQQ3kbF09ufvju25zj2kyd2HeLTT5+N7Y8++mhsnz24MttxjeHpW2+M7eVybrbb0eAJ9zSn116W/VQ1217vhVf7398jBYfD4XCM8JeCw+FwOEZ8KfpokMJMhlpqIB+UKDZDUTZm3XX1dKGnN1+Pki6GRZ9+YiVdy3kMHS8uY8ZjJ5I6xmP1LlJOVRl/52JuQztKUnm0QfNPjczzcAbsyy9BH+WggiC1KyQrMYFeNQ+RXqkqGzIze1eckcx2pI/yQErGdtV4+fbTkk1imKQ2hOYANUWSIpdjk5GhWo+ft0qZgPboU0hpNXMX48ws5mNFxAyFIt/xnDrTjsebC83BeX3MvdnKg0GpyPyiz3kOCWlPajGoOdBhU5u+nZY3DqDvSAGHEEI60FwJx0Pqc9JPP0fCBOUUgqW6jJd2KtnXmONXoJE//ORjs12NjOY3X386tt/9IG6nRSPpV04Dnrud9XLebuPfL168GNsX55dmu+c38bsaeu8S56CMMudUxvte/d29IJ7D4XA4viz8peBwOByOESfTR1OKBsViEamX9crWmme4zzr2FEKcny8CUSMrdH0fw7yisO+z5flhyohewiGEEFCb//wMtdhrFEbLLcXAzMsKFEMuIeW6jmEfi+PReyAEm6E75eWc55M5puZXtZAZqYPWFCJTGiD+boUx6brDhdFe9ilOl7aBUkeyensUGqwNIzA93dotQuHEXrPdJmYJF/N4nWtc5yEVdRX6YLJoJb08A3XWKNUI0DuA6jQdL0N1US3UxN+9XVmPjznoSlJLraiUOKeoqMoLq9nrzfVA8USqpjTrlcXy0O9MqTxTLBLbCWfRdoez+zPjY277MPWM6WqZ46D8MtxbqdBtLWg10j9PHj0w293dxyzmZ8+jkujh5dXYfu9DS1fbCg+x/fz5c7Pd06eRjvr89vrgOYQQwhmeRfT/4PzS+4eKtg6+C/mRIpmnwCMFh8PhcIzwl4LD4XA4RvhLweFwOBwjvpQkVbNtSX1uIe/qjkihyNGSp5/NrFzvBn6qS/isns3tdin4tRw8o2YOPnywHNsL/lZHLt5yy+R5U5qvJJa7Gyr6/bJC5nRlTgNwr7oPzU2sSY89BGWQueEt7fFYaXW9jhcwk/Rk8vsdqoPOwNlrZqox8AEfPKTTEkR6UO95X0MCOnT0UY7XORNjJGZzW89ne+ypOqTMbg4hhGrG35rmbDOT+Y8s4TbeF2qCMmB9bWeqiKrJDrPLmeFu+8o1FBr6cE5ppdYclYEzrFHsZcOarGqMnqwPmHUhqqSxWSvPB2P8c2QcKlQCDqygK13NMEY0U2qkEgFNteZ4rqzvo5x0NrfrNh989GHsAta5VCJOGWqLDPXNxq4r5Si1wHHomdndTWe4H/v81PXgL+CRgsPhcDhG+EvB4XA4HCO+lCQ1Vc5iouCYyioZ/jDcp5ft3b31Lj0/j1Kty/Orsd3WNnOwR3hY4ti5ZgYjHLu/uxvbA4r6nRVWQpqVoDZYtE7GgedBBqrQomnYL5mQnx2xPbHhoGSzFmU8d4ayKvOsG4wf5JJqXsSCcfSJZh+0IJ4pYEZfYaGPDA2DObQX3mO8emR7mqJukh3bg6fg8ZTRnJIWDhKqp8Ph8J40YQgh1BtkyZNKAJWx21h6sp6QbGrRR9KsVtoptAKlzVnsAykUc/1DCJtmg33i75RC55J2MvdzYR8lKSZFD2qpNxSY0InGWppGQdM0k6mMoJndzIo2vtVyzxQTFQLuaXwzTX1yn7lUQ9g0kMdT9i70JLPNrRFRQHuaFpr0RT/w92+DRwoOh8PhGOEvBYfD4XCM+JIezdN10EvQMMyyC8HSIxXUDiVC0uXMhl8Mx3b3McRtWht+XS6iAoD9USqiRrifQeVyOYsFqopch+Vw6LmXHUv/gpxjpNnEh7NC2UwGPTYydMPh8DKEEFrQK8x6TYUSY/d6I2zS4mpQQmC8KEpJhJpiuDrVPvpdN00X8HoWzFbX82N9MKjRBukraRgqjlgcT/vH8J6ZqPod9yFdWp3ZrP2modpETMUnYP2yLR3FPuTGAxweEzNLTxqvBcy1VO4F0q/MKC9LKbAHxRh9R4weTitmTmDPrwMwhTpl3pCO0oJ2U+D9wzFZr9dmO86bLQpr3t/fme2mvO07OXd9Tn2BY1YI9nbiw+PVPZ7Nb36lvR0Oh8Px9wr+UnA4HA7HiJPpI4ahquAgLZShfrvaVbL+N4vRGQtJCRXX6/uxzfCQ9cy1f+xPE2wfVncxPLx4EGusMwxlEb4QQshZn97YCYoiARH5bIba/K0UjIMShUl3pGE0wYl0VBqmQ2YWp4PYJJR7SinU2WeM2k3TF6RAbFuUUhij3oyRqI9wjsbWUhPR0tPoKMIUFzQ2lIVuiL7iN7WGP8cfSptSVDekHzaYRwkooiSxfaCqi5autSiggqGjOOZ2vGxy5ETSqYxdN2GNWqaiPoIabYFCin1jKSxaSnYYk8IkYR6zl8QZ7PlrQLmI48mtEOqJuZIfoRCncHZmae37VSyi12JcK6UdMS5MzN0K5cdEX3qi8Dmwl8w41e6ntzsFHik4HA6HY4S/FBwOh8Mxwl8KDofD4RjxpTKae80eBR9GZaD6tpoaWZQM4nBaKIq/uygjr8fCeyGEUIPjW55HrrPMj3Dp9LxltmdtWbg5DH1o6hHEv5bnlKNo167XcwK/TNmoeUVrMUGY0HAJQHhGI0lltrSMA7nhFBmnWsSQawIlCgPmGEflfHvw5w24ZUloDgn6ZLxos2mOnOtPw8RaQwgi2SSr2k4zrBw7lQiyIBrnED14Qwjm4jDTlTxvvxO5sclOns7k1XWOU7azVQSyg9vo37y/WzW4ySi5RXayzlccnhz+1O8o2Fct3jc1DgpeQ8p+tbAcx8+uLXI9wK5h8u8N1geWy6XZbvsimu5st3GNSYv3cSS+jKDUZD7L2t2p4/UFPFJwOBwOxwh/KTgcDodjxMn0EUMszWDV8G7yx/LDoRmpEQ2FCYb3ul3FGvBHMpoHSEWnCkrp+TC71WRGHvGvHSCL1WxPht2pkWUeDvtf/n1YCjuIhDRFlm8Gv4FU6QIWqkOoLkpYm+kKiocF0Pb8NagNhPxWa/Pzd0kZ9SpdpVoVfxgpoXS8ZX1/+F7sUV34reVFlCjf3NjCjC2uxwxZ9pqBPEUFHasIwKKDk14bwRaqI/Re4DGMtwWLOYr228z5Hh7IItc0HhG4tupvTdmoKW5H6asUsOO9Ranv3piw+Bs+VgqRz4sd/K2V8ru/j7L3FWhoyrsz8U7hM2GF4px7UmYzH+LnWiy0mfD8OPI4nE5cfrX6d3vwSMHhcDgcI/yl4HA4HI4Rp2c0TygIQgihQ2i126FmuFAbDJl2u6jIKaHmUOqGxel2WxxbaSFQFj0olItzqxrooIiqu7hdA3vKvrdZnKSguLK/kOzFAlmv9zdRHVVKsTaGzZP1/I/VRDf+FdNZoYmtwGX7QFURlUSSoWutAaeyLoUWoq0oKIZCxqFARiypqVYywLmfUT0doS1NMUaqlBLxHsAQkVbYV+fENser7+w8tAqm+Fvni5jBnxcyXoF05zRFGjCv2W/drgBt2OAetHNKFEsYI1I/iSb7GjtOWqPazUhP9R3HZDpjnteZ1OeeegZU4bajV4aMl/HywDESu107QS2Z+VDa5wjHi/1ORa2V4JlgrD6lakKKqWwpMRwrWCTK9f4GSr++an08jxQcDofDMcJfCg6Hw+EY4S8Fh8PhcIw4fU0BPPYx7i7Pp98zNI6hrHVW0v922nyCv5uVlp+usV0Frnmzs/IzLgMsYQhECaPKQTPwozmraooccUavVmQ8auVXykiZMVqAV+9E9ttiXMhV53LsPEzIEbU6KNBzHUL+T6APNTnpGtLCqpJpZHyd0TfhZRucUwaSnNngLw+CdRdwtD2OXm+tJLKowOHjeLVKeCnfNPNTZKMT62His2SylQ113ZCzt/u0Ldfhpjlyk/WK/qRyLwTKHVGRNae8VHh1VjnlWoGubeVY1yCvnsi9kHL+8jvjryxzjRnOrDYgc7KHZDbJKEWXdRKsmyS47qkYWNFcycpY47XI9xZX2B9UUS7tdrNFfCY8hwGPrsFMZTRrtWRiKlNZP39VhapHCg6Hw+EY4S8Fh8PhcIw4vSAeJY0StVBGSnndMX9RkykLPVYnUi3zOwiTNVOZXs4NfZiF2qBUcTIbUsJ249tK8xYttodQr6/gCywyvDRAesdsYoyjsEehYWEzUzTNbjeAq+K51omlV3jNiiIeROWzxgMXn1cY7z1JqikMCI9gycjdbikDjp/P5yL1RbY650oKQ6frmxdmn7KL43p2HvenCVQI9nqmGLttY4sY9sw2r2NndxvxR8a1nqGA424TacxeKFYyEwUotkGNljLKcZkNbuc4v8vNXKGvs0hDM9ArCTPhJUuYmbekvVpL05JypdlTir4W2u8J2XsmBlEDBwy077GiiB0yrnu5H3corrlDQU5DXcsc57zOIDGuZT5Q1srT1VqAJLTMs3E4/HkIIQwT9JHSRW6y43A4HI4vDX8pOBwOh2PEyfSRMSCWMC3Fd6QB9kRKiJFSMAQM8wYJFTNme4LCasXLoCygzqlRvEyyjtnXGqqDpkGWajmtrmIxOlWH2KKBoJL2xutwwbHaZE5PZ10WCLNVyZIajwJmhdpxNTX3QSW0wlux8BeppYynpD7RVG8lpJ+s6qMqQIGABtBxNWor428cz+G1N94y+2R5pG5WGDvNmDesAFQphRaCI3vKkF54APqSpzP6kFNBJRQdaUNwDN0eEYD7jBSDqnM6UrOkx0B9qvIHyh2jPuolA7wjPYn7VjPmMZbdEPs9x/nteSNDgWYy8+1Wpu/GB36Pk8H9eESCw2cJnx28ZmvxeSnh2UzfjDRdme26CbVVJ8+vqezkY4UUXzlV+UR4pOBwOByOEf5ScDgcDscIfyk4HA6HY8TJawrkw1rJOh6QYdi2lL3JMegjin16o3a1PCN51e0mrgEov7aFFCw1vP+0n3S9Az+KTNRhNr1WQBnY0FpZbNeCI0cfquJINjH6Ry6+kQzRnpJUvMozkfX1fM+TuxYe2xgCMXu0U1kfsrlZ+dIYLsuaAv7sUnLS9n8QUzV1OMyDhxBCjeq4eRb52w79uVhYb9wd+k3OVytIksqtkcE6K22l3ICMWK5F5Zp5jr8Nn0+Z6Gxu9mGJTMulT3PIPb/SdTgaFhmu/3CmeQhWhsrLJMthZu2B63Ntb/vAcTbPB0yOTM2BjH8zK7DK+kc4PF4yDGa/Kdn8y9/CmoKRuqMaqxjzJDDOqrC+UFR2DdP4wHeUz4ZJmHWEML2mMHWIV/VkVnik4HA4HI4R/lJwOBwOx4iT6SPSOokaldB4gxIs9SulHzGzmEk3SDE6hvSUJi6WZ2a7po6SsYRSNylYtlvH0H+5jGEfwzntQwuZWpbDtzWfLpJFKWc+aNgXj0fjIIb9ba9UCwp/gRpJRWqaFpH2GDDGO5EMMruYni9JaqcEQ/8dxx+/0w9CA6TMlgbdI+O62fHc43nMpA/0/eEcmCNUJ7UYQghbhO3VfDG21/DjDSGEszmMfjAHCuEiOkgzOxSPU2nnHJnsM7RryqllvCjtJBKRz9JgqGCmudJHyJhOzLyG5LlR819k1tP6Wh4RXRP/7lvSxpZKDQM9vPl8gPQ4lXkzYZqkmcrBFC6EWVSm8wb3E2Sxms3NZ8x6HWmiDW7bRqS5M3r2UN6tcxwVGphIne4xysPBdmKyvO0e/Jtj9BUtmj1ScDgcDkeEvxQcDofDMeL0gnjD4ZAmBJtdSZpJ6+IztKpretHGbZQOWW9BCwzMCNSQkhm6WOUv7HbMXjSr9D1DXN0n9tUUvdsLa6GsgGpAM3mNCovqifSwciWEEJKJwmb9XnVCFOJDOD0IRcEAmmyGRPTGX4G0QovxUgVUVhyeVr16NaDrpI9Y0DCEEAqkv5NqMWoVoQQq+FmQ7umF5thu4nmczSLVtRKaqW/g18trIePK60b/EGYCp6KIo6KHmedKTVFBYxLKRf3F+ctxpXKulwzajhQi9t9TH9GbO4AiLaZVN0a9x7FTkQxldTglvX+MWpGeDur9wKJ15v62x6PiaLWNNDRnYSKeFTynHebUSjKf2SVeTqWCjBfz31Gm8qnwSMHhcDgcI/yl4HA4HI4R/lJwOBwOx4jT1xQowRIeeyrrTitSbrE+gKTQUJaR4ysl29OsHaA050bMeFL6sYJzbzLLHy4WkfsccFLkKVUCZ/+e5vu49tCyEuqe29Dh7F1b+VWyesFbZsyalXUbctJG9qtyNqwD9MjW1e1SlGFNIfHjekpVWO/lATxv0x2WW4Zg50cF+Wbf2H22feRpF4soRd6ub+NvyrrGGY1swCdXpd1ut4kGK/lZXFNo6rXZrsbc5aG1Oqgpuso1BVyzhVQHNRnvRkMq2fg1CWpWFJX1Aaw40PKF/HuqawWUVfJwe1nHaKPKLWW/IYTQQX9JYx7D5++ZxuBneT/L+TG7n+sQWl2X9xbXVjqRBPPwDe6FHddRpRxxjXu97CE9rq3JDvfjzGsHXVdi+7SM5inx6bGKsKfAIwWHw+FwjPCXgsPhcDhGnG6ycyKOySoZ3bHuVFHEsKjeWWkhQ+HExpcGAygC/upeOHdGQwxsacLxafrIFvITKSCLXwWG6iJxpZkIQkJmDGuIu4OEd4YCb7kWbkuZSYq+aqiJsJvSYZUWMsuafsY9PXglXmUxQHMeakjT0s8YPsxyPGaOb7fRxISZvIszWxAv7ZG9yy5IYbNZRaOfuM9yaemQNWSj21Wklnqhx5hVu1lR1oprLpRTNcNvYbx1DgRkoWczjJf4TlNeOlitI45lKaw8o5Qc11wLSoISC5R3y5OENFGP7PwOYmj9j9QUjwPllAl1Qxm2oev0oWAyg6fNsXgU9puy60E8zgvM3YoUcD9NlyY2BXn6uxM+/7uERwoOh8PhGOEvBYfD4XCMOL0gHsIvzXK0BaZiGLrnwQpQcEEVStNqaHcYmpVIyoKKGfVTYF30dhmplwQheCf7kLViu8gtdZMjm9hQZUIDMByuqZRCOxUapw3g20BRtEILNTi/EjSAUmI70Gr5IqqHKqFNOqgxqCRqQSO0O0vJUHXTTWSDhxDCHOe4vr+LfajsuA5D7CvpQNII6m2RIAu2KOP5Mcs4hBA6iNiSBWk0lWFBUQVqqm/s73IsqDqrcK5pZ/fZ3b2I+7O4pNKYLGKI7OtUxotzgoUUWVCv3tk5uaFPOpVl4nHO70j5aZE50ph5yWxuXDPxDOG9lZfIxD7mr0yaSTPAkYXMrPbZmZ3jG0ghM4xRcx+pyvnCKuwyjOtqFdVx+sxjYcwVinGmOr8Ak/WtFCKwRwl/TfBIweFwOBwj/KXgcDgcjhEn00eka7p9M7+xNVXgLYQQKqhIjF0AEq4YmodgvRaCobAkAYUxJpp7Jdqh7qB13l7NdoDF++ZI2Nmriz8w4QaKBlU7QDXTI2ZuQFup6oMn0qCvdwhxQ7DJRVsk+DE5LARbEK1ZRcpjLTQALTO326i6YVhcSbGwCjQa6xtq3f8Gp9jW8brvGqv0YJ00zilTlGyrfhEIwWfx/PLS0gC8Zjucn9RlNPaQXU/OyW5HrxF6Pwyg4dZ3t2YfjssG9NPdxtJyGWiiiwcPx3YqCrQtxo/WuRmui96bvJ4F5tpWrGSZlEaa7/LM+psMCWkdJFTCvKOtp9V7xjJTroUp4Eh7XKV9J55FSvGQgtrBW4FzX+lqUt6mrqbc6/ybP6uWxrZY3rQS0uDvSJjkkYLD4XA4RvhLweFwOBwj/KXgcDgcjhGnrykEFrUSPiyBXy84tESIWXJ5zJSlKU7TCIfGAlw0MFHDFlPRbjqrkIYwpggVupoJR87sSmY5tiKfZUZyPsfvCPlXw5iF3r3sxCD7dOjsBryumrzU4KHJ+c4ay6WvwOdS3lg2MiXSyJ/f3t2M7QVlrFJkroIccYD8Ur2XlzDCKenrrMXHdlGuSl9mFgbsM3stWp4H5kMhhfPoF1WjOF5W2rnbUYZKKaUsFzVYE7i/iWsHlEIXsq6RQN54v45rRJ/f2LUHGijN767j/nJONech5bjG71fkwWUsRHmG4nbLpc0UL/LDGfObPTkoJaWHs4m1DzTdoXGNrgH0A88Dn8u9sJcR/huk4q3O7bi+MOCccjFVnldxXDf0vtbqBWaNjv3WtQKuI/DzV5edftUsaI8UHA6HwzHCXwoOh8PhGPGlCuJpiMTiaMzCLAbNaGalrtjewpO3VeYHu+SIBlUiliEETI1EzB5uvxjWSzDk0nA1nQjhtBDZYLJR4/EKkWLWyIKlNK1G31i/P4QQttsoM6Tfshb8Y4G29i7SLrO59al4/Pjx2N7cRpoiyaez0NcoRkfKaDazkkhmKtMTuZL/QZbzGILPQI3kUux/XsaxJA0zhxSzkH7T35jSQvWPLkGxJbhOmqHLjFh+p97QAdRSyiKLuEd2vb1mHSTPK9BPuh3nxOeg8la7aRk3KcSiQCHFXGTEuGaPrh6M7USuxRJ+Fn0Tx7jJxFe7iBQUPZB3bdxuKVnCvE5tM53JS+aFRMkgzwRTlO9YZjClsCmfS7Hfiws7XnxebNfwZT4iiyXtnuTp5HZTktRjtJDxYHD6yOFwOBxfF/yl4HA4HI4Rr0AfTRdXo9iHIVsuahOjQugOZ37uRT6mvnz8uBbljynbdeSspsIxhqRKHbCQGy0uZzMb/nIgyFJtleIxQS+K44EWWu3sPjxdqiy2sh3PaXl+Ebsm1+wWIS8pqPpOKAt8V8xiCP3pp8/Gdinqo5IZzcjkVYrn4cX52L5cRJXLWWWLsKVppD3Wdey3yXZXxRmUNleXl2N7u7M0B4vEpaTeOjsHKIiqQEGtxJ+BaquiitvN0zhXrtd2n20bz2lVx++GzP7PxkKKO5wHab0QbMWBFyi2l6OgXiX0UYHvWmTCD+IPUF9exe1QPHFobJG5ZofrNKEg3AotW1FZhnPoxX8iM6rG0+gVQzcfoXimPA+02B6rHKxxPRuxkqWkiofQKgdTfe+PKMYsDlOVv32/fXik4HA4HI4R/lJwOBwOxwh/KTgcDodjxMlrCsanWCWphndMJ9rByFCNXGya7gvphIxVaTJbSXO6cqKRn5mU5vi5nl+aHs7OZIboy+OhEiPXCoLlGRtwpKyMynWDnXCTNaSdHb+Tvs5RDXU2Y/ap5fM3m8hDN+BHlZsvIJ3bwgiHMt1eTGMSXIwM+wsta+bA1vDYls/f1THTeIA0dLugD7NW3IxtY6oiZjwD5soyjesaWoWXks2+jP2+G65tX1FplaixRjGXNROapRQlrrNITTdYP9oh83m33ZjteDzy710Tt9MKvzn2abHd7c3nZjt6Xyd9XKtJZR2O13N5Gde2rh7GfTpZt2maeC0Ws+kKxlzz4y2oScKUJfM7rRCbTqxLUCKrvDz7wOPpemTb4lqUWJft9Rnz23l/HYe/K/9mjxQcDofDMcJfCg6Hw+EYcXpBPONhI4WsTEbgdMg10FCmYRGpuE0tiq4MH2TwNU3EeYM/1UGy2WmENZDOOPxOzOT88gmv6a3IEefIHm1BjWjxPp77BuYymw1khmtLQ1B6SjnvXDx0C5jLZIGhvh3Yc1BL1WWUhta1PSdK75Jl/C2eeyPZ12HA77bTBdBaUHbM3u3F2KVlgT3SmJu4TybcQY7CgCwgWGpBvIlM0EIKoBnpIz2MRdrZYq7wOvPYnciIM3BdM2a/p/aatcguPpuDJqwuzXbM2uZ9wrFbSIY7M5UfXMTj6e3D7PySEkuhELegt3ifUb6cC2XSYu4lXezfHm2Cxxb92FMtIhkOQz3AaTCUgFYbICftWtsH+jeTZtICgrvb63g8Y/rz1amfKQOer3pkjxQcDofDMcJfCg6Hw+EYcTJ9xCzcXuIThjHZkcJMA5QtXJVnnFdo7GMKprNDkpWYHv5KatGF2TyGisxmHQYb/k71gcXy6FcbQggDas0z47QVJRHpjBW2u7u7H9tUb+jvVsg+Xc4tfXG1iGH3xTJSApp9/eBBLHrG8D4XU+sO9BYVKztkRK/Wd3YfqEoGKq1ae04cP1NkTtRHDWlHHG+NIoGlFBjj8S5fxOJxV0vrJZzgbxYaTCsZB1B2HK8z9SbGHL+5ib/b41wTKRSZ4vzmOTwwKqF4QqT5OqNYstc2r+iffZiGmQuFwut+fgYVlnoU8DxwX+SpPR5VQRvQiy9ePB/bZ/NpGoc38Wxms6Vz+DxnJuPXPhO6FtQSHhBVbilXnjuVWzXmvlLF9/j76vGjsf3k4ROz3Q5z+eY+3t9aEC89zASF/kglCfN85bmrhDOZLgZ4CB4pOBwOh2OEvxQcDofDMcJfCg6Hw+EYcXqVVEj5OuHI04LcYvy83kimZbdDG/sfLkz48m+sPSTw4S3kdcYqlqQmRUkWMnDFBXxkU3QoLaaHxfB6smYyJUEcRH5GfvJ+Ffl48reFZOhW6OvDh1dj+0IMbq4WkX99hEzSXDjyAj7UFxdxu1KOR2MXettuVlEyW5Zvm322yLC9g4GPrlewAutqFSV+t3d2jYLy3B4LUDtcs83azkkarjx7Fiu6LiQLfbeIfa0wcdLludmuL8DhF5B5Chmcb1FFl7w9updkYkq0KLEZ5mGuPt2xjWWIPU/xFOtPNNaxnL09NqW1lBjnsig3h5SVWeSJzNfLizgPed/ewwd7EBkrj83+JYPl89mnwUhSh8ntuKZ2c2erylJSSnk9/ZrXIrvOQtyn3sZ1g9nSrgMlPA8+HHW91UjYWVYWz5G9ChGxrxnXUfcWKF7N59kjBYfD4XCM8JeCw+FwOEacTB+xoNcgslFK9CjJyzIrLZyDAhmqw+FS04m0kL6m+N1cKJ6iIK1zOKx62SdIa1tmS8e+aZ0p0kmMADMxQSFlxDBUt+vRP1IolJ0uzq3UcQlDk8UiUgJzkS2SIqBBR9/bPmwQ8n702XtjeycmNAvQUfeQ1JEK0ixoylh5LR49eGi2e/gwymKvIJEtP39mtmOfPvj4o/i76zh2M81SBQ1mzGUkAzzHGBWQg+okKCH7rFG4rbNMhMkAr7fM2o8TsWnteHF6MBM+yL1whyKGz55fj+31RjLKccD5PM6j8/NIiV3BgCkE8bHmz0rRuvMLyJzhkd2IcRAPUqK43WLA/JSUY1KVSUf6yG5HmskoO+XBxN04/oXMFWYhc4xe3H8W9xejH8qmN7f3+MJSYmeUvRfxd67vbs12lvGBr7P52b3yDLHFTP9OJanhleCRgsPhcDhG+EvB4XA4HCNOz2hGaKb0UduimBmLj8k7Z5aDCqIQAuFOLmWstgyfqDBKbTjHQl0JC3DJdvOSWczIxM4OF10LIYQcMSoLZiV7q/z0ZIjncb+yKix6DFTwPzCeCYN4CsBHIOBwpdAhL6AK+vCz6M9LBU4IIWyp/IDCoZZ68KSMGGYzc323s+f3+mtPY/+gWHp2/Quz3Sd//q/G9htvvBH3f2qzQo06BHOFgpf1ytIXVBlVTyLdMF/YgmUzZO/mJWkFyThFUb5+IsM6BJtp3Bof8jjetWR2b9cx83kHSvOTZ8/Ndp89j5TD8urx2C5m9pxyZOy+2MT+bbs4h4bM3meLGe4ZiJlub2wffvXRL8d2D+rzrdfeNNtdgobZ7KhUi327RcZ3CCFkKEK4fAL6VDLc1/dxHHpQU7PS0kIpFFX0ZZnNrFqLlBGpKdK5WnCR2djGozy382EG+m6eoFCnUIjre9zfk3SPZiYPR7474XAT8EjB4XA4HCP8peBwOByOEafbcVKSIPwRC6CloFceXtoEoCUUHKwp38AzYbOzoeIKCpOGIZKoQ1ifnGomVaXMEVpP+Smw+FkItn6+2UeUGWFChaWF4G5Qiz2lUqQ4HLqGYFVAtD/92Tvv2mPfxMQvFkNbSfJNDnXOZ89AX0hdQOaRvfFG/PK//+/+27H9v//z/83sUyI5aIHQ+umTR2a737+MdftJQb3zi5+b7S6RSDaAFmJSWyZJaR1ogA4UD5O5QrAJQVQpBUkwY0FIUwhOiquxBv8Og/n551HJst7Z5LzPb67j8WbxXPPKFoJ7+mZMEnznlx+O7U1jLTN/+atIG37rO5GW+9M//dOx/ed/8a/NPmezON/efivSd9/91ltmu/Nvvj62P/jFe2P7b/7mb8x2Beb19//wH47tDlTQYmEL+VVF/JveCqlQpGUZx4XUbraX7Beve0c1YCX00UWk3+aghWhFq94PV+j7g6t4zUp5ot428TzuoKrrt9ZTg4+VYWKunWrHuaeefEXvBo8UHA6HwzHCXwoOh8PhGOEvBYfD4XCMOHlNYcss1c7yYTl8eCu8Zh4sLSf6GFm6AzI/mQG7FpPmFYrH7ZrIqa0bMWxhQakk8qPLhe3DDKRfYmRc9G42uxj/2QyctCpSuezSQJq7XFhOFN0LDSSW9/AVLqXI2d06SkOvr6/H9iefWFnf4ixynWuMSZfbNQqa+PSYBU/esLz/5peRr/58FcfrX/zLPxvb3/tH/8jsM8Nv/Tf/9L8a2//mX/1Ls92vP4jyxm+8Fbnr7732B2a7589iHz768NOxfXsbuXmVI27PcN0x4LvargM9goFLAQ6/FxOULeTCDUxM9HgvILPc7DB3kZW9Wdu5+/Txa2M7g7x0I5mp738c1wp2mF/Pb6wkuFrEC/oX/yFmgH/24p+N7Qu5Nz/9PM6vh49idvmf/5t/Z7ZbzONYfgsy4keP7Ly5vY59/cEPfjC2//AP/3Bs0+gpBLseSYllIxnz93dxXrPQ3dDb7P4Uc4LPBFY1eNmPuLZFSSqPnYni8+EyfvfmZbxmDx7YSgQ91kOan8brqXJjPnPgDTTpw6zfdVhIUK9qTSH4bfBIweFwOBwj/KXgcDgcjhEn00cNZJClFgtDqD3Ha+ZiZmmTCxSWM9bLMEeY55aamoGu2dHLeW3DqnrCO/Z8bvtQIE5jUatjPsUDwtocoWeRSB17ZD02LJxXqLwR/UFfmdG8qy0lQJqJ/Xv69NJsx8zey3NkIFdW/teBAvkMUrnz0obg//S/jNTQzYvrsf1H/9n3x/bf/PUPzT7/8//0P47tCnK4737jG2a7D959Z2y/95OfjO3vf//7Zru334jZsi+Q1ZskKEQmsrsORhqkFnet1dw28AZhBmwu9N0Ajo0FDjeFLWzGIm/ny1h0jr7H9I4IIYQ1qLyf/+r9+Jsyb/7kT/7x2P7ZLz8Y28uPrSR1Czq37t4b2xXk2fTQCCGEpIvX/bWnUXb67bffMNv96Id/NbZ/+uOfje2zwtKTD6/ivFzg3vrgg1+P7UK8GirMUT461F+cEsscVGUuFGlhpKco4Ci/S59t3sMlZOGbeysjXmC6XaLQ50Kq/H0Lkt7sLI7xD3/yM7MdmPEwvKL/gWLQwoCvZtHskYLD4XA4Ivyl4HA4HI4RJ9NHnbGps4oLFilD3bBQKc0EyoL2l4aSmdkuMSKsE1I84g+A7FHSBfPC0gDBUEbxnJglPMjqfZqSgor7pKJiSDFGc4Su3d7qf/zuDrXwqV5iAbYQQshgDHG7jZm8RWJD4e88jsXonj6JmannF1f2eKBHcoxRWli6jZRDgtD6CbwRvv+aLWB3jrG8BbXxRCisP/2jP47bwbbz3Z/aLO3ie98b22+/HbN6P/n8emwbK8dg6ZEEA/vgyno60PfiGn04u7C0XI5MVw55ObO/Wy3i3xV+96yiSsbO3U8+jUqdN1FYLpFrUcPKkt4krz+5MtttUdTwyeM/Gttvv/3NsX397DOzz09+9Ldj+1tvvY3tPjXb/e7v/H7s6+M4lp/82hY7XG8i3fL0aZyTZxcx+7dvLa9BGqfCuWt2f04FIca4FVXkUMf9etyrXWIpxEtkNC/AW53jWg5CHw01sul3kQ4sUvu8qVDN4HXMyZn8O34L1smQR3hGaQZzMkEzdfL5no3nb4FHCg6Hw+EY4S8Fh8PhcIzwl4LD4XA4Rpy8ppCT1+stFzjAGISsV9pbbiuB0UiCffIkP7hNCCEkWB9gFcWhkrUHYxSDfUr73stYTZUexpC0dmKokUHWSpMd9bXoIXecU0Yncj2atFyA65+D0/75L9+zB8f7m30QD6FwDk40x1i2KyudnGWo7IgxKhK7XkTPkBl43t115KTPKst9r8BXDzAHEqvq8AA+wd95K8pVNTt5mMexfIw1gQ8+iVLau2sxbEHFTFaY3Ul27Dl47DnWTyqprhuQmbqF7HeQNZ0zyFCZ2X0+j31Y3duM5rffxLkvY3/usIYQQghn4KSZDbxr7XzdGu/x2O8B99IyfWz2+ePv/Q9jO0EG/+Mru7by+qOrsc01tN///e+Z7YYQj3FLb+8scu6Pntos6OU8cvsl1rl2jb1mvDaUoaqXs6lobJ5fdsMKUmRW251DKp8u7drR3fO41nKPm+TNb9qqsve4F17A27sUWWyoWX0gfpywr9l0arLJfB7EE/4VFa4eKTgcDodjhL8UHA6HwzHiZPqo3UZaYaZhDCiGDOF0KRm/lJmFLoaE+RD3GWqhpmBkM6QxJNXwnrK1ATLPRGJKk8WMCC6HqUopdE9iIjgab5jNQgXZ4gwmNmlhh5nZi2CtQoeiaeczW7CMXsmPQSNUhWZVx/ErUZ2wmts+tE2kJuomSupU6kuToj4/HIL3knFaIOO6gX/3ttVrEfv6+V2kf2bwgg4hhBVosB/96Edje7eO/das13MUX5xBfqtZtEaKDIMczQpNILuuKhj4LGwBtDNQYh2y0q8haezFh7wCPcn5eSHjsMH5LiCZvXpwZbbrQOJWGBf6RKcqFwe3N6AP9dZm1negcniMUsZ/Not9evA4Zkj38B4vc3k+YM7nuM/SzG7HeU2mhDR2CFaaPlDaqdcWD7BL0IkfUjYvXPHVOeYArvMg3svLknRuvBdur8XIC5e6wLj0vM/EDzxgKtOXfo/WfkX+yCMFh8PhcIzwl4LD4XA4RpxMHzGbrpUa8gXpI4R6mYR9GTKD+VUPtUMr6iN6ujZr/JD4I2dUrIBCYbj6sk8x5koRRhpfZk1BRh+GAZnAYrxAymgBxUwjYS01WluE4xXomacPbebtFaiEAjQcfyeEEM7gGVyBtsoKLfIHtQPPPbGxZzbEkDfFuW9AK2TBjvEO/2vQp3g2t1TLCxhAny3i+YnzdeiRoUkvCfb74tz6gVMplYMOTIVOZO35DpnAzc5mx5ZUvOC66zktoD66exGPt0bW6yAyLM4BpktfnVkKkRRNiQzpXDJYSd8FKOJSUrGDnZMN5jwZxFLVe+gDs+6z1NK5y8s4DsxUZrZtIhnNRBpIQ6txCYoY4nhDameO9YDBd3J7F0mcKw9QRLLCs2Iu1+LNh6BwQZFeCeV3BZovuY/Z/VK7zwg6O6gLkwm/5pd/h5Mw5eU8BY8UHA6HwzHCXwoOh8PhGOEvBYfD4XCMOHlNIdAPtJuWOOXgtNPc8oxJBg4SNFezgv+t8IxUUzX0ShZZLE1RSNd1YnpBgxRKtVrwyZ2sKTBbkDLKPdlikhzcx3D2IYT1NnKQu3Xkk+dYF1mIt7SpFAnpZCr6syUkkqb6rEhXzfhRgljbbNu2tms84/HQv/nc9vXuPspdl+BY+8ROtwr7sSJoLqTv3fNYRZQGQ5Qwnkm10gLEOClpXSsYFjCkqfGdrikwcxkVazPJvj6/jBwyr3sDTlsV3fNlXA/hHNLKrxnXi7DGkYq0k0n3zOrV6pkWqGAMQ2K9z6jopYQ3Efk511oyyDJpkKNrCry3uLSl1YiThCVFY1tXKBJm5+PUk71nQvz79YdXY/sxvJe7jV0EePutWM222MX5Xsm9UOLc+YxJ5N9xPkp4nTIjh5d90O5NRrPdLtcf+y3wSMHhcDgcI/yl4HA4HI4Rp5vsINTL9EuGKwhVEjGK6ZLDIf0O9EUicr0c8eoMBhaZ+D8zdKQMNZHiUCnDMVARxuJX+pCItPYLDBrOTdBMSt3koClo6pFnsa2U06KMUsDl4hz7SGYqaQ7E4KnIZ0kLFFk8dt/b8JcZtgmOzeOpB+x8FvvH4oS1KHNb0mAY4+vPX5jtrl/EYn5zeEjPIGOdlSq5xYXmOQh1wL9TFhpU3SLO0ZiWDPZuKKpIm5xfkJ4EzSE+0Sl8yZkxT8OeEOw84vgX4uWcl7w3MMbYR41reEqcG1q3beANNPB44kPO4efYDaTe5H9So8skfyR8CGjItonS6GSw2+mcjzsJfYTr/vjqamxfQoa6kkKKjx7FYn6XxWvxN0VS32N+sBCm/jtO36WB9y3n1xFlKcdVh+tVPZ89UnA4HA7HCH8pOBwOh2PEyfQRI7tc3iXMwNug6FMteoAOFEGNTFfuk+biTYwQc4GCc2lpKZlbKF6GjuoJG/8yzLKZfsiM7I+oj7BdJ/wR/+5MESrNaI6gmmZJT1gpfsWCbwx3m41VC5FKYE36TOr+F0ipzDW9EqBiwtJjoEakr6W5hihsliuFFfu3ggqrra3yJwdtSK8LXr+zuc0kJRVUb+MYpWc285nqqqyiZ7c9pwZ9ypBNrMXaMuw3W8BbAdeJGfy/+STujymVyNylkoVUUiFezmnODO54LYb0MJUUgtwLxnNEqAdmxk8o4kKw42+URNxG+BB6p/SgeDQLndnYpJuleEEYDOcXj5Erm4IOLmeg6EDzLeR5wyztJ6g+UKNwZQghNBgvPh/2krknqCHzvJJ9kozXaTrz+VXhkYLD4XA4RvhLweFwOBwj/KXgcDgcjhEnrylYDtKScg0oc0q37nfWoONygew+8uJoFyJTm0GyWSGLtk+F9w+x4uYwHJFg4bst1jJyVoHtLZfLBO4e5B/59hBC2MEkZ+im37fkho1kFjy9msHQ7zoBebqsrGxxgQxbXjLNZiWX3uM8UllfMPwk5JIZpY6VPde2idfTZN5qtVhc9xW4WJVsct1lDj/oFBnye9cc49XhXGtZr1hUsU8ck0qkzAk0g6wOqr/LjPwSMuKLqyhh3K3uzD5FeVjqW4sMkteGstMkt2sKLSZsgQqxlNL2qqdmNj72b8WghZVWMfx748B5w+UGy3fLGGNcuf6k6xpmzRBraK14OdvKxzyGrG0xmxtz8tFVXKe6WL5h9nn0+MnYXmB9ocjstdhgLS/heoxKUjEsemmmYGSoR9YUkmNa1gPwSMHhcDgcI/yl4HA4HI4RJ9NHw2H1ZgghBLItO1AHn93YzNRHVzHM6lF0KyniwbPCvqfKOYtpxc9pvhOCzeJjFrQq6qbkWvxcqZauV/3YS/QSljUTUthSZLakFSjLYzbrorLmOZSXDpTwSh84RgWyfIup7E7ZSc+VFFlLigDn2sv/FiyKyCKGQSSWm3t4Q6Pyl3pfkwa4RME/KmF3G0sdFDgevaV3a0tpDpCN9tPK4ZDzeuD8uo2lujbwMh9wey2QfZ0p5QTDIt5LVWkNfEgf7ZA5W8iczkGpNKRNjCmO0JM0n8LxCjHjSXijcd6IzNZIRVkcEvOrl1R4mhcNPCf1GMbDKJmoIhCCpThb0F57xls5pdvxGL/7O78zth8/eGT2ef316DtNc6aht5P3rELhyOVV/J3KPhNM5QBmlGNMUpk3rZYS+GJ/lfp6RrPD4XA4viz8peBwOByOEaf7KVDNIZxMiXBnh3D1+fWt2W71NKpzKmbqISzOChvW5qBNGoSHqvxhsbYCobBmDpIm0rB7/B0pakVV0Q70Vib+AGUej0eFkdJHpLcYHlL9cndnFSpzZDSfUYEjoSKplrRlwTI5Vxb9Gw6H+iFIMTNc2+Ewi7DXByqHXjy/MdtxXM1vtrYPC5w7rx+FUm1j91mvIp10Btpkk6zNdndVHOdFGn9ns7E005kpyI++Cg3DcWEWdAL/biqyQrD0UdPQH8Bes4JeJbieSllst1STxXM3GbFazx/XNjVVI4VmYuY/2lr00VQcwCTiNe8aew+TqeI8HIQqLngifbxntAoA+8QMaWa4v+xrPD6Y7PAY3grn55IxD2/0HnOt7i2NWdFX+ywqBbXw54BHDu9pc52P+NjQT0ELA74aeeSRgsPhcDgAfyk4HA6HY8TpyWvJ9Co/Q+gaRfPvpVjb9U1MUHp6FkPoDA4N2Z53AUIp0DXb3Va2YmIIkzqUDoHqiQkfWMnPpcAYQ9kaKoZqsMNH9dEaIWp1JrX+sd0MYXaLQE9tI43yivSFKqNYj59qk8z2gcqFtpZKYkDGeu6I72tQXVq4LaQoRofzyIRnIktR7zD+kgBU9AyhD1OIvVARFa5tDfvTQQrn0VqWtJcWUmygWGECVy3qHBad4/i3VBgpHQIrUSYpqu0tc/oKqKFyoSdbyKhazA/SQl1n703meZUVKSdLYZGmyHmvSjKp6SyuRYUErlb9SEDxUKE1yD2c9Ey8jOehdDAVUZwrqfQ1wfUs8J2xBlYFFOifHIU6i52dDzuMw90mPv8GUQ7RdpM0UQ0qW4uFtng2sneZ9vUV4ZGCw+FwOEb4S8HhcDgcI/yl4HA4HI4Rp2c0k+MTyqodaIgRP9+JTHALY51kGTP9yO2nIvPcgu/e1ZC2bS0vyyzhzFCBamgSwd+lccdeoTuQn0UNzj63xy5TSA3pX5vqOgkKjiEDfDji6zzlz6sGyZTmkiNX4yDTm4HjIHI28Ko9+HzNuCa47tLTOEXWP8iZ762NAAUkuFvIPOsa5jmSjryAJDjHuo16X/Nac4wHMUbiOoDxAFe+m7w27wvwv13QNRz4FqfT8mDOUSvTFMkzuOeMhekCTWykC5B5mkJrqjeeyiCWy9fht6a8kveK6GHNY+C8kWzptI1zoMfzoVN/ZMzDY+dkvKvBx3NdaU8+3ZgFnticWbnxaof1J6wv9OKYwx7xG47Q/nzgX9MlJ1Si+tvgkYLD4XA4RvhLweFwOBwjTqaPKE3TgkuUvbGe3VbSie8h0xwgY7UeBVKQDaE66Sd6IYQQQg76qD+Sw8dQ0dR8x882QkVkCLVrZAk3jRS1gvmrKbCnhasQzpG+4KhW6lUN2a65FqlmVcdxMIXItEiWyeye9mge0sP0D6kMpWSYlcvs8O6IVG7KIzgEm/FeowAdpZfqobu8jNLTKxTRW0gG8tl5pDExxKGXOWAyqSGr3PO3pvQR9JYxEO6n5ca2kKL9n42+2ENGCa9QiJg7lIuDqdwrkjZAXt32nLtms5DSZ4IS3tKOQ2+oWfwuqWKZu+bYZKYSy3XR65j3+h492R6mvPf8qXHhe1wb83zQIplGvhw/Vzl7mXD8Qf+plwTopCnv+ES9LdLD99NeVQL3U3A4HA7Hl4W/FBwOh8Mx4vSCeIB6EhivBRRwqkV9dL+NWcg7Fk1D+Kbhqs047dEWdQgLdRkmwp5igqJ1CekQZAKrp0AH9RFDUqWZbIiJQndCiWWgHKgWYo0szVIlGB6WuaVN7LkftpB8+TetNafpo74nxQYLVao+5Frw2FUZs3UHUXW1sPEscW1vtzZb/X4Vs4HXKFTXg8JazO04sBDZDG3alYYQwgw+B1QfJUILMdM+4bhKYTMWQuyaSB81OPd6a4vtBdAjpI80s9tm4IMiSiSreojnmBS0Z43HruYLuw+tOk3Wv1hXon+JyfQXnwpSGIY+At0TLFhsj6o6pYWs9SSvk2Rf94cVVfr84nwlrd10cR4WUmmB93SHInhq5Vtju8+ePR/bOy3oid3sdeZGwaI/fE57njGvmODskYLD4XA4RvhLweFwOBwj/KXgcDgcjhGnrylQLiacFb1WO3CQtWSF3iEr8B6ZqedYh0ikmmdqeEFIVxvLM1IGmaTT/JrJHAQfzGqgXSMSy/5wtnPXSfVTSk0xJiqfzZLIFRfgMGmWsm92g3GgP7KMFytDMsubvskhyLh00/wtjVB47hnXQiSrd86sTqx5DKuV2Y5LTlzHuV/b7daYK+wffXf1/xuurdBzOxPJIGWeKa5LIrcGTXyGLdbDSl2zimso+QxjWTMr3vLvNSr+1i346XBvtuM6E6ukJsPcbGc4d3ovcy2rsGsrPXl1Y8Yj64dG0h3HpBosl54wa3vgeh2yevcykPFdz+xry79D+W3ng85dU4XhtDUFs6aDe2axsGswRR7Hj9VKzXMyhHC/jXP5g48+xLFl3mB9zK4PYBtZHDC/ZDLp7TgMr6ZI9UjB4XA4HBH+UnA4HA7HiNMzmtFWhRONRSjLVBONFcLF6/sYVs0vL8a2+r2k6OJwJMPw/j6G2hlCs2pmpWQ0m2EI10MgRz/XEGwxNMovO/ESZtG5DlI0YbpCAwlhmsQxMaYsEobm9EqmNFSoLlJGU4XIQtBiZmzb4+U4hpp8fAE1NzEexKCPMpGa1qCF6ImsxcdmoEoYCm820W9ZPajzjHJcfC7nYK4g5rFKeHsWDTQeuuJNbAoZQk6NkH7IhbqBRHWLc6p3lmbKcAwjs724NNvlc1QYuEThQuq9RSZt2B8jQxVaDuNAema7sdc2A8dTYQ4kpJ/Uu9zQkBw7kdxifjAbOZHMfCM1ZQE6zZg3Wdbpwe1ohPSyT2ibApz22C9uogf4R589G9sqSR0o9WV/DDUVLCg/57FekS5SeKTgcDgcjhH+UnA4HA7HiJPpo+xIGJMhS5gerlpnbQOlx+e3ke55uIxZpaWk7c3yw2oA0iQhhLBaxTAtH2K4WhaamYowLaOCBl7JtVVFMGGUtItm8tJHYANFSVpZuoCF3ArE7Q0orMIeOgwFVSRUl9j3usnKNYW+JFxlfXl8rpRTQfXKBB1SaLiK8LfFGLVCTa1Bm2xQPG6xsNd2Po8F7RqoV8IQ6ac8qFqL59tPtENIQTuR9spKq1LiuOTI0k5n4iuBOdBinzU+z3E+IYSQok85rkYjBdDqu9v4M02kmdLBUlgleFvO65QCmkqoFlA8bA+5cJ9U9mFuzGQcMlTG5Bgbj4lGKyNQYXfENxy/2xmaUKhB3Li94VeOUGI4XSrVykrpI9CJzIIWSvmDTz4d27drZOPLc84o5IbT/ldPlE6awBErlYPwSMHhcDgcI/yl4HA4HI4R/lJwOBwOx4gv59Es/qKUeXYwE0lFqkgJJ/m1LSSgD2aWb6U6rsTvLiRbukFFyrzkOoTI3phBbM5pQgYW1Cc1tjX712RVgxPNJDuZywCFrHl8gTqRdQ1j8kIeVfhRtJk9GvaqXeJ4x0w4aAxCYx6sXShnudlGrp+Z6yo15TrQDlm+C1QuDSGEEgY6SQ2e2GQT2zFu4ePb9XH/urfSyTKjORM8xAebhd538IPmIlOuYxfnBGWZAwxRauGdM6yPzZbgqiUT/v4ursPVkICuhfZnBjD56Rk5d60ejLnMbOJOeH+uYWWzCd/wIFnDydR65LS/dcL5Kfcwz++YvzglqmmK9QqRpHL+Wi/nuH8rWcJc7klgbLVa2Sz0n/ziF2P785u4DpQspLoxKxZMVEzV85vCq64hKDxScDgcDscIfyk4HA6HY8QrZDTH8CbVUB1hrilEJtEOmZI1spuf30Ya4fHZBXcJKcK27IgEjjTMahOzpRPRbdGYhSY0DWSolGGGEEICs5MUJ5UJ7UI/4rKKQ1uLvG6JULum1zGLs/X2fU3ZYmZki5ZmyntcUhPjyvFwjgWKo2Vy7il9gWmqgkJ5u9b2YYPvbm6ijPJ2vTbb3UBiGWgAs7ASXhYN7EGHzPNINWZCaa53cQ6UWex3LpJUzo/FeaStFtW52a5PkEU7J4do6YKhjufYktKE13UQypAe2QX8n7PG0m3rZzEjtoV2spZMcWaht5DPdsgaz4Tu6RpQJSwKV6k0F1Qe7wXJ0h449yb+9VSZdOA8YuUAkX6TaiG1NAjNRCOvxGRV2/GnAZKplIDrMhNK8/Y2zq/ZWRyjO6FI/91f/dXYLiADvpFigCw0yMKTWi2AID1vvXjE2/sVXXY8UnA4HA7HCH8pOBwOh2PEK3g009fAfpNMRIq6HYPAGlH8yng32/C+gsIkSRhWaUYm9uljKDtIcTv2dcrruO9tCEjvgGPZvybT0mT8WqXBGtnO7RBDz7M5QnBVSEx4NeSiImHomTP7NJ1WydRtPN+sk0J86WGlE0P/1b0t3LaC4mi9jcf+8JOP7XbwXn7w5PHB3wnBZvZSqcbrl+t4gdojnTWv7PwqKhTsg1roxYtnZrvFQ8z/T+CnMLe0CZU2DaikzV1sl0K1LJDRT0/kQnyil8uYkny7Q+E8KUaX5/DIhs/wboOikcFSNz29vukznWgGOKkzjLlkq5v5Bppp6OGN0Vp1FbOdmRneyXaJqSpw2Ic5BCmIZ76Y9jAepqrJadHHs3gtehyPaqMQQnh2fT22N1QnCoVIxVeCPnAef1lR0Z5n82+BRwoOh8PhGOEvBYfD4XCMOJ0+Qog0SKGuqeBE17ypRtqhfQ1VxAtJ/qjKqEZiUkchr7MMigImd222ltoIAUoivBPpwdCKmiYF53QqfRTChKIhhLBF8Td+V4Iq6yQ5rzfqocMJbyFY6oCJermoirgdVVR7LBNC8t4kOMX2/MxaFW7xXWLoFHtOW5hn1KABLgqxl0RyZA//gtvbqF5arS2FMkOVvgLner+11/YOc28B1VpWScHFF8/HdnWGhLznQm2A8ulq1v2PaBqhOfC7y4uoesrFR4DnUc5Id1oq6B40UYd9ZjjeLLMqvyyh7wIL05nNQkJzECaqSnJXgrmcInEvwHIzESWYIZhNAp0dYyZb8tz1fixJgzHRVCZ5a+7v+N3tfaToFvB/CSGEZBbn/M0qbvdXP/6x2W4FVeNgbDa1KJ8M9Bef4/mwpyEaDjaN38fB/X4LPFJwOBwOxwh/KTgcDodjhL8UHA6HwzHi9IJ4RtYkBb3Q7ie3sqouJuzegef9+PnzQCxnkRc8nyPrr7M8Y8XMRvLgar6Cv42BDPhIzepNwPfxHPaK0eF3M3DLWjivRRYyf4tyUjWkmSVxHI4VyeJvNZT3CmfJzNRSDGUIZnrXu9hu4fG7q+35sUvc7lZ42S0K5+XIGp/N7RrF7Tpy8+9/9PnYfo65UhRW9nu+iMdrdnFc71Pb1x5yVWbHLha2DwX6xOKL++cU1zYKFI/rmZUrsuvVImZmv/n662NbCzOyGB0zbNU7u7m5GdsbSFfzObJ6B1m34aMAUtNM5g19ojusvbUi5UyxAJhgXYOOVXpsFrpjQcOhs+tAtDemn/refcv7hM8erciAe2aL9QvOT3qIh2AzuD/4+JOx/e6vf2W26/lcwuedPBO47GKetKawoDxR+8PrDfrc9TUFh8PhcHxp+EvB4XA4HCNegT463A7BhjsMg1RwZqRSaO4QBj27uwvEg/sYJs/KKNdLRAKXZfFvU/tc5GfMNGY4zhCrkCJgPaSFxySppH8MJSMZhTXCUha1WsyQ6dpPB32U4XUyDszepSQ1kUudYlxqUmcSovL4vO4Z/LIbkf02oIxu4MW93VgaYIdxuINXwKPG0grPnl+P7V998NHYfu+9D8f2yk6bwKH8g+/GbOnf/dYbZrsOGeGfP0eBPsmYL3BOFfx6H5xfmu0+XsW58r/8s/91bL//wYuxfWl3CX/yJ38S+72Ix16It0iKwoVlESWkZWe3y1As8uZ5/N12Bzrk3g7YDHMqL5hxLfMQk4Dy275T7Sols/RrpjzVSmk7ZIA3uOcGkdy2kDKTIkqPeBt3ptDddLWABn1i0U2lWDfY7ic/f2dsf/jsU7MdC162eOgJg2i8H7SI57jPkUoSPJzKXY89Sw7BIwWHw+FwjPCXgsPhcDhGnEwfmdpXQh8Zymi6hL8pNtWzWBVCsfXOhorX9zGkf3Qew9ois/EXw76Wtdgl/K1RrG0+j6E6Q7Yit0qWhh4MzNaVgmVUSVAJoePAgniJKTRoa/jbYx/OJu5SVUrFdoasUlXnmExjFMSzBI8tuMfa+tsNrpOE4zuolDYbUG+pnW5rZCH/9Q9jJujHn1kFWoLsYp4769gPYp8JN8fw7EWcQzNJhX9wFenJqzy274TG5FypoZYrt5Y2+bP/6/8e2599Eqmbt958MLYvH9ps4h7/mz2/jjRa/tTSQmegk4xngtB3tA5dzOM5rTdxHHpkg/9mp7FZzmB5KiqZjhwG7pNBKNeAQnpklliVIAx2tnXwGEiwU6EqP/xpilXKdlQZ0TtlyOx2pKJ5X1xeXY3tqrJFDD/8PF7bv/zhfxzbN1KRoaFdKH5Wq0JY4DmZ8PmgSspDexw4mhfEczgcDseXhb8UHA6HwzHCXwoOh8PhGHH6mgKlaHuVNA+3lcuiIQYlf5RltsKbPQf3+fgiZpU+urAZp8YnmDyoyNTol8x9Kpit6JoJTziZMJ15+TcMW+C120qVx36iiqjZphUZXkJuHtVPc8kkBc/LjFjlI405SWDGtmbRxt/KrCB3bO129vy4dnRxEfWXZ/e2kukDjMNwHa/zJ598YrZ7vopj8fBJ5NWvriI3f3Em5kwY/wpjVPe2r5+j+unjR/HY2401WtpsY+byo4evxePV9nh//Mf/+dj+J//4vx7bO3j3bhqbBb1GtmzTcuyemO2KIvL2LcyLUpEwXpwjS34bufAea16d+D8zM5jS6iQXqanJuofZk6ogwXj3WP9jXyUB2fiQD9hOPYeZeZ7g/tb1D64p9BnloPacTPUASsSR1d7IPh98HKXRP/7pT8a2LDEFelYlk7UfgnlmmbUHnkMQME0AH6fqbvaK8EjB4XA4HCP8peBwOByOEa/g0RyhFIMpQDfh1/xyu8P7dJSLWeVkuIUxyx2kjlfiTZyACqJ/c6/ZgZRiIoQmfdQNlroZJsRfOg4lwnt6Pm83a7NdAfqnrGxhsnEfoSXoQUw5otJC7BNpgGEvA5wUFKSruUpX4291LQv+sYCdlU7e3Ee5XgJTnAcPHpjtLh5cje3Hj+IYrVorsfz0+Wdje41r1oIOSTOhvXDNzs6iLHNeWtqxQbbsGsXsUgnWmX3dP49F+R5cPTXbffPbvxP/gP7yGl69YWV5kzff/vbYfv31t+I5pFYGud3FPpUZzkN4mB43YQIpclmBHlOpNjLh6xDH/0zmQ1pCrkrKtlXDKdI/5FT4EDgilcQuWhyyKiFRpi9PYyWu9t4AlSrpxPw7DYfvi83O9uHmNkqWP3sRx0uGITToA+eUUl0pxiVhv7+EMbM+E14VHik4HA6HY4S/FBwOh8Mx4mT6iHXUlZLhCruJCKWCUwnagzQTA6mNZkuj/Tnoo8eW4QmPipgNPNRR3dGJ70Kaxx8mvWIqVKlRMTpLxVEh2cRzZN4yOzOVaO78PPaVx2NWdt/a8LJEKFtV6F9h+0Dqa4CMKt0zX44YkD1ay+8mGbLIkbW6WUWqZS3qo7yMlENOhYpIVM6RJdxgvB69ZmmmR6/FgnYvkOG+28TfXa2soqdj1jjmQNfYcdjiz19/EAvszeeWumFBtPMHkTK6fPLIbEf/5RmyYL/x7e/EfrdW+TODnwJZBakLGBazSIPttpFu00JpGQraDfCPKM7hd16KTzH8Cyiq0752a5wfrl/aWWVZ0sJXG4qvFlnMmmU/9FC65Ti2FCfsengUYF63SS3bocjfAIpUboUVihhWZRzjvosb3q/tsd/99Qfxd9C9jVot48fob9Ir7cs/jPHC1EbTRUr3/9N/tf/9PVJwOBwOxwh/KTgcDodjhL8UHA6HwzHi5DUFUtKJkFvDhCnEfrLuXk7ebzYEry6+rXxtvVhF6ddz8cZ9+lrM/kxRWXDXWHljAoldB0mj4VQzOyy5yVwmL2gXNrhZA0JYvWOrKsoJWZ2V+2dB0z0hDcX6jkpXKe8t0NZrwT71yeG1nhBCGHB8cqIb+jX3VgpossbryDWXsv7BSppXyFBPpfpsB1nr4zKuNwyQUTaNrTxao3IopZOa/du0sX811pgW2dJsd34Zf3cObj6Ryq9Jdbiq7EAZ8pmV8G6xnjIr43eFGLvQPKrH8Tqpbcs7KDWS0vjNrLJOP7mZu5Fj59pFCFbuWO/iGHeixZwncV0jy9FvrFnVnV2vGPA4mgVItaVyQMC5G7m3XFven5zX9c4+h+aoPttDRrxCNdxPXlybff79D384tjc4XF7ZG22DBZ9kr1TC1wd76l/tf32PFBwOh8Mxwl8KDofD4RhxuiTVGD/Y7wy5MkElhWAzmg0DBRpBqZYAOmkF6eNnKGQWQgivnccQ8MEySkNDZzOGa8gTC9ASNONR3+MS0jkaAtWSackCXDtQAsZ7OdhCWyxSRrOPQsbBmPaAC+qFbqshLx1Ag6W9ff8zSzTD8YagITjaKJrWgGohDffy70gLGBmqyGJ3kI1SvlmIHDTHDGvRv6GO1+Xs7LHZZ4C2kx7S1czKIDtcz+cvor/upRgpX10+jKcB/V8netCry0gtkQpao8BeObO3XYFxSXGd2z1/ZBRNg1FMWsk5gaLpOA40i9ozCUYTlNPZUgyBsNt6HQ1lGpF+D7in5wsUaaQEW4o+Ni3vTZj+wI86hBA6Vi9AJnstGc28T9brSDPlhX0mfPJZzMB/7Y1vju179O/f/uAHZp9ffBCLNkJJGxqZD6RCu4YFBMUQCAObTj0nT8UrejIrPFJwOBwOxwh/KTgcDodjxJcqiHcMZI/2fQli00RICPN2tQ0peQiGVZ+8sKqIKnt/bP/+t74xtmczGyqubhBGzqjuoAJHFCqgZDhgSjNt6kgR0Fu1FBVJkVNJFMPLAnSP1Hcz6hAqQJgF/fKA2AdZ0EGyr7kXM5r1/4Qe58hs5+2OWapCOTGLuYy/q4W6MpwkVVhZbrcrWMwMFEOLk80zW+huBgqqn4MOmdv5wL4+fvwwTGE2A+VnfCrshaLvdNvEsTRKJLm2s0WkRzZr+D+LZCwHjdlC/ZWrqiuLv9VAPdaCvmh3VpXH+UY/6tnCjhdVcbxv7+H/HIL1KsnB6vDYvSjsdjWLHcZ+572lE1nckYUiM/GJvlvFonUs2ni/FboTlN0G0/8v//Zvxva/+Dd/bvuK8WJFB81Cn/I22C+IF2HsaU6kj/jc3S9E+mp0kkcKDofD4RjhLwWHw+FwjDiZPjoWnvBvrQf1qtAEp54qGSgudrUNvz6+iclsC9S7f+2RpQQSKBmozDAWhKKS2SAUXqDYWy+FujZQ08wR6quiigqMFNtRSRFE2cR92Ne1JPGR5ggpwunchuCkhTpjX2o2Cx2opW0dx4H0gIodqMJqJyxPQwjhDN4GxpNDzx3JTyUKjC1wrrPSjvEcaqbZLF5ztVClnSbpQGPvGkLYIVEug28G2y8/ADWIcaA9aDvYpK0WHo47jHE2VyVePPa6QVJgL8mWGOYU1GXSgcIStRDvJlJiq7UtdJfBx6SCqm6RSULeLs5L1ljscOw8F1q1gLqKSXK19gH3AtV3icwb0Fu87uudJJ3O4zz6Dz+K1pr/7P/4P8f2ux9ZtWOD2wmsXJjN1AMD6kJDvcmTEuebTNDse1TSiaxQ+ooSJo8UHA6HwzHCXwoOh8PhGOEvBYfD4XCM+FokqVOyUV1fsDWbDvNcakjDnch9C50fVqAJ3/0oevquNpaPfOvR1dguc/LY+B2VWCJjtwbvX/a2EywYxzUFFhgLIYQ51iUqrKGQK02kKFyOdYntNsr/uI4RQgizeTTwobS27ezVYMavyaaUCzDw6nItJGdRMtsHFhTk+kAhfCvXKzgbcnFB2dIkB9eCawWFrClk4PBp+qP+vDQO6rluECwG/P9Er2ot3jdfcJ0kfseMXxrNhBDCFhnXCxjuMCs4hBB2WEcoUHhvkEUdXmlmlM+MHNceu6fU1xgfy72AxUXKjQuRg/Y4/gCzm7adlmrTezlFocFO5i7XqShl7hq7TlJB6vvsFtnXwrH/67/8q7H9r37wH8f2T9//aGzvdELgurfwkU9Fpm7WD2l6lYnBkKkKwPWF6WoDf1fwSMHhcDgcI/yl4HA4HI4Rp9NHpHtOzJDbY4IYtU0cY6+eXn+wGcTywBSlugNbU95ZyeaTB1foQ3wnGkmk9I1/Miu0Tm24OkNISc/hWmSQbRXD6RLhPaWwlYTjDKHvWUM+s8cm7USJpWY+01eAfhi96N7ogcu0avrXNkoUgo6qIA1VqmVbk1ZDRvPMFkCrICO+X8HfAdJcSXo148AM5D1vXEPLxXFdbWzGPMP4soo0zO3dndmOGfnM3mU7CB2SJYelq1pokBNxPl9iO6VX4hgloCRz4/NtB6zB3ZWSThRfbVKcnONpJuOK8U8w9Yz6Wa6FoVrSw/dmCLaIYYLvqtI+FMgUDuj3i3t7bf/5n/3Z2H7no0gzDbhkjfz7bDxl6Gm9sdeswPW01KW9z4xsdEKSeip7lEgm/KvW1PNIweFwOBwj/KXgcDgcjhGnZzTve2tGvGLBpb1jm2xpCX1YCA5UhiqE+Ce/aTp7vPu7qOB4cBWVIl3LzEgJa/HuZPG4tpG+IkOzZWWsatrLgHQU69dptud6exPPAbak5+c2k9SoMUDrFCLXypnpyoKEUpO+NkXKDvtFtKK4YLE8FinbCYVFT4CGypGd7cN8ib4iS5vl+KU0P60HQgalRyKKMVpwmjEfrKKq5fxARvI6uTfbcUaQzljdx/PTrP0cO23Xke7Uey4vI+XT7CIF0sg1I1LoqKiiU1tS0pX1Np6fUlNDICUZz2lW2EcJu87zMAyyWDo0zCJP4bEijx72gfd9JxU4ez4vMA6f3Vyb7d77GJQRWDXabPbSiQY0YQEqLlNVF/gyFrzsu2O1Hw7b/yp47scez68KjxQcDofDMcJfCg6Hw+EY4S8Fh8PhcIw4eU1hQKarGkQkzMCjAYlkQ1pjncO/kwqHZjlDZJJKRjQrUs7ggbtaWbJ5WzOLFtwuficT/rBFRjIHbBBe0GQGU1ooWjJW5mTGaDkH/y7ZmStkvW7x3cPiymyXF4f5yEJ47AHVJdUkh0jA+9/dxUxqVn/U7PQUGcSb5vD6Qgh2jAass3QyOcjHhw6ZyqhQOogHdZnRpzs2k0G3i8fIZ9O3w81NXNPpsA6h3DyPvr3negM48oWV3PbI+MWyQVitrXSyRDVPkw0s49X1qGa7Bf9OKafss4SZDuWq641dM+kxXzmnBuHzUyyU5LjOXDPs9+hyZI1TjpvImhzGf8Y5INP4HhVe12383R+98wuzHYvM7mgShnmtXaXKvENlW51fuXkecvzt8SgdZpXhYwY5U8/QQXzbE6+S6nA4HI4vC38pOBwOh2PEyfQRC2t1nQ1pGFKyfWrUwhDpWNEnWxzKIjNpgJDASSGrzTZSETUKm81R3KsX2isxB0FfJabkuFD52IjvdAlpWoMCYcy83TR2n9V9pI+yFAY+pc1MNRnElOmq7zRkjAkkmyweF0IINULwO2SC3oIaSXOZRvCDpsGQTBuT5TscoRWKgP6BsqhgHJQIfcQwflktwxRIRVCeWi7tOMzzSPnQ9EWLui1AkSWYR1tKSLfWH3m7jcfb5fG7XOi2BBLQNa5FU1u6gFLkDtfZZNdqljCK7c2RUd6K1pf3GYvbZeIBnuK6M1OfVMY+hXKYeu7lRqNMtkUm9WZnKdcN5sQOQ/S377xrtqOgtwNdah8D8kwYDv8/rZ+SXTwm3CdlNC1C/X8HHik4HA6HY4S/FBwOh8Mx4mT6KIOqReu8Dw1DwsNeowqKFbidUgwMSum52qkCCmEfQ2N6yoZg/RVu1zFUPyuRGSx9SExhLdIcmr3IjlNNIGomtBkKN1Ra1TZLlaFxUcXwviyskmUHv98ZMmoT5dFAMRgviVb6im60oNu2G9IuNmznGDHbsxMvYUb7BegGqWsWanSi3UQl2G4Tr59ei82bb8X+vP3NsT2v7Hhx/FmErZAM3QJF8FagTTrJvu5RJJHjH3A8oz4LtsjcZhVpoe7eKn9Y0K6YRWqpE4+I+zUydPFdDYro7Mxmwte7eOwdFD3LpVBvJlXZnIXZLMV9R28E9mdQ/tX8zHQRQ/p1NPiuk3t9A7XVR8+icu6Dz6zfMq9GN0W5SqHIKWp20OKQX6LYw6m+Cadqioa9KqPH4ZGCw+FwOEb4S8HhcDgcI/yl4HA4HI4RJ68p0EQjUckmCDZT8VReOb35jpw7sy6n/WZTcHfKp/F36QscxAuVGbYvYJBydR4540Wu/DuyM/EebTrNHKRhDjKaJSNzB16V6yQbVKdsZU2B5jczSDEzOb+r5QWOEY83SBXRWRWzY1kddLWxftKffPxsbP/i578c2599HnnZVuYDTWgoO72Z3ZjtuA6wQfaurqe0kMXOKJ/NKCO2/PTPf/rzsX1xEcfkcnlptiNn/vTp47FNKW0IlitmZveLFy/MdlxTe3AVf3exjBz+oydPzD6LZRwjrht0O3stdpDCrrBucLeyRlIffvjh2L65jf27vIznfnFh1woePHgQt1tGn29KaUOw15PrEirNzSdMcihx3avAeqI0nYY5NDXaSkVkrjH85BfvxT6InJQS3hbzKMd2+ryZyjQ+lb4fTl0Q+E8AjxQcDofDMcJfCg6Hw+EY8QomO9NSU9JEKeKiVEIpSjOnTHGUc+pJtRzrH9o0gxksuxIYYT67jWH3owegKB5YioHcCzNvlTbh3+xDKjK1AZJGht33NDeR7Ewra4UEWAqRUd4YxKiHYMZpA0MgzWAlvfI73/nO2H7rrW/E/SWUrhHSX19f43N7Tjz3h5eRakllgl2A6joHZXF5HveZSWY3Ja6kKeqtpaYy49Ec58BeJi+2KyDZfPTosdmOpkRr+El//vx6bP9YMmrLWZyklp6Zm+0yVBXguCpNG1B4rcrjsT/96OOxPbSPzC4sLLeA3PXyyp4fx8HQPWp6hXlJCTu9wpvG0mPTEPoV83UDk6pVY/uwy+Kc+PG772EfkY0a5x8+ow7T4roL0Wvm88SG/d7nU8bM07+pz9evCx4pOBwOh2OEvxQcDofDMeJ0+gixyl64ig9IH+2plCZCJPoN7HlB48/+iPpoSg2gXs4pvBJWdfzuBRQcy/OF2WeBDMqWNenlnboFPZLu4nelFJljTfkS4f26IX1kQ+uCPtEcYxkv1lLP4HPbq9wBCq0MsfFyr9b/4WvTowAaPadDsIXSXn8aaQqleKoqnnuLwm1Da4/38Coew4TM9KIo7BifLyLNVFUsZifZ1/3hsUxEgZZr0b8vurBnCkBvYXoEx8/V0/puHVVwLFQ4m1v67/IyqoKoLJvN7DVrkWH+/HlUiZEe22ysYmmxOOzVwH1CsJSW8R1R7xRmLqfMYj6iKpqgo1oZ411N+gjUbm7v25+996ux/d77H43tWgtZos3ifad6zzNjWJ9L+zTRF/vYv6c8D46JlJJTM59fUenkkYLD4XA4RvhLweFwOBwj/KXgcDgcjhFfTpKaquxqokqqUF58AzUTPFcrPBkpPmN1o8ceDq95dMLfGi4P2z1HRcrlnZUClpBLcp2kFGORGlx4Dm445Pbdy0zJht7EkMppZnc+oT/TMc5yjAO+3InEdddYaeYXKIT3T1D1M6SRx6aMldnbIYRQwJ83M3yy5bFreM1wTeDysZUEr1fx2lwskCUM+aZm1JoMd/yRSQnWGXyPZzNmecutkRzOnk5lgY08e26MZpCF29tr8Q2srWTmmlkzHnovN1hz0j7s8N1rr8Vj02daM5qJBOsfVWHHlWtgPea7Vk6mpJdrCprFPAVTPbi1x95iHWEHGer91s6vf/vv/8PYvl3HMekzO15c/2A14SShn7uFOV8z13S7w9/t8/x8brLN9Vq7R3Ji+rSvKTgcDofjS8NfCg6Hw+EYcTJ9dAxTxZ32Pke0wzCZ4b16VFhPDxrcTKcY0uBjjz5Cm6zH3SZud3tnw9BH51EK2MPwZTazoXUDioayUTVBId22g0SyQ8idC43G86DslJTCy7/jMQr4TleVmKDg3wEj05TxSkEl5ODytigsmOT2oqkpyhcoK0tNGdYD/W5rW4TtwWUs1kbecLeL16nvbQZynh6me1Sam+XxPIyf9J7UlDvFjs8yOwd46g2up5G4Cn1BjpTdm51ZiSWpy36BwnLi503qq4F5Dv27VZJaI5u+aSGHlvusgDzbeCVLBjjBuUv58iB8CGWozHyml3oIIexgbLTp4lj+7NcfmO3+9p1fxD9wL2w3UsjS3BsT1z2Zng+mvt4RRudUGsfQ8aSV9rdE82v44d/AIwWHw+FwjPCXgsPhcDhGnEwfmSxa8WPtEVp1JpTS8BD1yXtmfmIjjay5ss9VeYmITFYi1SHiTZwaeoSqg3jsTW2ziRnyFgj1Gwk1cyg1GE4rW8BwereFxywLt0mWcFrFY9Pbdre2NEC7RB8YjovayBbBg8pCqS5UEByQCtojhO8bUZ6gf/Mzm21LUCVDVYtmvW42MeO3B5VQQLFUVjajuYB3NcPxVOij3TZSVQVol7a148U+VXP6I0s2N/4uikjXDPC+ToP2IVJY8zkptun/2UiJ6bUlDVaigCCzoDO5f2rQQkkSaSvNLue15j0zKI2ZkAoCfRS4j+0Dz4lZ8fRVDyGEzTbeW2uM668/+dhsdwtWdFfBi3umEiHQcubZcYR2mbKqPrYdpvVx9RG3M7y43YP3ydHUZ/dodjgcDseXhL8UHA6HwzHiFZLXGAd1098dXX4/vIJvwmmhDkxU9DXXDzf97knjiE8CqCAmhO0V2zMFveLn+7aDoNsYusK3IVd6zCTzRBpg19pLuNpAudNFmiMRGq2k10LPGvdCM4EmGkj5wRazFqqFKqqWFI8kmDFZzNRWE+VPMqAPhv6Zppw413pkDem1NYoXU9/f9sEok0C9pYNVVOUFaJiA6wl6ZrOzdEiKi903SJ7SSUD6lUo+4Q54nej/wXNIE/HaoKINdqiaakZKhYUGN5JoR1uPAZQfC0oqHULasQa1uF5bNdoalOuA5MOdUJ8ZmEtaLSRitdrB/+PkZ9mJmGKgtJBlejIfhc0mElr3PnX1kcPhcDi+LPyl4HA4HI4R/lJwOBwOx4jT1xSGw1K0lxgOttO9d05yoCUZsNNqMUONHfW/AJ+s8j+CBaqYNKnZmfy7ODJiLEym2ZpTGJgVyqxc6fYuYRv+ysKj7urDhe4ykRHPyO+bgob2h42cE+eXo8hfo8X78F3Xxf7sNvbYzLBNWYBukIJlw+F5w0zeRgr+ZRgjGukEWa9g9m9bR66fWeMhhDBgu3qLNYXU8t30WDa+zrN4rkmna3LxfHvIRgdJEqa8mmZRmXDzxhjJ3EBYZxGpKafrgGs+yL3O69n30/9TTmU7d5Baq1yc+1AWvmvstQ3wXqbBkK6HTd2Be3M85Xf4oufn0+Zfxj39SEG85Nh9xvGfuGanIpHLcmrhvC/gkYLD4XA4RvhLweFwOBwjXsGjObbTzoY+DAIZlGrQMpWpx7ZKC09Wu06yREcKWZkqerEpjEzoyC1Rmig0QI9BIqPSyas3n8VhNwX6TKE7e+xtF0PoXYqa9vJeN7I89C/f85WI+2Vop+JNzAznrEWmbMkMazW3iONaQ4LYCbXVgZIpUMAuFf8JFoJjNj1ppUaKwiWBNMdh3+QQbIE3+lZryJ3iGCw6OCh9h3CfGc0JfSWENhkgceX1zDTteKLw2p5lenb4frIZw+JVHQ6feyrUFCmazY5FLW0fmpqeBzi2yEEJFmakN7TWJpzBRzzBPNyJ/zZZ4KwERSdzgDQfx2iPMgJs0bqIPujza5oymjw2uLwTbaIlZWC6D6fAIwWHw+FwjPCXgsPhcDhGfCk7zr0CS+Y784Ucg/Khw58PEupMFn064tVgKacj4RzCNBN97SmgDqs5utpSPE1KGgC/K3RI0dPyDyoS0k9CHzFLeAsaZi2qG8pI+iSG2ZVYZmamTjv2EeUV1SacAzkoijafvs6k6DSr2lBG9MoQZUyZRxqmoMUlqKRUrFF5najw6mXikALkNC5EZkaLyjmK7yWilOpBw7B4ItV7mchDMlRMLDFXKinyx/HjdTmGzliHop+lUFig4uqBviBKOx729ejlnIxPCC4nLUpV5cfM5e0m7p/mdhxIcTbo32prs6rJa9MOdV9JdJheOabaGcLh59L+kQ5TQfsKqMMPNytitP2x9p68nyVbWuVIvwUeKTgcDodjhL8UHA6HwzHCXwoOh8PhGPG1eDQTxhRnb30gtqdkUsflU9NSrak1AeXXCLKlWpDS/CrTEsEh92IswvUQ+k4PYuxCiSslfyn5cvHG3faRY13DlOXzmzuz3ZBecK+xRROVECxPOzOSPMvzUqLH7F9jOnNEN8d9Usmq5nfHpHtcR8gzVn5FBrn0gWsFVmaYynbxGnLtQjPhya3bipZa1RdrRPnha6syz9SQ/ey3yDfxnVamNX0gvzyh6c60Umg3tY8F+9rheK3IsxuzloF5g0NvdtbMipJU/k41s0ZNzA6nBNtUCA7Wg71mJdRKM8Cx3sO1B/qiH8tUDq+Ok+WpR9Y1Tq3A+qrwSMHhcDgcI/yl4HA4HI4Rp3s0H1aTfi0wBcGkABR/64jaNUx9dVxWBroHn2tGMzMqT85yxGZqxtOCGuIFKFmcTcaBCtUavb0T/9qzs1iQjedeZbYPJUL3FOG0ehgnkEvSKCbHNatEMmgyvbl/YqdbP2Hak6ea9YosX4T3KfqjxjyUBNMYJhfaxNAUKNC3f5lpXMOsY6HEIGVNkW079Tu/+TL+LjOQ5X82skxZxrHT8UL2NQvToa1zkr7hA6W0KgfFtalRtK5R6Tc6W5T0Lo+/s1lb+ojU7GIRzXPmy3Pbhyp+9+zFzdhebezxyMCywkCqJk5T1RUmtnn5N7p9Ytrx0exmKcB4Co44eOsvf03HdTgcDsf/7+AvBYfD4XCM+NrVRwyC+r2wiuHTYRWDhlWmoBfr1x0tjne4WJUeL5tQ+2gWJ0NrQ1NIGMq6eemED/PL/iGLFhmsrPuvRcB4iAGheS9Uy2obQ+hqBvoiszQAM3trFCzL5N8EJGkbai/JD2dlh2Api5wZ27n+DxJPqkS2biGUBf93YSG+cjbHJrYPrUbQE301mc9HfATK0ipgvkBW2L5SGdPR9xvtVrLQi0LP9yXyvcxnXGuMUSJzoIMqjvOrR3HCTC406baESiQZ15Le3ChCOIgSrzDe3HHs6vp+bLPoXQj22pjrXFq6rUWf7lZRcaSKLN6PxQyZ1PJUyECZtij4R7pOKSItADhud/jj34p0So15bKcpavyIJ8pJfXmlrR0Oh8Px9xr+UnA4HA7HCH8pOBwOh2PEyWsKlMepbJT8dHKEVbPcFvhzkw0pawpG+oX2kdfZYLKBpXqm+Qa8uPGgFn4anPswi1ypyUQNUk015fnJ2gOqQ9boa1GAVxeeOSthrENzGakout3RBCX+jspBM2R45uBb1Qgnx2/NZ8v4ec4MXTHFmbg4RWrPaV7GNYEc36nEcmod6BiMdy+4dL22rFh6dnaGz6czpMt5PHYvEl5W8MyQUpvj+nVicMNjcw4oWlxrjoNMgdC0h9foinIRppAWMKsZItffNLbyqFlTwxzPZH5xzYnX7+YmSkj35gP8rc/OIENNdT7Fv7fwb65lIHjXGTmuVm82md74juuMRysehMnt7CNvutL0pKr12O+aKg6s/ry35fRBDsAjBYfD4XCM8JeCw+FwOEacLklFqDhMyP1+G/oJYxcWCNuTb5r46Qg1NeX/vFc4D+dhjJQhfe1EfmYymg+bvIQQwjBE6qUDZZTIu5ff7RDy0lSlKqwMrzRetNhf5I1L0CYtzkNOyXg0GwpE4t8Gfd1AQpiBaklF/0mqpEABu0HDexrckEqQOcAsZBaWY2aweksPyHZelLGv+x7glAFDeiwDNptF6iXntVGqMeFcRn8wrtudHYcKlGR1Fim6TLgDFowb6BMt50RzH3oqJ8cywFk0ENtl3XS2Oill/k4IIcyrOA9vX9yO7d02brdcLs0+5+eX8Xchs+2EmiJlenMbJa4qQ+ZU7iY+f/lB+K3Q5wjvaCNP/Wq16I73QY/9FQvfTcEjBYfD4XCM8JeCw+FwOEa8An3EQl2qPoowwpNeV9hZbAp1+4/6HwyHNtsDqRxmKGpWKMNA1pDv4be8a22/t6BrzJlLVmjWHVYcpeKPbLK0EbZvUWAsy2Xs+AfVGHLsFSieAtmspWQJZxkyN/n5npdBPH5tssvjXrVQBwtkoOY5iqF1orpBRmyXkFKbzvit8LtUj2X4nRBCaDBg/O4YbUKKjiqZEIR+AwUyEwqkAH1HmrUD3VNBZROCVXIF+jD3ylmg2B5pKvEyYBYzvR8MxdYrlRc72zagDGtbZG6HQoots5jlXthsomrp+fPnY7uEymm5sIXuSJm26F8u17arYxbz9fU19gkWxWGqWLO0jVrxqzIyx6ioL3FsntIeezS1z4kF+qbgkYLD4XA4RvhLweFwOBwjvvaCeMcWxAeGrNb0ABupXOjwLnt1/2mXCLXC3nbsD1VANRJVxOlwC/tLUmCatMUEsS5QfSThKt7FpNuY1LbdiaKkYNIc1CGSzFXXkT7a7liUTGrNgzZpkbC2XNjCb1mJc0KYfXO3GtuJXDNjuznE3x0aa/VJ+ijlmKhKKTucKEcaThU4rPtPemVQ6gD7rdeRllA1DW1A8xL0jNB3VDPR74GSl9nM0iE9LEFrXItOxosqPaOi0+qJLJiI725vV/jcjjGtQ8146f3M8esP/04IIaz4W6BjLy+jwqiUIo0scsk51On5MXkN46WqSEOjUD0pRwvm8XMaXW16YyyI7Xdfhsixvgun2aSa3/yKhjceKTgcDodjhL8UHA6HwzHCXwoOh8PhGHF6QbxEeb0IenwcWx6YKhw1GJMdu49ZR+D6gma9ohM53nWFFmfjmgCNZiAZbC2Va7j0ZEIW+LKvkYs13Hdv+0ADF643dPi8F8/WIZxWCC7H2kMLkpWF8kKwHLDhUUVa2FDKh8JyFaWFMyuxpPf1lqYlkiVMzjzHuNKrOoQQqrzCdzCxMX0zu4TZgkXr4Iktx6Z09e42Zt7uyakpXc2ZsS2FBpkpjjnZgKfP9sxz4jFM8T/N0N3z3v3i8+kifwHnW9cT8tQQQgMZ8N3d3djeNtYIh/OmxneUqoYQQg9Z6yU8lnmfDlIoMkUxQN5bdWO3y5D9bjLSj1DutoDgtB+yeayYKgnTxzbPNfnO7EdJ/h7vP/HDdvHV7jLlNOZrCg6Hw+H4uuAvBYfD4XCMOJk+MnIoYTJMFJMeCXcCKYv46dEkwIm4LRVKJh9ip0pmusp2SYtiYfiKp9QeCRVTI/cTSoaaOM1GnTqeyWaNYa36zdI/OM+mJalM2d6h1rxKBs+TWCQuz5lVbbkzZreG4XCWaSd0yI7F1ZApPi+sFJNjybZ6SSQT2bv0+VZ5MP0U+iPS1fWK0lrzo2Y70iOkoIrKFi605wQqCH1tRe6a9FO0o6U5KFnujxTEo7yU25lbWPyy6be8qWM2ctNaWojjT49l9Vs+m8X5NZ/HNgsNpjJ3DaWJaZcVQtENnA/H7jOcY3KMujFlGOIu+HTvkXDi88v+1rS8dFpGemyfw9991Tp5Hik4HA6HY4S/FBwOh8Mx4hUymmlXab+xkTtt4USdA3WBKQpnYjGhexgW4fNMpAZFj5Aep6V10PknKacUx1NlE7OYOxyhlfA+N1nVDOfsOTGblBm2VEOphSczbAeeq1At/QC6AP2pJU17tbU2i+OxKzuuHaiSHBd6bTJJ12afGvRWgbFUVVGaMFMZ1yyxtILJbgUdNZuRApOiaciiLWeR4tms7812LNxGCqQUVdF8ftgXohe6re7iMXJczxlpJqWFehaHjNdMizlSZZTiu0EIDM5fbleDnlnf2+u/WkfFEQsXNo2lj+5WcfxIqWlxO9J3NksYFp5CHzXwBqFlZjG3WfYJKt/d38f+qDaLjwilT6fB542RSE5tJs/D035HKb8prsqIl47sY56nTh85HA6H4+uCvxQcDofDMcJfCg6Hw+EYcfKawh6fNQGzBqBqSZBd9HdN6I0riwDk61SGSqTMEqansmzHiosZ/ZYpWQu6pnA4w3CPp8SPUbbYyzpJD7lpgvUKSglDatcKKAfl+oJW8ywrSju5tmLPabOL3Dc5cr3OZ4voTcw+UU7YHxPlYYx1vIzJDuSqXSoexgXknMwMzqaPTZOcy/RqbNPnWP/mOGylQil9ousmyljn84XZjvOV1WdzSECbtZVvdpA2V5VdGzHbtazWyyx02RDfUcbKtYKdSEjv72M29916dfDzEEKo0Yfz84uxrX7LsyKOCw2sWEl4kMxiIzdG1vix9YAVJMV7lPuE//aezP0rZgATmmR8Kr+fTj3ajvRt6pH8VU/HIwWHw+FwjPCXgsPhcDhGJMOpvJDD4XA4/t7DIwWHw+FwjPCXgsPhcDhG+EvB4XA4HCP8peBwOByOEf5ScDgcDscIfyk4HA6HY4S/FBwOh8Mxwl8KDofD4RjhLwWHw+FwjPh/AJ4r62qYMnCwAAAAAElFTkSuQmCC\n"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from PIL import Image\nall_ids = [d for d in os.listdir(DATASET_INPUT) if os.path.isdir(os.path.join(DATASET_INPUT, d))]\n\nfor i in range(5):\n    pid = random.choice(all_ids)\n    pdir = os.path.join(DATASET_INPUT, pid)\n    imgs = [x for x in os.listdir(pdir) if x.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n    \n    if not imgs:\n        continue\n    \n    img_path = os.path.join(pdir, random.choice(imgs))\n    img = Image.open(img_path).convert(\"RGB\")\n    \n    print(f\" Sample {i+1}: ID={pid}, size={img.size}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T04:27:50.509015Z","iopub.execute_input":"2026-01-23T04:27:50.509265Z","iopub.status.idle":"2026-01-23T04:27:50.633422Z","shell.execute_reply.started":"2026-01-23T04:27:50.509244Z","shell.execute_reply":"2026-01-23T04:27:50.632858Z"}},"outputs":[{"name":"stdout","text":" Sample 1: ID=id_3427, size=(112, 112)\n Sample 2: ID=id_2427, size=(112, 112)\n Sample 3: ID=id_7680, size=(112, 112)\n Sample 4: ID=id_6367, size=(112, 112)\n Sample 5: ID=id_8796, size=(112, 112)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import os, json\n\nDATASET_INPUT = \"/kaggle/input/webface-112x112/webface_112x112\"\nPROJECT_DIR   = \"/kaggle/working/FaceDetectionViT\"\n\nall_ids = sorted([d for d in os.listdir(DATASET_INPUT) if os.path.isdir(os.path.join(DATASET_INPUT, d))])\n\nid2label = {pid: idx for idx, pid in enumerate(all_ids)}\nlabel2id = {idx: pid for pid, idx in id2label.items()}\n\nsave_path = f\"{PROJECT_DIR}/data/annotations/id_map.json\"\nos.makedirs(os.path.dirname(save_path), exist_ok=True)\n\nwith open(save_path, \"w\") as f:\n    json.dump({\"id2label\": id2label, \"label2id\": label2id}, f, indent=2)\n\nprint(\" Total Classes:\", len(all_ids))\nprint(\" Saved:\", save_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T04:27:50.634107Z","iopub.execute_input":"2026-01-23T04:27:50.634364Z","iopub.status.idle":"2026-01-23T04:27:50.725304Z","shell.execute_reply.started":"2026-01-23T04:27:50.634343Z","shell.execute_reply":"2026-01-23T04:27:50.724762Z"}},"outputs":[{"name":"stdout","text":" Total Classes: 10572\n Saved: /kaggle/working/FaceDetectionViT/data/annotations/id_map.json\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import random\n\nrandom.seed(42)\n\nall_ids = [d for d in os.listdir(DATASET_INPUT) if os.path.isdir(os.path.join(DATASET_INPUT, d))]\nrandom.shuffle(all_ids)\n\nval_ratio = 0.1\nval_count = int(len(all_ids) * val_ratio)\n\nval_ids = set(all_ids[:val_count])\ntrain_ids = set(all_ids[val_count:])\n\nprint(\" Train IDs:\", len(train_ids))\nprint(\" Val IDs:\", len(val_ids))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T04:27:50.726053Z","iopub.execute_input":"2026-01-23T04:27:50.726292Z","iopub.status.idle":"2026-01-23T04:27:50.795462Z","shell.execute_reply.started":"2026-01-23T04:27:50.726273Z","shell.execute_reply":"2026-01-23T04:27:50.794936Z"}},"outputs":[{"name":"stdout","text":" Train IDs: 9515\n Val IDs: 1057\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import os, json\n\nPROJECT_DIR = \"/kaggle/working/FaceDetectionViT\"\n\nsplit_path = f\"{PROJECT_DIR}/data/annotations/split.json\"\nos.makedirs(os.path.dirname(split_path), exist_ok=True)\n\nsplits = {\n    \"train_ids\": sorted(list(train_ids)),\n    \"val_ids\": sorted(list(val_ids)),\n    \"dataset_root\": DATASET_INPUT\n}\n\nwith open(split_path, \"w\") as f:\n    json.dump(splits, f, indent=2)\n\nprint(\" Saved:\", split_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T04:27:50.796108Z","iopub.execute_input":"2026-01-23T04:27:50.796351Z","iopub.status.idle":"2026-01-23T04:27:50.808160Z","shell.execute_reply.started":"2026-01-23T04:27:50.796325Z","shell.execute_reply":"2026-01-23T04:27:50.807513Z"}},"outputs":[{"name":"stdout","text":" Saved: /kaggle/working/FaceDetectionViT/data/annotations/split.json\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Model Build (ViT-S/16 + 512 Embedding)\n","metadata":{}},{"cell_type":"code","source":"!pip -q install timm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:07:59.275921Z","iopub.execute_input":"2026-01-19T14:07:59.276200Z","iopub.status.idle":"2026-01-19T14:08:03.440914Z","shell.execute_reply.started":"2026-01-19T14:07:59.276176Z","shell.execute_reply":"2026-01-19T14:08:03.440124Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport timm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:08:05.374233Z","iopub.execute_input":"2026-01-19T14:08:05.374554Z","iopub.status.idle":"2026-01-19T14:08:15.905795Z","shell.execute_reply.started":"2026-01-19T14:08:05.374522Z","shell.execute_reply":"2026-01-19T14:08:15.905022Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"ViT Backbone + Embedding Head","metadata":{}},{"cell_type":"code","source":"class ViTFaceEmbedder(nn.Module):\n    def __init__(self, model_name=\"vit_small_patch16_224\", embed_dim=512):\n        super().__init__()\n\n        self.backbone = timm.create_model(\n            model_name,\n            pretrained=False,  \n            num_classes=0\n        )\n\n        backbone_out = self.backbone.num_features\n\n        self.embedding = nn.Sequential(\n            nn.Linear(backbone_out, embed_dim),\n            nn.BatchNorm1d(embed_dim)\n        )\n\n    def forward(self, x):\n        feats = self.backbone(x)\n        emb = self.embedding(feats)\n        emb = nn.functional.normalize(emb, p=2, dim=1)\n        return emb\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:08:21.818163Z","iopub.execute_input":"2026-01-19T14:08:21.818649Z","iopub.status.idle":"2026-01-19T14:08:21.824026Z","shell.execute_reply.started":"2026-01-19T14:08:21.818617Z","shell.execute_reply":"2026-01-19T14:08:21.823445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = ViTFaceEmbedder().to(device)\nmodel.eval()\n\ndummy = torch.randn(2, 3, 224, 224).to(device)\n\nwith torch.no_grad():\n    out = model(dummy)\n\nprint(\" Output shape:\", out.shape)  \nprint(\" Norms:\", out.norm(dim=1))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:08:24.509900Z","iopub.execute_input":"2026-01-19T14:08:24.510401Z","iopub.status.idle":"2026-01-19T14:08:26.040713Z","shell.execute_reply.started":"2026-01-19T14:08:24.510372Z","shell.execute_reply":"2026-01-19T14:08:26.039942Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\nclass ArcFace(nn.Module):\n    def __init__(self, in_features=512, out_features=1000, s=64.0, m=0.5):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n\n        self.W = nn.Parameter(torch.randn(out_features, in_features))\n        nn.init.xavier_uniform_(self.W)\n\n    def forward(self, embeddings, labels):\n        embeddings = F.normalize(embeddings, p=2, dim=1)\n        W = F.normalize(self.W, p=2, dim=1)\n\n        cosine = F.linear(embeddings, W)\n        cosine = cosine.clamp(-1.0, 1.0)\n\n        theta = torch.acos(cosine)\n        target_cosine = torch.cos(theta + self.m)\n\n        one_hot = torch.zeros_like(cosine)\n        one_hot.scatter_(1, labels.view(-1, 1), 1.0)\n\n        logits = cosine * (1 - one_hot) + target_cosine * one_hot\n        logits = logits * self.s\n\n        return logits\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:08:29.880418Z","iopub.execute_input":"2026-01-19T14:08:29.881132Z","iopub.status.idle":"2026-01-19T14:08:29.887609Z","shell.execute_reply.started":"2026-01-19T14:08:29.881101Z","shell.execute_reply":"2026-01-19T14:08:29.886871Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\narc = ArcFace(in_features=512, out_features=10).to(device)\n\nemb = torch.randn(4, 512).to(device)\nlabels = torch.tensor([0,1,2,3]).to(device)\n\nlogits = arc(emb, labels)\n\nprint(\" Logits shape:\", logits.shape)  # (4, 10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:08:34.000854Z","iopub.execute_input":"2026-01-19T14:08:34.001383Z","iopub.status.idle":"2026-01-19T14:08:34.091081Z","shell.execute_reply.started":"2026-01-19T14:08:34.001355Z","shell.execute_reply":"2026-01-19T14:08:34.090366Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\n\nloss = loss_fn(logits, labels)\nprint(\" Loss:\", loss.item())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:08:36.703173Z","iopub.execute_input":"2026-01-19T14:08:36.703857Z","iopub.status.idle":"2026-01-19T14:08:36.755142Z","shell.execute_reply.started":"2026-01-19T14:08:36.703823Z","shell.execute_reply":"2026-01-19T14:08:36.754552Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip -q install torchvision\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:08:39.007126Z","iopub.execute_input":"2026-01-19T14:08:39.007408Z","iopub.status.idle":"2026-01-19T14:08:42.148678Z","shell.execute_reply.started":"2026-01-19T14:08:39.007383Z","shell.execute_reply":"2026-01-19T14:08:42.147919Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create src/dataset.py","metadata":{}},{"cell_type":"code","source":"import os\n\nPROJECT_DIR = \"/kaggle/working/FaceDetectionViT\"\ndataset_path = f\"{PROJECT_DIR}/src/dataset.py\"\n\ncode = r'''\nimport os\nimport random\nfrom PIL import Image\n\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\n\nclass WebFaceDataset(Dataset):\n    def __init__(self, root, id_list, id2label, img_size=224, augment=False):\n        self.root = root\n        self.id_list = id_list\n        self.id2label = id2label\n        self.augment = augment\n        \n        self.samples = []\n        for pid in self.id_list:\n            pdir = os.path.join(self.root, pid)\n            if not os.path.isdir(pdir):\n                continue\n            imgs = [x for x in os.listdir(pdir) if x.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n            for img in imgs:\n                self.samples.append((os.path.join(pdir, img), self.id2label[pid]))\n\n        base_tf = [\n            transforms.Resize((img_size, img_size)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n        ]\n\n        if augment:\n            self.transform = transforms.Compose([\n                transforms.RandomHorizontalFlip(p=0.5),\n                transforms.ColorJitter(brightness=0.2, contrast=0.2),\n                *base_tf\n            ])\n        else:\n            self.transform = transforms.Compose(base_tf)\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        img_path, label = self.samples[idx]\n        img = Image.open(img_path).convert(\"RGB\")\n        img = self.transform(img)\n        return img, torch.tensor(label, dtype=torch.long)\n'''\nwith open(dataset_path, \"w\") as f:\n    f.write(code)\n\nprint(\"Saved:\", dataset_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:08:42.188848Z","iopub.execute_input":"2026-01-19T14:08:42.189121Z","iopub.status.idle":"2026-01-19T14:08:42.195592Z","shell.execute_reply.started":"2026-01-19T14:08:42.189093Z","shell.execute_reply":"2026-01-19T14:08:42.194960Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\n\nPROJECT_DIR = \"/kaggle/working/FaceDetectionViT\"\nif PROJECT_DIR not in sys.path:\n    sys.path.append(PROJECT_DIR)\n\nfrom src.dataset import WebFaceDataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:08:45.619994Z","iopub.execute_input":"2026-01-19T14:08:45.620943Z","iopub.status.idle":"2026-01-19T14:08:45.628178Z","shell.execute_reply.started":"2026-01-19T14:08:45.620907Z","shell.execute_reply":"2026-01-19T14:08:45.627284Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport torch\nfrom torch.utils.data import DataLoader\n\nPROJECT_DIR = \"/kaggle/working/FaceDetectionViT\"\nsplit_path  = f\"{PROJECT_DIR}/data/annotations/split.json\"\nidmap_path  = f\"{PROJECT_DIR}/data/annotations/id_map.json\"\n\nsplits = json.load(open(split_path))\nidmap  = json.load(open(idmap_path))\n\nroot = splits[\"dataset_root\"]\ntrain_ids = splits[\"train_ids\"][:200]\n\ndataset = WebFaceDataset(\n    root=root,\n    id_list=train_ids,\n    id2label=idmap[\"id2label\"],\n    img_size=224,\n    augment=True\n)\n\nloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=2)\n\nx, y = next(iter(loader))\nprint(\" Batch images:\", x.shape)\nprint(\" Batch labels:\", y.shape)\nprint(\" Unique labels in batch:\", torch.unique(y))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:08:47.937166Z","iopub.execute_input":"2026-01-19T14:08:47.937496Z","iopub.status.idle":"2026-01-19T14:08:48.395411Z","shell.execute_reply.started":"2026-01-19T14:08:47.937457Z","shell.execute_reply":"2026-01-19T14:08:48.394639Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"src/config.py","metadata":{}},{"cell_type":"code","source":"%%writefile /kaggle/working/FaceDetectionViT/src/config.py\nPROJECT_DIR = \"/kaggle/working/FaceDetectionViT\"\n\nSPLIT_JSON   = f\"{PROJECT_DIR}/data/annotations/split.json\"\nIDMAP_JSON   = f\"{PROJECT_DIR}/data/annotations/id_map.json\"\n\nIMG_SIZE     = 224\nEMBED_DIM    = 512\n\nBATCH_SIZE   = 32\nLR           = 1e-4\nEPOCHS       = 1\nNUM_WORKERS  = 2\n\nARC_S        = 64.0\nARC_M        = 0.5\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:08:53.581540Z","iopub.execute_input":"2026-01-19T14:08:53.582128Z","iopub.status.idle":"2026-01-19T14:08:53.588005Z","shell.execute_reply.started":"2026-01-19T14:08:53.582092Z","shell.execute_reply":"2026-01-19T14:08:53.587104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/FaceDetectionViT/src/dataset.py\nimport os\nfrom PIL import Image\n\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\n\nclass WebFaceDataset(Dataset):\n    def __init__(self, root, id_list, id2label, img_size=224, augment=False):\n        self.root = root\n        self.id_list = id_list\n        self.id2label = id2label\n\n        self.samples = []\n        for pid in self.id_list:\n            pdir = os.path.join(self.root, pid)\n            if not os.path.isdir(pdir):\n                continue\n            imgs = [x for x in os.listdir(pdir) if x.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n            for img in imgs:\n                self.samples.append((os.path.join(pdir, img), self.id2label[pid]))\n\n        base_tf = [\n            transforms.Resize((img_size, img_size)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5]),\n        ]\n\n        if augment:\n            self.transform = transforms.Compose([\n                transforms.RandomHorizontalFlip(p=0.5),\n                transforms.ColorJitter(brightness=0.2, contrast=0.2),\n                *base_tf\n            ])\n        else:\n            self.transform = transforms.Compose(base_tf)\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        img_path, label = self.samples[idx]\n        img = Image.open(img_path).convert(\"RGB\")\n        img = self.transform(img)\n        return img, torch.tensor(label, dtype=torch.long)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:08:55.736936Z","iopub.execute_input":"2026-01-19T14:08:55.737245Z","iopub.status.idle":"2026-01-19T14:08:55.742534Z","shell.execute_reply.started":"2026-01-19T14:08:55.737218Z","shell.execute_reply":"2026-01-19T14:08:55.741820Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/FaceDetectionViT/src/model.py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport timm\n\nclass ViTFaceEmbedder(nn.Module):\n    def __init__(self, model_name=\"vit_small_patch16_224\", embed_dim=512):\n        super().__init__()\n\n        self.backbone = timm.create_model(\n            model_name,\n            pretrained=False,\n            num_classes=0\n        )\n\n        backbone_out = self.backbone.num_features\n\n        self.embedding = nn.Sequential(\n            nn.Linear(backbone_out, embed_dim),\n            nn.BatchNorm1d(embed_dim)\n        )\n\n    def forward(self, x):\n        feats = self.backbone(x)\n        emb = self.embedding(feats)\n        emb = F.normalize(emb, p=2, dim=1)\n        return emb\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:08:58.285813Z","iopub.execute_input":"2026-01-19T14:08:58.286471Z","iopub.status.idle":"2026-01-19T14:08:58.290983Z","shell.execute_reply.started":"2026-01-19T14:08:58.286440Z","shell.execute_reply":"2026-01-19T14:08:58.290311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/FaceDetectionViT/src/arcface.py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass ArcFace(nn.Module):\n    def __init__(self, in_features, out_features, s=64.0, m=0.5):\n        super().__init__()\n        self.s = s\n        self.m = m\n        self.W = nn.Parameter(torch.randn(out_features, in_features))\n        nn.init.xavier_uniform_(self.W)\n\n    def forward(self, embeddings, labels):\n        embeddings = F.normalize(embeddings, p=2, dim=1)\n        W = F.normalize(self.W, p=2, dim=1)\n\n        cosine = F.linear(embeddings, W).clamp(-1.0, 1.0)\n        theta = torch.acos(cosine)\n        target_cosine = torch.cos(theta + self.m)\n\n        one_hot = torch.zeros_like(cosine)\n        one_hot.scatter_(1, labels.view(-1, 1), 1.0)\n\n        logits = cosine * (1 - one_hot) + target_cosine * one_hot\n        return logits * self.s\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:09:02.008696Z","iopub.execute_input":"2026-01-19T14:09:02.009225Z","iopub.status.idle":"2026-01-19T14:09:02.014155Z","shell.execute_reply.started":"2026-01-19T14:09:02.009197Z","shell.execute_reply":"2026-01-19T14:09:02.013536Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"src/trainer.py","metadata":{}},{"cell_type":"code","source":"%%writefile /kaggle/working/FaceDetectionViT/src/arcface.py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass ArcFace(nn.Module):\n    def __init__(self, in_features, out_features, s=64.0, m=0.5):\n        super().__init__()\n        self.s = s\n        self.m = m\n        self.W = nn.Parameter(torch.randn(out_features, in_features))\n        nn.init.xavier_uniform_(self.W)\n\n    def forward(self, embeddings, labels):\n        embeddings = F.normalize(embeddings, p=2, dim=1)\n        W = F.normalize(self.W, p=2, dim=1)\n\n        cosine = F.linear(embeddings, W).clamp(-1.0, 1.0)\n        theta = torch.acos(cosine)\n        target_cosine = torch.cos(theta + self.m)\n\n        one_hot = torch.zeros_like(cosine)\n        one_hot.scatter_(1, labels.view(-1, 1), 1.0)\n\n        logits = cosine * (1 - one_hot) + target_cosine * one_hot\n        return logits * self.s\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:09:09.578041Z","iopub.execute_input":"2026-01-19T14:09:09.578716Z","iopub.status.idle":"2026-01-19T14:09:09.583306Z","shell.execute_reply.started":"2026-01-19T14:09:09.578677Z","shell.execute_reply":"2026-01-19T14:09:09.582734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lah /kaggle/working/FaceDetectionViT/src/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:09:15.463306Z","iopub.execute_input":"2026-01-19T14:09:15.463847Z","iopub.status.idle":"2026-01-19T14:09:15.602390Z","shell.execute_reply.started":"2026-01-19T14:09:15.463816Z","shell.execute_reply":"2026-01-19T14:09:15.601540Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/FaceDetectionViT/src/train.py\nimport os, sys, json\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom tqdm.auto import tqdm\n\nPROJECT_DIR = \"/kaggle/working/FaceDetectionViT\"\nif PROJECT_DIR not in sys.path:\n    sys.path.append(PROJECT_DIR)\n\nfrom src.config import *\nfrom src.dataset import WebFaceDataset\nfrom src.model import ViTFaceEmbedder\nfrom src.arcface import ArcFace\n\nclass Trainer:\n    def __init__(self, model, arcface, optimizer, device):\n        self.model = model\n        self.arcface = arcface\n        self.optimizer = optimizer\n        self.device = device\n        self.loss_fn = nn.CrossEntropyLoss()\n\n    def train_one_epoch(self, loader, epoch, epochs):\n        self.model.train()\n        self.arcface.train()\n\n        pbar = tqdm(loader, desc=f\"Epoch {epoch}/{epochs}\", leave=True)\n        total_loss = 0.0\n\n        for step, (imgs, labels) in enumerate(pbar, start=1):\n            imgs = imgs.to(self.device)\n            labels = labels.to(self.device)\n\n            emb = self.model(imgs)\n            logits = self.arcface(emb, labels)\n            loss = self.loss_fn(logits, labels)\n\n            self.optimizer.zero_grad()\n            loss.backward()\n            self.optimizer.step()\n\n            total_loss += loss.item()\n            avg_loss = total_loss / step\n\n            pbar.set_postfix(loss=f\"{loss.item():.4f}\", avg=f\"{avg_loss:.4f}\")\n\n        return total_loss / len(loader)\n\ndef main():\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n    splits = json.load(open(SPLIT_JSON))\n    idmap  = json.load(open(IDMAP_JSON))\n\n    root = splits[\"dataset_root\"]\n    train_ids = splits[\"train_ids\"][:2000]\n\n    trainset = WebFaceDataset(\n        root=root,\n        id_list=train_ids,\n        id2label=idmap[\"id2label\"],\n        img_size=IMG_SIZE,\n        augment=True\n    )\n\n    loader = DataLoader(\n        trainset,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        num_workers=NUM_WORKERS,\n        pin_memory=True\n    )\n\n    model = ViTFaceEmbedder(embed_dim=EMBED_DIM).to(device)\n    arc   = ArcFace(in_features=EMBED_DIM, out_features=len(idmap[\"id2label\"]), s=ARC_S, m=ARC_M).to(device)\n\n    optimizer = torch.optim.AdamW(list(model.parameters()) + list(arc.parameters()), lr=LR)\n\n    trainer = Trainer(model, arc, optimizer, device)\n\n    for epoch in range(1, EPOCHS + 1):\n        loss = trainer.train_one_epoch(loader, epoch, EPOCHS)\n        print(f\" Epoch {epoch}/{EPOCHS} | Avg Loss: {loss:.4f}\")\n\nif __name__ == \"__main__\":\n    main()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:09:19.245389Z","iopub.execute_input":"2026-01-19T14:09:19.245737Z","iopub.status.idle":"2026-01-19T14:09:19.252241Z","shell.execute_reply.started":"2026-01-19T14:09:19.245703Z","shell.execute_reply":"2026-01-19T14:09:19.251670Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/FaceDetectionViT/src/train.py\nimport os, sys, json\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom tqdm.auto import tqdm\n\nPROJECT_DIR = \"/kaggle/working/FaceDetectionViT\"\nif PROJECT_DIR not in sys.path:\n    sys.path.append(PROJECT_DIR)\n\nfrom src.config import *\nfrom src.dataset import WebFaceDataset\nfrom src.model import ViTFaceEmbedder\nfrom src.arcface import ArcFace\n\nos.makedirs(f\"{PROJECT_DIR}/models/checkpoints\", exist_ok=True)\n\nclass Trainer:\n    def __init__(self, model, arcface, optimizer, device):\n        self.model = model\n        self.arcface = arcface\n        self.optimizer = optimizer\n        self.device = device\n        self.loss_fn = nn.CrossEntropyLoss()\n\n    def train_one_epoch(self, loader, epoch, epochs, max_steps=50):\n        self.model.train()\n        self.arcface.train()\n\n        pbar = tqdm(loader, desc=f\"Epoch {epoch}/{epochs}\", leave=True)\n        total_loss = 0.0\n\n        for step, (imgs, labels) in enumerate(pbar, start=1):\n            imgs = imgs.to(self.device)\n            labels = labels.to(self.device)\n\n            emb = self.model(imgs)\n            logits = self.arcface(emb, labels)\n            loss = self.loss_fn(logits, labels)\n\n            self.optimizer.zero_grad()\n            loss.backward()\n            self.optimizer.step()\n\n            total_loss += loss.item()\n            avg_loss = total_loss / step\n            pbar.set_postfix(loss=f\"{loss.item():.4f}\", avg=f\"{avg_loss:.4f}\")\n\n            if step >= max_steps:\n                break\n\n        return total_loss / step\n\ndef main():\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n    splits = json.load(open(SPLIT_JSON))\n    idmap  = json.load(open(IDMAP_JSON))\n\n    root = splits[\"dataset_root\"]\n    train_ids = splits[\"train_ids\"][:300]\n\n    trainset = WebFaceDataset(\n        root=root,\n        id_list=train_ids,\n        id2label=idmap[\"id2label\"],\n        img_size=IMG_SIZE,\n        augment=True\n    )\n\n    loader = DataLoader(\n        trainset,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        num_workers=NUM_WORKERS,\n        pin_memory=True\n    )\n\n    model = ViTFaceEmbedder(embed_dim=EMBED_DIM).to(device)\n    arc   = ArcFace(in_features=EMBED_DIM, out_features=len(idmap[\"id2label\"]), s=ARC_S, m=ARC_M).to(device)\n\n    optimizer = torch.optim.AdamW(list(model.parameters()) + list(arc.parameters()), lr=LR)\n\n    trainer = Trainer(model, arc, optimizer, device)\n\n    loss = trainer.train_one_epoch(loader, 1, 1, max_steps=50)\n    print(f\" Mini Train Done | Avg Loss: {loss:.4f}\")\n\n    save_path = f\"{PROJECT_DIR}/models/checkpoints/ckpt_latest.pth\"\n    torch.save({\n        \"model\": model.state_dict(),\n        \"arcface\": arc.state_dict(),\n        \"optimizer\": optimizer.state_dict(),\n        \"epoch\": 1\n    }, save_path)\n\n    print(\" Saved:\", save_path)\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:09:23.717080Z","iopub.execute_input":"2026-01-19T14:09:23.717377Z","iopub.status.idle":"2026-01-19T14:09:23.723315Z","shell.execute_reply.started":"2026-01-19T14:09:23.717350Z","shell.execute_reply":"2026-01-19T14:09:23.722630Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/FaceDetectionViT/src/config.py\nPROJECT_DIR = \"/kaggle/working/FaceDetectionViT\"\n\nSPLIT_JSON   = f\"{PROJECT_DIR}/data/annotations/split.json\"\nIDMAP_JSON   = f\"{PROJECT_DIR}/data/annotations/id_map.json\"\n\nIMG_SIZE     = 224\nEMBED_DIM    = 512\n\nBATCH_SIZE   = 64\nLR           = 1e-4\nEPOCHS       = 1\nNUM_WORKERS  = 2\n\nARC_S        = 30.0\nARC_M        = 0.5\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:09:30.824759Z","iopub.execute_input":"2026-01-19T14:09:30.825270Z","iopub.status.idle":"2026-01-19T14:09:30.829987Z","shell.execute_reply.started":"2026-01-19T14:09:30.825242Z","shell.execute_reply":"2026-01-19T14:09:30.829376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python /kaggle/working/FaceDetectionViT/src/train.py\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:11:47.407978Z","iopub.execute_input":"2026-01-19T14:11:47.408764Z","iopub.status.idle":"2026-01-19T14:12:13.821065Z","shell.execute_reply.started":"2026-01-19T14:11:47.408728Z","shell.execute_reply":"2026-01-19T14:12:13.820102Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, sys, random, torch\nimport torch.nn.functional as F\nfrom PIL import Image\nfrom torchvision import transforms\n\nPROJECT_DIR = \"/kaggle/working/FaceDetectionViT\"\nif PROJECT_DIR not in sys.path:\n    sys.path.append(PROJECT_DIR)\n\nfrom src.model import ViTFaceEmbedder\n\nDATASET_ROOT = \"/kaggle/input/webface-112x112/webface_112x112\"\nCKPT_PATH = \"/kaggle/working/FaceDetectionViT/models/checkpoints/ckpt_latest.pth\"\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ntf = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n])\n\ndef pick_random_image():\n    pid = random.choice([d for d in os.listdir(DATASET_ROOT) if os.path.isdir(os.path.join(DATASET_ROOT, d))])\n    pdir = os.path.join(DATASET_ROOT, pid)\n    imgs = [x for x in os.listdir(pdir) if x.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n    return os.path.join(pdir, random.choice(imgs)), pid\n\n# Load model\nmodel = ViTFaceEmbedder(embed_dim=512).to(device)\nckpt = torch.load(CKPT_PATH, map_location=device)\nmodel.load_state_dict(ckpt[\"model\"])\nmodel.eval()\n\n# Build small gallery (Blacklist-like DB)\ngallery_paths = []\ngallery_ids = []\nall_ids = [d for d in os.listdir(DATASET_ROOT) if os.path.isdir(os.path.join(DATASET_ROOT, d))]\nsample_ids = random.sample(all_ids, 80)\n\nfor pid in sample_ids:\n    pdir = os.path.join(DATASET_ROOT, pid)\n    imgs = [x for x in os.listdir(pdir) if x.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n    if len(imgs) == 0:\n        continue\n    gallery_paths.append(os.path.join(pdir, imgs[0]))\n    gallery_ids.append(pid)\n\n# Gallery embeddings\ngallery_embs = []\nwith torch.no_grad():\n    for p in gallery_paths:\n        img = tf(Image.open(p).convert(\"RGB\")).unsqueeze(0).to(device)\n        emb = model(img)\n        gallery_embs.append(emb.cpu())\n\ngallery_embs = torch.cat(gallery_embs, dim=0).to(device)\n\n# Query\nquery_path, true_id = pick_random_image()\nqimg = tf(Image.open(query_path).convert(\"RGB\")).unsqueeze(0).to(device)\n\nwith torch.no_grad():\n    qemb = model(qimg)\n    sims = F.linear(qemb, gallery_embs).squeeze(0)\n    best_idx = int(torch.argmax(sims).cpu())\n\nprint(\" Query Image:\", query_path)\nprint(\" True ID:\", true_id)\nprint(\" Predicted ID:\", gallery_ids[best_idx])\nprint(\" Similarity:\", float(sims[best_idx].cpu()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:13:42.372356Z","iopub.execute_input":"2026-01-19T14:13:42.372933Z","iopub.status.idle":"2026-01-19T14:13:49.977477Z","shell.execute_reply.started":"2026-01-19T14:13:42.372885Z","shell.execute_reply":"2026-01-19T14:13:49.976837Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lh /kaggle/working/FaceDetectionViT/models/checkpoints/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:14:16.061391Z","iopub.execute_input":"2026-01-19T14:14:16.062195Z","iopub.status.idle":"2026-01-19T14:14:16.208706Z","shell.execute_reply.started":"2026-01-19T14:14:16.062164Z","shell.execute_reply":"2026-01-19T14:14:16.207979Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cp /kaggle/working/FaceDetectionViT/models/checkpoints/ckpt_latest.pth /kaggle/working/ckpt_latest.pth\n!ls -lh /kaggle/working/ckpt_latest.pth\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:14:40.632401Z","iopub.execute_input":"2026-01-19T14:14:40.632966Z","iopub.status.idle":"2026-01-19T14:14:41.179859Z","shell.execute_reply.started":"2026-01-19T14:14:40.632931Z","shell.execute_reply":"2026-01-19T14:14:41.178960Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"topk = 5\nvals, idxs = torch.topk(sims, k=topk)\n\nprint(\"\\nâœ… TOP-5 Matches:\")\nfor i in range(topk):\n    print(f\"{i+1}) ID={gallery_ids[int(idxs[i])]}  score={float(vals[i])}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:14:45.546505Z","iopub.execute_input":"2026-01-19T14:14:45.547180Z","iopub.status.idle":"2026-01-19T14:14:45.616832Z","shell.execute_reply.started":"2026-01-19T14:14:45.547145Z","shell.execute_reply":"2026-01-19T14:14:45.616097Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lah /kaggle/working/FaceDetectionViT/src/\n!ls -lah /kaggle/working/FaceDetectionViT/models/checkpoints/\n!ls -lah /kaggle/working/FaceDetectionViT/data/annotations/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:14:48.717930Z","iopub.execute_input":"2026-01-19T14:14:48.718218Z","iopub.status.idle":"2026-01-19T14:14:49.133322Z","shell.execute_reply.started":"2026-01-19T14:14:48.718192Z","shell.execute_reply":"2026-01-19T14:14:49.132710Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/Roli368/Biometric-Verification-Project.git /kaggle/working/leader_repo\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:15:25.030050Z","iopub.execute_input":"2026-01-19T14:15:25.030861Z","iopub.status.idle":"2026-01-19T14:15:26.538241Z","shell.execute_reply.started":"2026-01-19T14:15:25.030824Z","shell.execute_reply":"2026-01-19T14:15:26.537354Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/leader_repo\n!git checkout -b vit-ritik\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:15:29.680076Z","iopub.execute_input":"2026-01-19T14:15:29.680854Z","iopub.status.idle":"2026-01-19T14:15:29.826321Z","shell.execute_reply.started":"2026-01-19T14:15:29.680818Z","shell.execute_reply":"2026-01-19T14:15:29.825622Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p /kaggle/working/leader_repo/face_module\n!cp -r /kaggle/working/FaceDetectionViT/src /kaggle/working/leader_repo/face_module/\n!cp -r /kaggle/working/FaceDetectionViT/data/annotations /kaggle/working/leader_repo/face_module/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:15:33.937738Z","iopub.execute_input":"2026-01-19T14:15:33.938077Z","iopub.status.idle":"2026-01-19T14:15:34.354932Z","shell.execute_reply.started":"2026-01-19T14:15:33.938044Z","shell.execute_reply":"2026-01-19T14:15:34.354121Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/leader_repo/.gitignore\n__pycache__/\n*.pyc\n*.pth\nface_module/models/checkpoints/\nFaceDetectionViT/models/checkpoints/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T19:17:28.360169Z","iopub.execute_input":"2026-01-16T19:17:28.360877Z","iopub.status.idle":"2026-01-16T19:17:28.366022Z","shell.execute_reply.started":"2026-01-16T19:17:28.360843Z","shell.execute_reply":"2026-01-16T19:17:28.365329Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/ritikrockyraj/Biometric-Verification-Project.git /kaggle/working/my_repo\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T19:48:20.444205Z","iopub.execute_input":"2026-01-16T19:48:20.444430Z","iopub.status.idle":"2026-01-16T19:48:21.142215Z","shell.execute_reply.started":"2026-01-16T19:48:20.444405Z","shell.execute_reply":"2026-01-16T19:48:21.141566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/my_repo\n!git checkout -b vit-ritik\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T19:48:52.734214Z","iopub.execute_input":"2026-01-16T19:48:52.734859Z","iopub.status.idle":"2026-01-16T19:48:52.880368Z","shell.execute_reply.started":"2026-01-16T19:48:52.734825Z","shell.execute_reply":"2026-01-16T19:48:52.879468Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p /kaggle/working/my_repo/face_module\n!cp -r /kaggle/working/FaceDetectionViT/src /kaggle/working/my_repo/face_module/\n!cp -r /kaggle/working/FaceDetectionViT/data/annotations /kaggle/working/my_repo/face_module/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:17:38.542648Z","iopub.execute_input":"2026-01-19T14:17:38.543628Z","iopub.status.idle":"2026-01-19T14:17:38.972190Z","shell.execute_reply.started":"2026-01-19T14:17:38.543586Z","shell.execute_reply":"2026-01-19T14:17:38.971373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/my_repo/.gitignore\n__pycache__/\n*.pyc\n*.pth\nface_module/models/checkpoints/\nFaceDetectionViT/models/checkpoints/\nnode_modules/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:17:45.845906Z","iopub.execute_input":"2026-01-19T14:17:45.846769Z","iopub.status.idle":"2026-01-19T14:17:45.852017Z","shell.execute_reply.started":"2026-01-19T14:17:45.846728Z","shell.execute_reply":"2026-01-19T14:17:45.851397Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git config --global user.name \"Ritik\"\n!git config --global user.email \"ritikrockyraj@gmail.com\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:17:47.774176Z","iopub.execute_input":"2026-01-19T14:17:47.774814Z","iopub.status.idle":"2026-01-19T14:17:48.056625Z","shell.execute_reply.started":"2026-01-19T14:17:47.774784Z","shell.execute_reply":"2026-01-19T14:17:48.055824Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/my_repo\n!git add .\n!git commit -m \"Add face_module (ViT + ArcFace training pipeline)\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:17:51.179382Z","iopub.execute_input":"2026-01-19T14:17:51.180017Z","iopub.status.idle":"2026-01-19T14:17:51.469771Z","shell.execute_reply.started":"2026-01-19T14:17:51.179982Z","shell.execute_reply":"2026-01-19T14:17:51.468988Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git remote -v\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:17:54.173918Z","iopub.execute_input":"2026-01-19T14:17:54.174601Z","iopub.status.idle":"2026-01-19T14:17:54.319350Z","shell.execute_reply.started":"2026-01-19T14:17:54.174567Z","shell.execute_reply":"2026-01-19T14:17:54.318388Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/my_repo\n!git branch\n!git log --oneline -3\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:17:57.051989Z","iopub.execute_input":"2026-01-19T14:17:57.052389Z","iopub.status.idle":"2026-01-19T14:17:57.336435Z","shell.execute_reply.started":"2026-01-19T14:17:57.052356Z","shell.execute_reply":"2026-01-19T14:17:57.335727Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git status\n!git remote -v\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:17:59.621007Z","iopub.execute_input":"2026-01-19T14:17:59.621782Z","iopub.status.idle":"2026-01-19T14:17:59.904828Z","shell.execute_reply.started":"2026-01-19T14:17:59.621749Z","shell.execute_reply":"2026-01-19T14:17:59.903900Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p /kaggle/working/my_repo/face_module/src\n!mkdir -p /kaggle/working/my_repo/face_module/models/checkpoints\n!mkdir -p /kaggle/working/my_repo/face_module/models/exported\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:18:34.060016Z","iopub.execute_input":"2026-01-19T14:18:34.061121Z","iopub.status.idle":"2026-01-19T14:18:34.478254Z","shell.execute_reply.started":"2026-01-19T14:18:34.061083Z","shell.execute_reply":"2026-01-19T14:18:34.477271Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/my_repo/face_module/src/config.py\nimport os\n\nBASE_DIR = os.path.dirname(os.path.dirname(__file__))  # face_module/\n\nIMG_SIZE = 224\nEMBED_DIM = 512\nBACKBONE = \"vit_small_patch16_224\"\n\nCHECKPOINT_PATH = os.path.join(BASE_DIR, \"models\", \"checkpoints\", \"ckpt_latest.pth\")\nGALLERY_PATH    = os.path.join(BASE_DIR, \"models\", \"exported\", \"gallery.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:18:40.239765Z","iopub.execute_input":"2026-01-19T14:18:40.240307Z","iopub.status.idle":"2026-01-19T14:18:40.245949Z","shell.execute_reply.started":"2026-01-19T14:18:40.240272Z","shell.execute_reply":"2026-01-19T14:18:40.245211Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/my_repo/face_module/src/infer.py\nimport os\nimport torch\nimport torch.nn.functional as F\nfrom PIL import Image\nfrom torchvision import transforms\n\nfrom src.model import ViTFaceEmbedder\nfrom src.config import IMG_SIZE, EMBED_DIM, CHECKPOINT_PATH, GALLERY_PATH\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ntf = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n])\n\ndef load_model():\n    if not os.path.exists(CHECKPOINT_PATH):\n        raise FileNotFoundError(f\"Checkpoint missing: {CHECKPOINT_PATH}\")\n\n    model = ViTFaceEmbedder(embed_dim=EMBED_DIM).to(device)\n    ckpt = torch.load(CHECKPOINT_PATH, map_location=device)\n\n    if isinstance(ckpt, dict) and \"model\" in ckpt:\n        model.load_state_dict(ckpt[\"model\"])\n    else:\n        model.load_state_dict(ckpt)\n\n    model.eval()\n    return model\n\ndef embed_image(model, img_path):\n    img = Image.open(img_path).convert(\"RGB\")\n    x = tf(img).unsqueeze(0).to(device)\n    with torch.no_grad():\n        emb = model(x)\n    return emb\n\ndef predict(img_path):\n    model = load_model()\n    emb = embed_image(model, img_path)\n    return {\n        \"status\": \"ok\",\n        \"embedding_shape\": list(emb.shape),\n        \"embedding_norm\": float(emb.norm(dim=1).cpu())\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:18:44.477458Z","iopub.execute_input":"2026-01-19T14:18:44.477848Z","iopub.status.idle":"2026-01-19T14:18:44.483066Z","shell.execute_reply.started":"2026-01-19T14:18:44.477819Z","shell.execute_reply":"2026-01-19T14:18:44.482352Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lah /kaggle/working/my_repo/face_module/src/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:18:47.715088Z","iopub.execute_input":"2026-01-19T14:18:47.715678Z","iopub.status.idle":"2026-01-19T14:18:47.860401Z","shell.execute_reply.started":"2026-01-19T14:18:47.715630Z","shell.execute_reply":"2026-01-19T14:18:47.859722Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/my_repo\n!git status\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:18:49.645196Z","iopub.execute_input":"2026-01-19T14:18:49.645497Z","iopub.status.idle":"2026-01-19T14:18:49.791393Z","shell.execute_reply.started":"2026-01-19T14:18:49.645468Z","shell.execute_reply":"2026-01-19T14:18:49.790525Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/ritikrockyraj/Biometric-Verification-Project.git /kaggle/working/my_repo","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T08:09:07.958652Z","iopub.execute_input":"2026-01-19T08:09:07.959436Z","iopub.status.idle":"2026-01-19T08:09:08.076240Z","shell.execute_reply.started":"2026-01-19T08:09:07.959401Z","shell.execute_reply":"2026-01-19T08:09:08.075559Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p /kaggle/working/FaceDetectionViT/src\n!mkdir -p /kaggle/working/FaceDetectionViT/models/checkpoints\n!mkdir -p /kaggle/working/FaceDetectionViT/data/annotations\n!touch /kaggle/working/FaceDetectionViT/src/__init__.py\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T08:09:10.848028Z","iopub.execute_input":"2026-01-19T08:09:10.848604Z","iopub.status.idle":"2026-01-19T08:09:11.294521Z","shell.execute_reply.started":"2026-01-19T08:09:10.848571Z","shell.execute_reply":"2026-01-19T08:09:11.293803Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/my_repo\n!git status\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T08:09:14.563640Z","iopub.execute_input":"2026-01-19T08:09:14.563963Z","iopub.status.idle":"2026-01-19T08:09:14.682615Z","shell.execute_reply.started":"2026-01-19T08:09:14.563933Z","shell.execute_reply":"2026-01-19T08:09:14.681980Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, json, random\n\nPROJECT_DIR = \"/kaggle/working/FaceDetectionViT\"\nDATASET_ROOT = \"/kaggle/input/webface-112x112/webface_112x112\"\n\nann_dir = f\"{PROJECT_DIR}/data/annotations\"\nos.makedirs(ann_dir, exist_ok=True)\n\nall_ids = [d for d in os.listdir(DATASET_ROOT) if os.path.isdir(os.path.join(DATASET_ROOT, d))]\nall_ids = sorted(all_ids)\n\nrandom.seed(42)\nrandom.shuffle(all_ids)\n\nval_ratio = 0.1\nval_count = int(len(all_ids) * val_ratio)\n\nval_ids = all_ids[:val_count]\ntrain_ids = all_ids[val_count:]\n\nsplits = {\n    \"dataset_root\": DATASET_ROOT,\n    \"train_ids\": train_ids,\n    \"val_ids\": val_ids\n}\n\nwith open(f\"{ann_dir}/split.json\", \"w\") as f:\n    json.dump(splits, f, indent=2)\n\nid2label = {pid: i for i, pid in enumerate(all_ids)}\nlabel2id = {i: pid for pid, i in id2label.items()}\n\nidmap = {\"id2label\": id2label, \"label2id\": label2id}\n\nwith open(f\"{ann_dir}/id_map.json\", \"w\") as f:\n    json.dump(idmap, f, indent=2)\n\nprint(\"âœ… Saved split.json and id_map.json in:\", ann_dir)\nprint(\"Train IDs:\", len(train_ids), \"| Val IDs:\", len(val_ids))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:19:24.723801Z","iopub.execute_input":"2026-01-19T14:19:24.724135Z","iopub.status.idle":"2026-01-19T14:19:29.530942Z","shell.execute_reply.started":"2026-01-19T14:19:24.724104Z","shell.execute_reply":"2026-01-19T14:19:29.530169Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/FaceDetectionViT/src/dataset.py\nimport os\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nimport random\n\nclass WebFaceDataset(Dataset):\n    def __init__(self, root, id_list, id2label, img_size=224, augment=True):\n        self.root = root\n        self.id_list = id_list\n        self.id2label = id2label\n        self.img_size = img_size\n        self.augment = augment\n\n        self.samples = []\n        for pid in self.id_list:\n            person_dir = os.path.join(self.root, pid)\n            if not os.path.isdir(person_dir):\n                continue\n            for fn in os.listdir(person_dir):\n                if fn.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n                    self.samples.append((os.path.join(person_dir, fn), pid))\n\n        aug = []\n        if augment:\n            aug = [\n                transforms.RandomHorizontalFlip(p=0.5),\n            ]\n\n        self.tf = transforms.Compose(\n            aug + [\n                transforms.Resize((self.img_size, self.img_size)),\n                transforms.ToTensor(),\n                transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5]),\n            ]\n        )\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        path, pid = self.samples[idx]\n        img = Image.open(path).convert(\"RGB\")\n        x = self.tf(img)\n        y = int(self.id2label[pid])\n        return x, torch.tensor(y, dtype=torch.long)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:19:32.512701Z","iopub.execute_input":"2026-01-19T14:19:32.512987Z","iopub.status.idle":"2026-01-19T14:19:32.518774Z","shell.execute_reply.started":"2026-01-19T14:19:32.512962Z","shell.execute_reply":"2026-01-19T14:19:32.518048Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/FaceDetectionViT/src/config.py\nPROJECT_DIR = \"/kaggle/working/FaceDetectionViT\"\n\nDATASET_ROOT = \"/kaggle/input/webface-112x112/webface_112x112\"\nSPLIT_JSON   = f\"{PROJECT_DIR}/data/annotations/split.json\"\nIDMAP_JSON   = f\"{PROJECT_DIR}/data/annotations/id_map.json\"\n\nIMG_SIZE     = 224\nEMBED_DIM    = 512\nBACKBONE     = \"vit_small_patch16_224\"\n\nBATCH_SIZE   = 128\nLR           = 3e-4\nWEIGHT_DECAY = 0.05\nEPOCHS       = 10\nNUM_WORKERS  = 4\n\nARC_S        = 30.0\nARC_M        = 0.5\n\nUSE_AMP      = True\nGRAD_CLIP    = 1.0\n\nCKPT_LATEST  = f\"{PROJECT_DIR}/models/checkpoints/ckpt_latest.pth\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:19:35.981855Z","iopub.execute_input":"2026-01-19T14:19:35.982460Z","iopub.status.idle":"2026-01-19T14:19:35.987160Z","shell.execute_reply.started":"2026-01-19T14:19:35.982435Z","shell.execute_reply":"2026-01-19T14:19:35.986565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/FaceDetectionViT/src/arcface.py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\nclass ArcFace(nn.Module):\n    \"\"\"\n    Stable ArcFace implementation (no acos)\n    phi = cos(theta + m) = cosÎ¸*cosm - sinÎ¸*sinm\n    \"\"\"\n    def __init__(self, in_features, out_features, s=30.0, m=0.5, easy_margin=False):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.easy_margin = easy_margin\n\n        self.W = nn.Parameter(torch.randn(out_features, in_features))\n        nn.init.xavier_uniform_(self.W)\n\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = math.cos(math.pi - m)\n        self.mm = math.sin(math.pi - m) * m\n\n    def forward(self, embeddings, labels):\n        embeddings = F.normalize(embeddings, p=2, dim=1)\n        W = F.normalize(self.W, p=2, dim=1)\n\n        cosine = F.linear(embeddings, W).clamp(-1.0, 1.0)\n        sine = torch.sqrt(torch.clamp(1.0 - cosine * cosine, min=1e-9))\n\n        phi = cosine * self.cos_m - sine * self.sin_m\n\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n\n        one_hot = torch.zeros_like(cosine)\n        one_hot.scatter_(1, labels.view(-1, 1), 1.0)\n\n        logits = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        logits = logits * self.s\n        return logits\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:19:39.013511Z","iopub.execute_input":"2026-01-19T14:19:39.014118Z","iopub.status.idle":"2026-01-19T14:19:39.019256Z","shell.execute_reply.started":"2026-01-19T14:19:39.014088Z","shell.execute_reply":"2026-01-19T14:19:39.018580Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/FaceDetectionViT/src/model.py\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport timm\n\nclass ViTFaceEmbedder(nn.Module):\n    def __init__(self, model_name=\"vit_small_patch16_224\", embed_dim=512):\n        super().__init__()\n        self.backbone = timm.create_model(model_name, pretrained=False, num_classes=0)\n        out_dim = self.backbone.num_features\n        self.head = nn.Sequential(nn.Linear(out_dim, embed_dim), nn.BatchNorm1d(embed_dim))\n\n    def forward(self, x):\n        x = self.backbone(x)\n        x = self.head(x)\n        x = F.normalize(x, p=2, dim=1)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:19:42.199933Z","iopub.execute_input":"2026-01-19T14:19:42.200221Z","iopub.status.idle":"2026-01-19T14:19:42.205167Z","shell.execute_reply.started":"2026-01-19T14:19:42.200195Z","shell.execute_reply":"2026-01-19T14:19:42.204479Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/FaceDetectionViT/src/train.py\nimport os, json\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom tqdm.auto import tqdm\n\nfrom src.config import *\nfrom src.dataset import WebFaceDataset\nfrom src.model import ViTFaceEmbedder\nfrom src.arcface import ArcFace\n\ndef save_ckpt(epoch, model, arcface, optimizer):\n    os.makedirs(os.path.dirname(CKPT_LATEST), exist_ok=True)\n    torch.save({\n        \"epoch\": epoch,\n        \"model\": model.state_dict(),\n        \"arcface\": arcface.state_dict(),\n        \"optimizer\": optimizer.state_dict(),\n    }, CKPT_LATEST)\n\ndef load_ckpt(model, arcface, optimizer, device):\n    ckpt = torch.load(CKPT_LATEST, map_location=device)\n    model.load_state_dict(ckpt[\"model\"])\n    arcface.load_state_dict(ckpt[\"arcface\"])\n    optimizer.load_state_dict(ckpt[\"optimizer\"])\n    return ckpt[\"epoch\"] + 1\n\ndef main():\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(\"âœ… Device:\", device)\n\n    splits = json.load(open(SPLIT_JSON))\n    idmap  = json.load(open(IDMAP_JSON))\n\n    trainset = WebFaceDataset(\n        root=splits[\"dataset_root\"],\n        id_list=splits[\"train_ids\"],\n        id2label=idmap[\"id2label\"],\n        img_size=IMG_SIZE,\n        augment=True\n    )\n\n    loader = DataLoader(\n        trainset,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        num_workers=NUM_WORKERS,\n        pin_memory=True,\n        persistent_workers=True\n    )\n\n    model = ViTFaceEmbedder(model_name=BACKBONE, embed_dim=EMBED_DIM).to(device)\n    arcface = ArcFace(EMBED_DIM, out_features=len(idmap[\"id2label\"]), s=ARC_S, m=ARC_M).to(device)\n\n    optimizer = torch.optim.AdamW(\n        list(model.parameters()) + list(arcface.parameters()),\n        lr=LR,\n        weight_decay=WEIGHT_DECAY\n    )\n\n    loss_fn = nn.CrossEntropyLoss()\n    scaler = torch.amp.GradScaler(\"cuda\", enabled=(USE_AMP and device == \"cuda\"))\n\n    start_epoch = 1\n    if os.path.exists(CKPT_LATEST):\n        print(\"âœ… Resuming from:\", CKPT_LATEST)\n        start_epoch = load_ckpt(model, arcface, optimizer, device)\n        print(\"âœ… Start epoch:\", start_epoch)\n\n    for epoch in range(start_epoch, EPOCHS + 1):\n        model.train()\n        arcface.train()\n\n        pbar = tqdm(loader, desc=f\"Epoch {epoch}/{EPOCHS}\")\n        total = 0.0\n\n        for step, (imgs, labels) in enumerate(pbar, start=1):\n            imgs = imgs.to(device, non_blocking=True)\n            labels = labels.to(device, non_blocking=True)\n\n            optimizer.zero_grad(set_to_none=True)\n\n            with torch.amp.autocast(\"cuda\", enabled=(USE_AMP and device == \"cuda\")):\n                emb = model(imgs)\n                logits = arcface(emb, labels)\n                loss = loss_fn(logits, labels)\n\n            scaler.scale(loss).backward()\n\n            if GRAD_CLIP and GRAD_CLIP > 0:\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n\n            scaler.step(optimizer)\n            scaler.update()\n\n            total += loss.item()\n            pbar.set_postfix(loss=f\"{loss.item():.4f}\", avg=f\"{total/step:.4f}\")\n\n        save_ckpt(epoch, model, arcface, optimizer)\n        print(\"ðŸ’¾ Saved checkpoint:\", CKPT_LATEST)\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:19:44.614781Z","iopub.execute_input":"2026-01-19T14:19:44.615447Z","iopub.status.idle":"2026-01-19T14:19:44.621134Z","shell.execute_reply.started":"2026-01-19T14:19:44.615417Z","shell.execute_reply":"2026-01-19T14:19:44.620590Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/FaceDetectionViT/src/model.py\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport timm\n\nclass ViTFaceEmbedder(nn.Module):\n    def __init__(self, model_name=\"vit_small_patch16_224\", embed_dim=512):\n        super().__init__()\n\n        self.backbone = timm.create_model(\n            model_name,\n            pretrained=False,\n            num_classes=0\n        )\n\n        out_dim = self.backbone.num_features\n\n        self.embedding = nn.Sequential(\n            nn.Linear(out_dim, embed_dim),\n            nn.BatchNorm1d(embed_dim)\n        )\n\n    def forward(self, x):\n        feats = self.backbone(x)\n        emb = self.embedding(feats)\n        emb = F.normalize(emb, p=2, dim=1)\n        return emb\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:22:18.874548Z","iopub.execute_input":"2026-01-19T14:22:18.875412Z","iopub.status.idle":"2026-01-19T14:22:18.880704Z","shell.execute_reply.started":"2026-01-19T14:22:18.875372Z","shell.execute_reply":"2026-01-19T14:22:18.880108Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/FaceDetectionViT\n!python -m src.train\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:22:22.559444Z","iopub.execute_input":"2026-01-19T14:22:22.560141Z","iopub.status.idle":"2026-01-19T14:25:11.305212Z","shell.execute_reply.started":"2026-01-19T14:22:22.560114Z","shell.execute_reply":"2026-01-19T14:25:11.304389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lh /kaggle/working/FaceDetectionViT/models/checkpoints/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:25:17.918403Z","iopub.execute_input":"2026-01-19T14:25:17.918734Z","iopub.status.idle":"2026-01-19T14:25:18.064393Z","shell.execute_reply.started":"2026-01-19T14:25:17.918702Z","shell.execute_reply":"2026-01-19T14:25:18.063572Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p /kaggle/working/my_repo/face_module/models/checkpoints\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:30:49.009109Z","iopub.execute_input":"2026-01-19T14:30:49.009995Z","iopub.status.idle":"2026-01-19T14:30:49.154105Z","shell.execute_reply.started":"2026-01-19T14:30:49.009958Z","shell.execute_reply":"2026-01-19T14:30:49.153186Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cp /kaggle/working/ckpt_latest.pth /kaggle/working/my_repo/face_module/models/checkpoints/ckpt_latest.pth\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:31:01.260908Z","iopub.execute_input":"2026-01-19T14:31:01.261221Z","iopub.status.idle":"2026-01-19T14:31:01.616589Z","shell.execute_reply.started":"2026-01-19T14:31:01.261190Z","shell.execute_reply":"2026-01-19T14:31:01.615836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lh /kaggle/working/my_repo/face_module/models/checkpoints/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:31:09.926927Z","iopub.execute_input":"2026-01-19T14:31:09.927263Z","iopub.status.idle":"2026-01-19T14:31:10.072186Z","shell.execute_reply.started":"2026-01-19T14:31:09.927231Z","shell.execute_reply":"2026-01-19T14:31:10.071340Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lah /kaggle/working/my_repo | head\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:32:13.132159Z","iopub.execute_input":"2026-01-19T14:32:13.132876Z","iopub.status.idle":"2026-01-19T14:32:13.285683Z","shell.execute_reply.started":"2026-01-19T14:32:13.132839Z","shell.execute_reply":"2026-01-19T14:32:13.284943Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/my_repo\n!pwd\n!ls -lah | head\n!git status\n%cd /kaggle/working\n!rm -rf my_repo\n!git clone https://github.com/ritikrockyraj/Biometric-Verification-Project.git my_repo\n%cd /kaggle/working/my_repo\n!git checkout vit-ritik\n!git status\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:32:57.507999Z","iopub.execute_input":"2026-01-19T14:32:57.508779Z","iopub.status.idle":"2026-01-19T14:32:59.625605Z","shell.execute_reply.started":"2026-01-19T14:32:57.508744Z","shell.execute_reply":"2026-01-19T14:32:59.624729Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p /kaggle/working/my_repo/face_module/src\n\n!cp /kaggle/working/FaceDetectionViT/src/config.py  /kaggle/working/my_repo/face_module/src/config.py\n!cp /kaggle/working/FaceDetectionViT/src/model.py   /kaggle/working/my_repo/face_module/src/model.py\n!cp /kaggle/working/FaceDetectionViT/src/arcface.py  /kaggle/working/my_repo/face_module/src/arcface.py\n!cp /kaggle/working/FaceDetectionViT/src/dataset.py  /kaggle/working/my_repo/face_module/src/dataset.py\n!cp /kaggle/working/FaceDetectionViT/src/train.py    /kaggle/working/my_repo/face_module/src/train.py\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:34:12.222525Z","iopub.execute_input":"2026-01-19T14:34:12.223235Z","iopub.status.idle":"2026-01-19T14:34:13.062861Z","shell.execute_reply.started":"2026-01-19T14:34:12.223199Z","shell.execute_reply":"2026-01-19T14:34:13.061879Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/my_repo\n!git status\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:34:22.598879Z","iopub.execute_input":"2026-01-19T14:34:22.599647Z","iopub.status.idle":"2026-01-19T14:34:22.778709Z","shell.execute_reply.started":"2026-01-19T14:34:22.599608Z","shell.execute_reply":"2026-01-19T14:34:22.777670Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git add face_module/src\n!git commit -m \"Update training pipeline + model code\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:34:37.111214Z","iopub.execute_input":"2026-01-19T14:34:37.112060Z","iopub.status.idle":"2026-01-19T14:34:37.405102Z","shell.execute_reply.started":"2026-01-19T14:34:37.112022Z","shell.execute_reply":"2026-01-19T14:34:37.404213Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git push origin vit-ritik\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:34:52.121188Z","iopub.execute_input":"2026-01-19T14:34:52.121503Z","iopub.status.idle":"2026-01-19T14:35:51.644803Z","shell.execute_reply.started":"2026-01-19T14:34:52.121470Z","shell.execute_reply":"2026-01-19T14:35:51.644065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git config --global user.name \"Ritik\"\n!git config --global user.email \"ritik@gmail.com\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:36:46.622695Z","iopub.execute_input":"2026-01-19T14:36:46.622990Z","iopub.status.idle":"2026-01-19T14:36:46.904219Z","shell.execute_reply.started":"2026-01-19T14:36:46.622964Z","shell.execute_reply":"2026-01-19T14:36:46.903473Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p /kaggle/working/my_repo/face_module/src\n\n!cp /kaggle/working/FaceDetectionViT/src/config.py  /kaggle/working/my_repo/face_module/src/config.py\n!cp /kaggle/working/FaceDetectionViT/src/model.py   /kaggle/working/my_repo/face_module/src/model.py\n!cp /kaggle/working/FaceDetectionViT/src/arcface.py  /kaggle/working/my_repo/face_module/src/arcface.py\n!cp /kaggle/working/FaceDetectionViT/src/dataset.py  /kaggle/working/my_repo/face_module/src/dataset.py\n!cp /kaggle/working/FaceDetectionViT/src/train.py    /kaggle/working/my_repo/face_module/src/train.py\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:37:03.089068Z","iopub.execute_input":"2026-01-19T14:37:03.089389Z","iopub.status.idle":"2026-01-19T14:37:03.913365Z","shell.execute_reply.started":"2026-01-19T14:37:03.089355Z","shell.execute_reply":"2026-01-19T14:37:03.912647Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/my_repo\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:41:24.357083Z","iopub.execute_input":"2026-01-19T14:41:24.357371Z","iopub.status.idle":"2026-01-19T14:41:24.362631Z","shell.execute_reply.started":"2026-01-19T14:41:24.357345Z","shell.execute_reply":"2026-01-19T14:41:24.361997Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git remote set-url origin https://ritikrockyraj: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@github.com/ritikrockyraj/Biometric-Verification-Project.git\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:42:04.924725Z","iopub.execute_input":"2026-01-19T14:42:04.925488Z","iopub.status.idle":"2026-01-19T14:42:05.069020Z","shell.execute_reply.started":"2026-01-19T14:42:04.925458Z","shell.execute_reply":"2026-01-19T14:42:05.068253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git push origin vit-ritik\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:42:25.226181Z","iopub.execute_input":"2026-01-19T14:42:25.227070Z","iopub.status.idle":"2026-01-19T14:42:26.550447Z","shell.execute_reply.started":"2026-01-19T14:42:25.227032Z","shell.execute_reply":"2026-01-19T14:42:26.549571Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git remote set-url origin https://github.com/ritikrockyraj/Biometric-Verification-Project.git\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:42:40.101587Z","iopub.execute_input":"2026-01-19T14:42:40.101898Z","iopub.status.idle":"2026-01-19T14:42:40.246494Z","shell.execute_reply.started":"2026-01-19T14:42:40.101869Z","shell.execute_reply":"2026-01-19T14:42:40.245751Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git add face_module/src\n!git commit -m \"Update ViT + ArcFace training code\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:37:12.959020Z","iopub.execute_input":"2026-01-19T14:37:12.959311Z","iopub.status.idle":"2026-01-19T14:37:13.243736Z","shell.execute_reply.started":"2026-01-19T14:37:12.959282Z","shell.execute_reply":"2026-01-19T14:37:13.243025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/my_repo\n!git status\n!git add face_module/src face_module/annotations\n!git commit -m \"Update face_module code + annotations\"\n!git push origin vit-ritik\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:31:22.215516Z","iopub.execute_input":"2026-01-19T14:31:22.216348Z","iopub.status.idle":"2026-01-19T14:31:22.768525Z","shell.execute_reply.started":"2026-01-19T14:31:22.216297Z","shell.execute_reply":"2026-01-19T14:31:22.767688Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/my_repo\n!git status\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T14:27:14.848896Z","iopub.execute_input":"2026-01-19T14:27:14.849620Z","iopub.status.idle":"2026-01-19T14:27:14.994684Z","shell.execute_reply.started":"2026-01-19T14:27:14.849583Z","shell.execute_reply":"2026-01-19T14:27:14.993862Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lh /kaggle/working/FaceDetectionViT/models/checkpoints/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T10:06:35.556543Z","iopub.execute_input":"2026-01-19T10:06:35.557216Z","iopub.status.idle":"2026-01-19T10:06:35.682025Z","shell.execute_reply.started":"2026-01-19T10:06:35.557185Z","shell.execute_reply":"2026-01-19T10:06:35.681324Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cp /kaggle/working/FaceDetectionViT/models/checkpoints/ckpt_latest.pth /kaggle/working/ckpt_latest.pth\n!ls -lh /kaggle/working/ckpt_latest.pth\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T10:07:02.261342Z","iopub.execute_input":"2026-01-19T10:07:02.262168Z","iopub.status.idle":"2026-01-19T10:07:02.723895Z","shell.execute_reply.started":"2026-01-19T10:07:02.262128Z","shell.execute_reply":"2026-01-19T10:07:02.722992Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lh /kaggle/working/ckpt_latest.pth\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T10:20:28.782603Z","iopub.execute_input":"2026-01-19T10:20:28.783404Z","iopub.status.idle":"2026-01-19T10:20:28.899422Z","shell.execute_reply.started":"2026-01-19T10:20:28.783365Z","shell.execute_reply":"2026-01-19T10:20:28.898592Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p /kaggle/working/my_repo/face_module/src\n\n!cp /kaggle/working/FaceDetectionViT/src/config.py  /kaggle/working/my_repo/face_module/src/config.py\n!cp /kaggle/working/FaceDetectionViT/src/model.py   /kaggle/working/my_repo/face_module/src/model.py\n!cp /kaggle/working/FaceDetectionViT/src/arcface.py  /kaggle/working/my_repo/face_module/src/arcface.py\n!cp /kaggle/working/FaceDetectionViT/src/dataset.py  /kaggle/working/my_repo/face_module/src/dataset.py\n!cp /kaggle/working/FaceDetectionViT/src/train.py    /kaggle/working/my_repo/face_module/src/train.py\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T11:18:03.043917Z","iopub.execute_input":"2026-01-19T11:18:03.044646Z","iopub.status.idle":"2026-01-19T11:18:03.715724Z","shell.execute_reply.started":"2026-01-19T11:18:03.044617Z","shell.execute_reply":"2026-01-19T11:18:03.714806Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/my_repo\n!git status\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T11:18:29.037280Z","iopub.execute_input":"2026-01-19T11:18:29.038055Z","iopub.status.idle":"2026-01-19T11:18:29.157701Z","shell.execute_reply.started":"2026-01-19T11:18:29.038019Z","shell.execute_reply":"2026-01-19T11:18:29.156981Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/my_repo\n!git status\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T11:15:50.307612Z","iopub.execute_input":"2026-01-19T11:15:50.308271Z","iopub.status.idle":"2026-01-19T11:15:50.427420Z","shell.execute_reply.started":"2026-01-19T11:15:50.308238Z","shell.execute_reply":"2026-01-19T11:15:50.426706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -j /kaggle/working/ckpt_latest.zip /kaggle/working/ckpt_latest.pth\n!ls -lh /kaggle/working/ckpt_latest.zip\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T10:38:39.805315Z","iopub.execute_input":"2026-01-19T10:38:39.805624Z","iopub.status.idle":"2026-01-19T10:38:57.118447Z","shell.execute_reply.started":"2026-01-19T10:38:39.805595Z","shell.execute_reply":"2026-01-19T10:38:57.117782Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lh /kaggle/working/ckpt_latest.zip\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T10:41:41.777007Z","iopub.execute_input":"2026-01-19T10:41:41.777809Z","iopub.status.idle":"2026-01-19T10:41:41.894448Z","shell.execute_reply.started":"2026-01-19T10:41:41.777773Z","shell.execute_reply":"2026-01-19T10:41:41.893618Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/FaceDetectionViT\n!python -m src.train\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T13:46:35.191168Z","iopub.status.idle":"2026-01-19T13:46:35.191554Z","shell.execute_reply.started":"2026-01-19T13:46:35.191307Z","shell.execute_reply":"2026-01-19T13:46:35.191320Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working\n!rm -rf my_repo\n!git clone https://github.com/ritikrockyraj/Biometric-Verification-Project.git my_repo\n%cd /kaggle/working/my_repo\n!git checkout vit-ritik\n!ls -lah\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T11:36:31.334034Z","iopub.execute_input":"2026-01-19T11:36:31.334637Z","iopub.status.idle":"2026-01-19T11:36:32.281779Z","shell.execute_reply.started":"2026-01-19T11:36:31.334604Z","shell.execute_reply":"2026-01-19T11:36:32.281118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip -q install timm pillow\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T11:36:39.465620Z","iopub.execute_input":"2026-01-19T11:36:39.465927Z","iopub.status.idle":"2026-01-19T11:36:43.485684Z","shell.execute_reply.started":"2026-01-19T11:36:39.465898Z","shell.execute_reply":"2026-01-19T11:36:43.484813Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/my_repo/face_module\n!ls -lah\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T11:36:50.796030Z","iopub.execute_input":"2026-01-19T11:36:50.796611Z","iopub.status.idle":"2026-01-19T11:36:50.914136Z","shell.execute_reply.started":"2026-01-19T11:36:50.796577Z","shell.execute_reply":"2026-01-19T11:36:50.913221Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lh /kaggle/working/my_repo/face_module/models/checkpoints/\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T13:42:52.019017Z","iopub.execute_input":"2026-01-19T13:42:52.019250Z","iopub.status.idle":"2026-01-19T13:42:52.140587Z","shell.execute_reply.started":"2026-01-19T13:42:52.019229Z","shell.execute_reply":"2026-01-19T13:42:52.139942Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working\n!rm -rf test_repo\n!git clone https://github.com/ritikrockyraj/Biometric-Verification-Project.git test_repo\n%cd /kaggle/working/test_repo\n!git checkout vit-ritik\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T10:01:00.391079Z","iopub.execute_input":"2026-01-20T10:01:00.391348Z","iopub.status.idle":"2026-01-20T10:01:02.112868Z","shell.execute_reply.started":"2026-01-20T10:01:00.391323Z","shell.execute_reply":"2026-01-20T10:01:02.111794Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'test_repo'...\nremote: Enumerating objects: 184, done.\u001b[K\nremote: Counting objects: 100% (184/184), done.\u001b[K\nremote: Compressing objects: 100% (125/125), done.\u001b[K\nremote: Total 184 (delta 53), reused 181 (delta 50), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (184/184), 1.00 MiB | 5.66 MiB/s, done.\nResolving deltas: 100% (53/53), done.\n/kaggle/working/test_repo\nBranch 'vit-ritik' set up to track remote branch 'vit-ritik' from 'origin'.\nSwitched to a new branch 'vit-ritik'\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!ls -lh face_module/models/checkpoints/\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T10:15:47.250465Z","iopub.execute_input":"2026-01-20T10:15:47.250807Z","iopub.status.idle":"2026-01-20T10:15:47.368340Z","shell.execute_reply.started":"2026-01-20T10:15:47.250764Z","shell.execute_reply":"2026-01-20T10:15:47.367405Z"}},"outputs":[{"name":"stdout","text":"total 0\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!find /kaggle/input/yup1223 -type f -name \"*.pth\"\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T10:22:53.701790Z","iopub.execute_input":"2026-01-20T10:22:53.702906Z","iopub.status.idle":"2026-01-20T10:22:53.857110Z","shell.execute_reply.started":"2026-01-20T10:22:53.702861Z","shell.execute_reply":"2026-01-20T10:22:53.856210Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/yup1223/ckpt_latest.pth\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"!ls -lh /kaggle/working/test_repo/face_module/models/checkpoints/ckpt_latest.pth\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T10:23:24.940831Z","iopub.execute_input":"2026-01-20T10:23:24.941718Z","iopub.status.idle":"2026-01-20T10:23:25.059415Z","shell.execute_reply.started":"2026-01-20T10:23:24.941677Z","shell.execute_reply":"2026-01-20T10:23:25.058482Z"}},"outputs":[{"name":"stdout","text":"ls: cannot access '/kaggle/working/test_repo/face_module/models/checkpoints/ckpt_latest.pth': No such file or directory\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"!cp -v /kaggle/input/yup1223/ckpt_latest.pth /kaggle/working/test_repo/face_module/models/checkpoints/ckpt_latest.pth\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T10:23:55.252267Z","iopub.execute_input":"2026-01-20T10:23:55.253024Z","iopub.status.idle":"2026-01-20T10:24:00.842630Z","shell.execute_reply.started":"2026-01-20T10:23:55.252978Z","shell.execute_reply":"2026-01-20T10:24:00.841625Z"}},"outputs":[{"name":"stdout","text":"'/kaggle/input/yup1223/ckpt_latest.pth' -> '/kaggle/working/test_repo/face_module/models/checkpoints/ckpt_latest.pth'\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"!ls -lh /kaggle/working/test_repo/face_module/models/checkpoints/ckpt_latest.pth\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T10:24:23.779512Z","iopub.execute_input":"2026-01-20T10:24:23.780332Z","iopub.status.idle":"2026-01-20T10:24:23.900445Z","shell.execute_reply.started":"2026-01-20T10:24:23.780291Z","shell.execute_reply":"2026-01-20T10:24:23.899236Z"}},"outputs":[{"name":"stdout","text":"-rw-r--r-- 1 root root 313M Jan 20 10:24 /kaggle/working/test_repo/face_module/models/checkpoints/ckpt_latest.pth\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"%cd /kaggle/working/test_repo\n!git branch\n!ls -lah\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T10:26:43.117364Z","iopub.execute_input":"2026-01-20T10:26:43.117814Z","iopub.status.idle":"2026-01-20T10:26:43.354635Z","shell.execute_reply.started":"2026-01-20T10:26:43.117772Z","shell.execute_reply":"2026-01-20T10:26:43.353570Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/test_repo\n  main\u001b[m\n* \u001b[32mvit-ritik\u001b[m\ntotal 44K\ndrwxr-xr-x 8 root root 4.0K Jan 20 10:01 .\ndrwxr-xr-x 4 root root 4.0K Jan 20 10:01 ..\ndrwxr-xr-x 3 root root 4.0K Jan 20 10:01 backend\ndrwxr-xr-x 2 root root 4.0K Jan 20 10:01 docker\ndrwxr-xr-x 5 root root 4.0K Jan 20 10:02 face_module\ndrwxr-xr-x 3 root root 4.0K Jan 20 10:01 frontend\ndrwxr-xr-x 8 root root 4.0K Jan 20 10:01 .git\n-rw-r--r-- 1 root root  108 Jan 20 10:01 .gitignore\ndrwxr-xr-x 6 root root 4.0K Jan 20 10:01 node_modules\n-rw-r--r-- 1 root root   57 Jan 20 10:01 package.json\n-rw-r--r-- 1 root root 1.7K Jan 20 10:01 package-lock.json\n-rw-r--r-- 1 root root    0 Jan 20 10:01 README.md\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"!ls -lah face_module/src\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T10:26:55.004981Z","iopub.execute_input":"2026-01-20T10:26:55.005528Z","iopub.status.idle":"2026-01-20T10:26:55.124622Z","shell.execute_reply.started":"2026-01-20T10:26:55.005484Z","shell.execute_reply":"2026-01-20T10:26:55.123629Z"}},"outputs":[{"name":"stdout","text":"total 36K\ndrwxr-xr-x 3 root root 4.0K Jan 20 10:24 .\ndrwxr-xr-x 5 root root 4.0K Jan 20 10:02 ..\n-rw-r--r-- 1 root root 1.5K Jan 20 10:01 arcface.py\n-rw-r--r-- 1 root root  555 Jan 20 10:01 config.py\n-rw-r--r-- 1 root root 1.5K Jan 20 10:01 dataset.py\n-rw-r--r-- 1 root root 1.3K Jan 20 10:01 infer.py\n-rw-r--r-- 1 root root  673 Jan 20 10:01 model.py\ndrwxr-xr-x 2 root root 4.0K Jan 20 10:24 __pycache__\n-rw-r--r-- 1 root root 3.2K Jan 20 10:01 train.py\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"%%writefile /kaggle/working/test_repo/face_module/src/infer.py\nimport os\nimport torch\nimport torch.nn.functional as F\nfrom PIL import Image\nfrom torchvision import transforms\n\nfrom face_module.src.model import ViTFaceEmbedder\nfrom face_module.src.config import IMG_SIZE, EMBED_DIM, CHECKPOINT_PATH\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ntf = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n])\n\n_model = None\n\ndef load_model():\n    global _model\n    if _model is not None:\n        return _model\n\n    if not os.path.exists(CHECKPOINT_PATH):\n        raise FileNotFoundError(f\"Checkpoint missing: {CHECKPOINT_PATH}\")\n\n    model = ViTFaceEmbedder(embed_dim=EMBED_DIM).to(device)\n\n    ckpt = torch.load(CHECKPOINT_PATH, map_location=device)\n    if isinstance(ckpt, dict) and \"model\" in ckpt:\n        model.load_state_dict(ckpt[\"model\"])\n    else:\n        model.load_state_dict(ckpt)\n\n    model.eval()\n    _model = model\n    return model\n\ndef predict(img_path):\n    model = load_model()\n    img = Image.open(img_path).convert(\"RGB\")\n    x = tf(img).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        emb = model(x)\n\n    return {\n        \"embedding_shape\": list(emb.shape),\n        \"embedding_norm\": float(emb.norm(dim=1).cpu())\n    }\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T10:29:39.915434Z","iopub.execute_input":"2026-01-20T10:29:39.916194Z","iopub.status.idle":"2026-01-20T10:29:39.925162Z","shell.execute_reply.started":"2026-01-20T10:29:39.916139Z","shell.execute_reply":"2026-01-20T10:29:39.924240Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/test_repo/face_module/src/infer.py\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"%%writefile /kaggle/working/test_repo/face_module/src/config.py\nimport os\n\nBASE_DIR = os.path.dirname(os.path.dirname(__file__))  # face_module/\n\nIMG_SIZE  = 224\nEMBED_DIM = 512\nBACKBONE  = \"vit_small_patch16_224\"\n\nCHECKPOINT_PATH = os.path.join(BASE_DIR, \"models\", \"checkpoints\", \"ckpt_latest.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T10:30:55.402251Z","iopub.execute_input":"2026-01-20T10:30:55.402697Z","iopub.status.idle":"2026-01-20T10:30:55.409238Z","shell.execute_reply.started":"2026-01-20T10:30:55.402657Z","shell.execute_reply":"2026-01-20T10:30:55.408450Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/test_repo/face_module/src/config.py\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"!mkdir -p /kaggle/working/test_repo/face_module/models/checkpoints\n!ls -lh /kaggle/working/test_repo/face_module/models/checkpoints/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T10:31:08.151135Z","iopub.execute_input":"2026-01-20T10:31:08.151721Z","iopub.status.idle":"2026-01-20T10:31:08.381576Z","shell.execute_reply.started":"2026-01-20T10:31:08.151688Z","shell.execute_reply":"2026-01-20T10:31:08.380659Z"}},"outputs":[{"name":"stdout","text":"total 313M\n-rw-r--r-- 1 root root 313M Jan 20 10:24 ckpt_latest.pth\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"%%writefile /kaggle/working/test_repo/face_module/src/model.py\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport timm\n\nclass ViTFaceEmbedder(nn.Module):\n    def __init__(self, model_name=\"vit_small_patch16_224\", embed_dim=512):\n        super().__init__()\n\n        self.backbone = timm.create_model(\n            model_name,\n            pretrained=False,\n            num_classes=0\n        )\n\n        out_dim = self.backbone.num_features\n\n        self.head = nn.Sequential(\n            nn.Linear(out_dim, embed_dim),\n            nn.BatchNorm1d(embed_dim)\n        )\n\n    def forward(self, x):\n        feats = self.backbone(x)\n        emb = self.head(feats)\n        emb = F.normalize(emb, p=2, dim=1)\n        return emb\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T10:32:38.321394Z","iopub.execute_input":"2026-01-20T10:32:38.321803Z","iopub.status.idle":"2026-01-20T10:32:38.328740Z","shell.execute_reply.started":"2026-01-20T10:32:38.321770Z","shell.execute_reply":"2026-01-20T10:32:38.327908Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/test_repo/face_module/src/model.py\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"!ls -lh /kaggle/working | head\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T10:40:05.270479Z","iopub.execute_input":"2026-01-20T10:40:05.271145Z","iopub.status.idle":"2026-01-20T10:40:05.390082Z","shell.execute_reply.started":"2026-01-20T10:40:05.271080Z","shell.execute_reply":"2026-01-20T10:40:05.389026Z"}},"outputs":[{"name":"stdout","text":"total 4.0K\ndrwxr-xr-x 8 root root 4.0K Jan 20 10:01 test_repo\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"!cd /kaggle/working/test_repo && PYTHONPATH=/kaggle/working/test_repo python -c \"from face_module.src.infer import predict; print(predict('/kaggle/input/ritik1/IMG_20231214_134057.jpg'))\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T10:41:58.427960Z","iopub.execute_input":"2026-01-20T10:41:58.428950Z","iopub.status.idle":"2026-01-20T10:42:05.591978Z","shell.execute_reply.started":"2026-01-20T10:41:58.428908Z","shell.execute_reply":"2026-01-20T10:42:05.590984Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n{'embedding_shape': [1, 512], 'embedding_norm': 1.0}\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom PIL import Image\nfrom torchvision import transforms\n\nfrom face_module.src.infer import load_model\nfrom face_module.src.config import IMG_SIZE\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nimg1_path = \"/kaggle/input/ritik1/IMG_20231214_134057.jpg\"\nimg2_path = \"/kaggle/input/ritik2/IMG_20240814_042245.jpg\"\n\ntf = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n])\n\ndef get_embedding(path):\n    model = load_model()\n    img = Image.open(path).convert(\"RGB\")\n    x = tf(img).unsqueeze(0).to(device)\n    with torch.no_grad():\n        emb = model(x)\n    return emb\n\nemb1 = get_embedding(img1_path)\nemb2 = get_embedding(img2_path)\n\nsim = F.cosine_similarity(emb1, emb2).item()\nprint(\"âœ… Cosine Similarity:\", sim)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T10:57:30.147188Z","iopub.execute_input":"2026-01-20T10:57:30.147602Z","iopub.status.idle":"2026-01-20T10:57:30.633857Z","shell.execute_reply.started":"2026-01-20T10:57:30.147572Z","shell.execute_reply":"2026-01-20T10:57:30.632995Z"}},"outputs":[{"name":"stdout","text":"âœ… Cosine Similarity: 0.9999871253967285\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"from face_module.src.infer import predict\n\nimg_path = \"/kaggle/input/ritik1/IMG_20231214_134057.jpg\"\nprint(predict(img_path))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T10:59:20.678357Z","iopub.execute_input":"2026-01-20T10:59:20.679282Z","iopub.status.idle":"2026-01-20T10:59:20.904748Z","shell.execute_reply.started":"2026-01-20T10:59:20.679244Z","shell.execute_reply":"2026-01-20T10:59:20.903878Z"}},"outputs":[{"name":"stdout","text":"{'embedding_shape': [1, 512], 'embedding_norm': 1.0}\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"import os, json, torch\nimport torch.nn.functional as F\nfrom PIL import Image\nfrom torchvision import transforms\n\nfrom face_module.src.infer import load_model\nfrom face_module.src.config import IMG_SIZE\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = load_model()\n\ntf = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n])\n\nDATASET_ROOT = \"/kaggle/input/webface-112x112/webface_112x112\"\n\ndef embed_one(img_path):\n    img = Image.open(img_path).convert(\"RGB\")\n    x = tf(img).unsqueeze(0).to(device)\n    with torch.no_grad():\n        emb = model(x)\n    return emb\n\ngallery_ids = sorted([d for d in os.listdir(DATASET_ROOT) if os.path.isdir(os.path.join(DATASET_ROOT, d))])[:100]\n\ngallery_embs = []\ngallery_names = []\n\nfor pid in gallery_ids:\n    pdir = os.path.join(DATASET_ROOT, pid)\n    imgs = [f for f in os.listdir(pdir) if f.lower().endswith(\".jpg\")]\n    if len(imgs) == 0:\n        continue\n    img_path = os.path.join(pdir, imgs[0])  # first image\n    emb = embed_one(img_path)\n    gallery_embs.append(emb)\n    gallery_names.append(pid)\n\ngallery_embs = torch.cat(gallery_embs, dim=0)  # [N,512]\nprint(\"âœ… Gallery built:\", gallery_embs.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T11:06:44.686947Z","iopub.execute_input":"2026-01-20T11:06:44.687343Z","iopub.status.idle":"2026-01-20T11:07:01.619940Z","shell.execute_reply.started":"2026-01-20T11:06:44.687314Z","shell.execute_reply":"2026-01-20T11:07:01.619052Z"}},"outputs":[{"name":"stdout","text":"âœ… Gallery built: torch.Size([100, 512])\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"query_path = \"/kaggle/input/ritik1/IMG_20231214_134057.jpg\"  # change if needed\n\nqemb = embed_one(query_path)  # [1,512]\n\nsims = F.cosine_similarity(qemb, gallery_embs)  # [N]\nbest_idx = int(torch.argmax(sims).item())\n\nprint(\"âœ… Predicted ID:\", gallery_names[best_idx])\nprint(\"âœ… Similarity:\", float(sims[best_idx].item()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T11:07:40.126725Z","iopub.execute_input":"2026-01-20T11:07:40.127520Z","iopub.status.idle":"2026-01-20T11:07:40.362881Z","shell.execute_reply.started":"2026-01-20T11:07:40.127483Z","shell.execute_reply":"2026-01-20T11:07:40.362182Z"}},"outputs":[{"name":"stdout","text":"âœ… Predicted ID: id_10010\nâœ… Similarity: 0.9999977350234985\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"topk = 5\nvals, idxs = torch.topk(sims, k=topk)\n\nprint(\"\\nâœ… TOP-5 Matches:\")\nfor rank, (v, i) in enumerate(zip(vals, idxs), start=1):\n    print(rank, gallery_names[int(i)], float(v))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T11:07:54.505321Z","iopub.execute_input":"2026-01-20T11:07:54.505650Z","iopub.status.idle":"2026-01-20T11:07:54.515975Z","shell.execute_reply.started":"2026-01-20T11:07:54.505620Z","shell.execute_reply":"2026-01-20T11:07:54.515175Z"}},"outputs":[{"name":"stdout","text":"\nâœ… TOP-5 Matches:\n1 id_10010 0.9999977350234985\n2 id_10056 0.9999974966049194\n3 id_10011 0.999996542930603\n4 id_10082 0.9999964833259583\n5 id_10030 0.9999963641166687\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}